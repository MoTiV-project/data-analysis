{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Clustering applied to data from trips and legs\n",
    "\n",
    "### Steps\n",
    "\n",
    "- [Read data and preprocessing](#read_data)\n",
    "\n",
    "- [Dimensionality reduction - UMAP](#umap)\n",
    "\n",
    "    - [kmeans](#umap_kmeans)\n",
    "    - [hierarchical](#umap_hier)\n",
    "\n",
    "- [Final setting](#final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import clustering_functions\n",
    "import importlib\n",
    "import itertools\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "input_path = \"../../2019-12-16.out/clustering/\"\n",
    "out_path = \"../../2019-12-16.out/clustering/results_trips/\"\n",
    "anon_df_path = \"../../anon-dataset/2019-12-16.anon/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read_data' ></a>\n",
    "### Read data and preprocessing\n",
    "\n",
    "Each user is represented with a vector of values, corresponding to PEF values for each category of transport, so it is a vector of **15 positions**.\n",
    "<br> **0 if** the user has not any leg with that category **OR** if the user selected 0 importance for that variable.\n",
    "\n",
    "<br> We also added the generic values of PEF given by the user, so the final lenght of the vector will be of **18 elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_demographics = pd.read_csv(input_path + \"users_demographics.csv\")\n",
    "print(users_demographics.shape)\n",
    "\n",
    "tc = pd.read_csv(input_path + \"transport_category_count_tr.csv\")\n",
    "transp_cat = list(tc[\"transp_category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read users profile\n",
    "users_profile = pd.read_csv(input_path + \"users_profile_trips.csv\")\n",
    "print(users_profile.shape)\n",
    "# convert in int\n",
    "for col in users_profile.columns[1:]:\n",
    "    users_profile[col] = users_profile[col].apply(lambda x: int(np.round(x)))\n",
    "\n",
    "# convert in class 0-1-2 the generic values\n",
    "# with right=True the classes are (-2, 32], (32, 65], (66,100]\n",
    "users_profile[\"genFit\"] = pd.cut(\n",
    "    users_profile[\"genFit\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "users_profile[\"genProd\"] = pd.cut(\n",
    "    users_profile[\"genProd\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "users_profile[\"genEnj\"] = pd.cut(\n",
    "    users_profile[\"genEnj\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "\n",
    "users_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_specgen_tr = spec_gen_pivot_classes.copy()\n",
    "# df_specgen_tr = df_specgen_tr.drop(['userid'],1)\n",
    "\n",
    "X_transformed = users_profile.drop([\"userid\"], 1)\n",
    "print(X_transformed.shape)\n",
    "print(\"na in the dataset: \", X_transformed.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap' ></a>\n",
    "## Dimensionality reduction - UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, there is really no requirement to stop at n_components at 3. If you are interested in (density based) clustering, or other machine learning techniques, it can be beneficial to pick a larger embedding dimension (say 10, or 50) closer to the the dimension of the underlying manifold on which your data lies.\n",
    "\n",
    "UMAP, like t-SNE, does not completely preserve density.\n",
    "\n",
    "Our goal is to make use of UMAP to perform non-linear manifold aware dimension reduction so we can get the dataset down to a number of dimensions small enough for a density based clustering algorithm to make progress. One advantage of UMAP for this is that it doesn’t require you to reduce to only two dimensions – you can reduce to 10 dimensions instead since the goal is to cluster, not visualize, and the performance cost with UMAP is minimal. As it happens MNIST is such a simple dataset that we really can push it all the way down to only two dimensions, but in general you should explore different embedding dimension options.\n",
    "\n",
    "The next thing to be aware of is that when using UMAP for dimension reduction you will want to select different parameters than if you were using it for visualization. First of all we will want a larger n_neighbors value – small values will focus more on very local structure and are more prone to producing fine grained cluster structure that may be more a result of patterns of noise in the data than actual clusters\n",
    "\n",
    "------\n",
    "https://umap-learn.readthedocs.io/en/latest/clustering.html\n",
    "\n",
    "https://umap-learn.readthedocs.io/en/latest/how_umap_works.html\n",
    "\n",
    "https://github.com/lmcinnes/umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "n_components = 2\n",
    "n_neighbors = 60\n",
    "umap_dr = umap.UMAP(\n",
    "    n_neighbors=n_neighbors, min_dist=0.0, n_components=n_components, random_state=42\n",
    ")\n",
    "\n",
    "# apply to data\n",
    "reduced_data_umap = pd.DataFrame(umap_dr.fit_transform(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = 1\n",
    "n_neighbors_lst = [10, 20, 60]\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 4))\n",
    "axes = axes.ravel()\n",
    "for i in range(len(n_neighbors_lst)):\n",
    "\n",
    "    standard_embedding = umap.UMAP(\n",
    "        random_state=42, n_neighbors=n_neighbors_lst[i], min_dist=0.0\n",
    "    ).fit_transform(X_transformed)\n",
    "\n",
    "    axes[i].scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.9)\n",
    "    axes[i].set_title(\"Neighbors: \" + str(n_neighbors_lst[i]))\n",
    "\n",
    "plt.savefig(\n",
    "    out_path + \"umap_neigh_dim\" + str(n_components) + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap_kmeans' ></a>\n",
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict_red_umap = {}\n",
    "metrics_dict = {\"distortion\", \"silhouette\", \"calinski_harabasz\"}\n",
    "for metric in metrics_dict:\n",
    "    kmeans_dict_red_umap[metric] = {}\n",
    "    kopt = clustering_functions.kmeans_elbow(reduced_data_umap, metric=metric)\n",
    "    kmeans_dict_red_umap[metric][\"kopt\"] = kopt\n",
    "    if kopt != None:\n",
    "\n",
    "        labels, centroids = clustering_functions.kmeans(kopt, reduced_data_umap)\n",
    "        kmeans_dict_red_umap[metric][\"kopt\"] = kopt\n",
    "        kmeans_dict_red_umap[metric][\"silhouette\"] = metrics.silhouette_score(\n",
    "            reduced_data_umap, labels\n",
    "        )\n",
    "        kmeans_dict_red_umap[metric][\n",
    "            \"calinski_harabasz\"\n",
    "        ] = metrics.calinski_harabasz_score(reduced_data_umap, labels)\n",
    "\n",
    "kmeans_dict_red_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### initialization\n",
    "k = 5\n",
    "method = \"kmeans\"\n",
    "\n",
    "\n",
    "labels, centroids = clustering_functions.kmeans(k, reduced_data_umap)\n",
    "\n",
    "all_data_clustered = users_profile.copy()\n",
    "all_data_clustered[\"cluster\"] = labels\n",
    "\n",
    "cluster_df_umap = reduced_data_umap.copy()\n",
    "cluster_df_umap.columns = [\"comp_1\", \"comp_2\"]\n",
    "cluster_df_umap[\"cluster\"] = labels\n",
    "\n",
    "print(\n",
    "    \"Silhouette score:\",\n",
    "    np.round(metrics.silhouette_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "print(\n",
    "    \"Calinski Harabasz score:\",\n",
    "    np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "\n",
    "## Save all data\n",
    "all_data_clustered.to_csv(\n",
    "    out_path\n",
    "    + \"data_for_matching_trips_umap_\"\n",
    "    + method\n",
    "    + \"_dim\"\n",
    "    + str(n_components)\n",
    "    + \"_neigh\"\n",
    "    + str(n_neighbors)\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### VISUALIZATION\n",
    "\n",
    "data_for_plot = all_data_clustered[[\"userid\", \"cluster\"]]\n",
    "data_for_plot.columns = [\"userid\", \"cluster\"]\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    cluster_df_umap, on=[cluster_df_umap.index, \"cluster\"]\n",
    ").iloc[:, 1:]\n",
    "\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    users_demographics[[\"userid\", \"gender\", \"age_range\"]], on=\"userid\", how=\"left\"\n",
    ")\n",
    "\n",
    "# data_for_plot.head()\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "f.subplots_adjust(top=0.9)\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"gender\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"age_range\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "\n",
    "# plt.suptitle(method)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap_hier' ></a>\n",
    "### hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_lst = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "affinity_lst = [\"euclidean\", \"manhattan\", \"cosine\"]\n",
    "# all comb\n",
    "all_comb = list(itertools.product(linkage_lst, affinity_lst))\n",
    "all_comb.remove((\"ward\", \"manhattan\"))\n",
    "all_comb.remove((\"ward\", \"cosine\"))\n",
    "\n",
    "rows_lst = []\n",
    "cols = [\"n_clusters\"]\n",
    "for comb in all_comb:\n",
    "    comb_name = comb[0] + \"_\" + comb[1]\n",
    "    cols.append(comb_name + \"_silhouette\")\n",
    "    cols.append(comb_name + \"_calinski_harabasz\")\n",
    "\n",
    "for k in range(2, 16):\n",
    "    # hier_dict['n_cluster_'+str(k)] = {}\n",
    "    row = [k]\n",
    "    for comb in all_comb:\n",
    "        comb_name = comb[0] + \"_\" + comb[1]\n",
    "\n",
    "        labels = clustering_functions.hierarchical(\n",
    "            reduced_data_umap, k, affinity=comb[1], linkage=comb[0]\n",
    "        )\n",
    "        row.append(np.round(metrics.silhouette_score(reduced_data_umap, labels), 2))\n",
    "        row.append(\n",
    "            np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2)\n",
    "        )\n",
    "\n",
    "    rows_lst.append(row)\n",
    "hier_df_red_umap = pd.DataFrame(rows_lst, columns=cols)\n",
    "hier_df_red_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier_df_red_umap.iloc[:, [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]].max()\n",
    "# hier_df_red_umap.iloc[:, [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='final' ></a>\n",
    "## FINAL hierarchical clustering with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### hierarchical clustering with ward_euclidean and 5 clusters\n",
    "k = 5\n",
    "affinity = \"euclidean\"\n",
    "linkage = \"ward\"\n",
    "method = \"hierarchical\"\n",
    "\n",
    "labels = clustering_functions.hierarchical(\n",
    "    reduced_data_umap, k, affinity=affinity, linkage=linkage\n",
    ")\n",
    "# memorize in a df\n",
    "cluster_df_umap = reduced_data_umap.copy()\n",
    "cluster_df_umap.columns = [\"comp_1\", \"comp_2\"]\n",
    "cluster_df_umap[\"cluster\"] = labels\n",
    "\n",
    "# add labels to the complete dataset\n",
    "all_data_clustered = users_profile.copy()\n",
    "all_data_clustered[\"cluster\"] = labels\n",
    "\n",
    "print(\n",
    "    \"Silhouette score:\",\n",
    "    np.round(metrics.silhouette_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "print(\n",
    "    \"Calinski Harabasz score:\",\n",
    "    np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "\n",
    "\n",
    "all_data_clustered.to_csv(\n",
    "    out_path\n",
    "    + \"data_for_matching_trips_umap_\"\n",
    "    + method\n",
    "    + \"_dim\"\n",
    "    + str(n_components)\n",
    "    + \"_neigh\"\n",
    "    + str(n_neighbors)\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZATION\n",
    "\n",
    "data_for_plot = all_data_clustered[[\"userid\", \"cluster\"]]\n",
    "data_for_plot.columns = [\"userid\", \"cluster\"]\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    cluster_df_umap, on=[cluster_df_umap.index, \"cluster\"]\n",
    ").iloc[:, 1:]\n",
    "\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    users_demographics[[\"userid\", \"gender\", \"age_range\"]], on=\"userid\", how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "f.subplots_adjust(top=0.9)\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"gender\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"age_range\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "\n",
    "# plt.suptitle(method)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.despine(left=True)\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \"_ALL.png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUMMARY TABLES\n",
    "\n",
    "for c in range(0, len(all_data_clustered[\"cluster\"].unique())):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    print(\"Users in cluster\", c, \" : \", cl_df.shape[0])\n",
    "    print()\n",
    "    tmp = pd.DataFrame(\n",
    "        index=transp_cat,\n",
    "        columns=[\n",
    "            \"count\",\n",
    "            \"relfreq_tot\",\n",
    "            \"relfreq_tc\",\n",
    "            \"meanP\",\n",
    "            \"meanE\",\n",
    "            \"meanF\",\n",
    "            \"meanGenP\",\n",
    "            \"meanGenE\",\n",
    "            \"meanGenF\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    for i in transp_cat:  # for each transport category\n",
    "        users_with_tc = cl_df[\n",
    "            (cl_df[\"fit_\" + i] != 0)\n",
    "            | (cl_df[\"prod_\" + i] != 0)\n",
    "            | (cl_df[\"enj_\" + i] != 0)\n",
    "        ]\n",
    "\n",
    "        tmp.loc[i] = [\n",
    "            len(users_with_tc),\n",
    "            np.round(len(users_with_tc) / cl_df.shape[0], 2),\n",
    "            np.round(len(users_with_tc) / int(tc[\"count\"][tc.transp_category == i]), 2),\n",
    "            np.round(users_with_tc[\"prod_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"enj_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"fit_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genProd\"].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genEnj\"].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genFit\"].astype(\"float\").mean(), 2),\n",
    "        ]\n",
    "\n",
    "    tmp.to_csv(\n",
    "        out_path + \"summary_table_trips_\" + method + \"_cl\" + str(c) + \"_mean.csv\"\n",
    "    )\n",
    "\n",
    "# example of summaty table\n",
    "# relfreq_tot: divided by total users in the cluster\n",
    "# relfreq_tc: divided by total of selection\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(out_path + \"summary_table_trips_\" + method + \"_cl\" + str(4) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### Number of Transport Categories (TC) selected by each users\n",
    "# ex. cluster 0: users selected 4 or 5 TC as preferred\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "# hist\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=(17, 10), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "r = 0\n",
    "for c in range(0, ncols):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    transp_df_clust = users_profile[[\"userid\", \"transp_category\"]][\n",
    "        users_profile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    tmp = pd.DataFrame(transp_df_clust.groupby(\"userid\").count()[\"transp_category\"])\n",
    "    tmp2 = tmp.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "    axes[r][c].bar(tmp2[\"transp_category\"], tmp2[\"count\"])\n",
    "    axes[r][c].set_title(\"Number of TC - cluster \" + str(c), fontsize=14)\n",
    "    axes[r][c].set_xticks(range(1, len(transp_cat) + 1))\n",
    "    axes[r][c - ncols].tick_params(labelsize=13)\n",
    "\n",
    "r = 1\n",
    "for c in range(ncols, k):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    transp_df_clust = users_profile[[\"userid\", \"transp_category\"]][\n",
    "        users_profile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    tmp = pd.DataFrame(transp_df_clust.groupby(\"userid\").count()[\"transp_category\"])\n",
    "    tmp2 = tmp.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "    axes[r][c - ncols].bar(tmp2[\"transp_category\"], tmp2[\"count\"])\n",
    "    axes[r][c - ncols].set_title(\"Number of TC - cluster \" + str(c), fontsize=14)\n",
    "    axes[r][c - ncols].set_xticks(range(1, len(transp_cat) + 1))\n",
    "    axes[r][c - ncols].tick_params(labelsize=13)\n",
    "\n",
    "\n",
    "plt.savefig(out_path + \"tc_per_user_classes.png\", bbox_to_anchor=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Association Table\n",
    "# for each combination of transport mode, find how many users selected that combination\n",
    "\n",
    "all_comb_tr = [\n",
    "    (transp_cat[i], transp_cat[j])\n",
    "    for i in range(len(transp_cat))\n",
    "    for j in range(i, len(transp_cat))\n",
    "]\n",
    "\n",
    "for c in range(k):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"Hcluster_umap\"] == c]\n",
    "    transp_df_clust = spec_worthwhile[[\"userid\", \"transp_category\"]][\n",
    "        spec_worthwhile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        transp_df_clust.groupby([\"userid\", \"transp_category\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    basket = (\n",
    "        df.groupby([\"userid\", \"transp_category\"])[\"count\"]\n",
    "        .sum()\n",
    "        .unstack()\n",
    "        .reset_index()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    cont_table = pd.DataFrame(columns=transp_cat, index=transp_cat)\n",
    "    for comb in all_comb_tr:\n",
    "        cont_table.loc[comb[0], comb[1]] = len(\n",
    "            basket[(basket[comb[0]] == 1) & (basket[comb[1]] == 1)]\n",
    "        )\n",
    "        cont_table.loc[comb[1], comb[0]] = len(\n",
    "            basket[(basket[comb[0]] == 1) & (basket[comb[1]] == 1)]\n",
    "        )\n",
    "        # save\n",
    "        cont_table.to_csv(\n",
    "            out_path + \"transport_modes_associations_cl\" + str(c) + \".csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of association table generated\n",
    "# users who selected cycling_emerging_micromobility are 9 and 8 of them also selected public_transp_short_dist\n",
    "cont_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUMMARY TABLES\n",
    "\n",
    "for c in range(0, len(all_data_clustered[\"Hcluster_umap\"].unique())):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"Hcluster_umap\"] == c]\n",
    "    print(\"Users in cluster\", c, \" : \", cl_df.shape[0])\n",
    "    print()\n",
    "    tmp = pd.DataFrame(\n",
    "        index=transp_cat,\n",
    "        columns=[\n",
    "            \"count\",\n",
    "            \"relfreq_tot\",\n",
    "            \"relfreq_tc\",\n",
    "            \"meanP\",\n",
    "            \"meanE\",\n",
    "            \"meanF\",\n",
    "            \"meanGenP\",\n",
    "            \"meanGenE\",\n",
    "            \"meanGenF\",\n",
    "        ],\n",
    "    )\n",
    "    for tc in transp_cat:\n",
    "        users_with_tc = cl_df[\n",
    "            (cl_df[\"motsFit_\" + tc] != 0)\n",
    "            | (cl_df[\"motsProd_\" + tc] != 0)\n",
    "            | (cl_df[\"motsRelax_\" + tc] != 0)\n",
    "        ]\n",
    "\n",
    "        tmp.loc[tc] = [\n",
    "            len(users_with_tc),\n",
    "            np.round(len(users_with_tc) / cl_df.shape[0], 2),\n",
    "            np.round(\n",
    "                len(users_with_tc)\n",
    "                / int(\n",
    "                    transp_cat_count[\"count\"][transp_cat_count.transp_category == tc]\n",
    "                ),\n",
    "                2,\n",
    "            ),\n",
    "            np.round(users_with_tc[\"motsProd_\" + tc].mode()[0], 2),\n",
    "            np.round(users_with_tc[\"motsRelax_\" + tc].mode()[0], 2),\n",
    "            np.round(users_with_tc[\"motsFit_\" + tc].mode()[0], 2),\n",
    "            np.round(users_with_tc[\"genProd\"].mode()[0], 2),\n",
    "            np.round(users_with_tc[\"genRelax\"].mode()[0], 2),\n",
    "            np.round(users_with_tc[\"genFit\"].mode()[0], 2),\n",
    "        ]\n",
    "\n",
    "    tmp.to_csv(out_path + \"summary_table_with_classes_cl\" + str(c) + \".csv\")\n",
    "\n",
    "# example of summaty table\n",
    "# relfreq_tot: divided by total users in the cluster\n",
    "# relfreq_tc: divided by total of selection\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create users profiles\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Read data and preprocessing\n",
    "    - `all_legs`\n",
    "    - `category_transp_mode_dict`\n",
    "    - `specific_worthwhile`\n",
    "    - `gen_worthwhile`\n",
    "    - `values_from_trip`\n",
    "\n",
    "- Finale set of users\n",
    "- Create users profiles for onBoarding data\n",
    "- Create users profiles for trips data\n",
    "- Take users demograhic information\n",
    "- Create transport category tables\n",
    "\n",
    "\n",
    "### Savings\n",
    "\n",
    "- `final_users_sample.txt`\n",
    "- `users_profile_spec_gen.csv`\n",
    "- `users_profile_trips.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import clustering_functions\n",
    "import importlib\n",
    "import itertools\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "input_path = \"../../2019-12-16.out/\"\n",
    "out_path = \"../../2019-12-16.out/clustering/\"\n",
    "anon_df_path = \"../../anon-dataset/2019-12-16.anon/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legs = pd.read_pickle(input_path + legs)\n",
    "\n",
    "# transport categories\n",
    "with open(input_path + \"category_transp_mode_dict.json\", \"r\") as f:\n",
    "    category_transp_mode_dict = json.load(f)\n",
    "\n",
    "inverted_category_transp_mode_dict = dict(\n",
    "    (v, k) for k in category_transp_mode_dict for v in category_transp_mode_dict[k]\n",
    ")\n",
    "\n",
    "# final sample of users for onBoarding clusters\n",
    "# with open(out_path + 'final_users_sample.txt', 'r')as f:\n",
    "#    final_users_onBoarding = f.read().splitlines()\n",
    "# print(len(final_users_onBoarding))\n",
    "\n",
    "print(all_legs.shape)\n",
    "print(\"users in all_legs:\", len(all_legs.userid.unique()))\n",
    "print(\"legs:\", len(all_legs.legid.unique()))\n",
    "print(\"trips in all_legs:\", len(all_legs.tripid.unique()))\n",
    "\n",
    "\n",
    "all_legs.head()\n",
    "### GENERAL results, not the ones referred to the sample we will create in this code!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`specific_worthwhile`**\n",
    "\n",
    "- Take users with at least a leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_worthwhile = pd.read_pickle(input_path + \"specific_worthwhile.pkl\")  # 3309 users\n",
    "print(\"initial users:\", len(spec_worthwhile.userid.unique()))\n",
    "# select only trips in all_legs\n",
    "spec_worthwhile = spec_worthwhile[\n",
    "    (spec_worthwhile[\"userid\"].isin(all_legs[\"userid\"]))\n",
    "    & (spec_worthwhile[\"MotText\"] != \"\")\n",
    "]\n",
    "# convert intercityTrain into intercity\n",
    "spec_worthwhile[\"MotText\"] = spec_worthwhile[\"MotText\"].apply(\n",
    "    lambda x: \"intercityTrain\" if x == \"intercity\" else x\n",
    ")\n",
    "# select legs that are in all_legs\n",
    "spec_worthwhile = spec_worthwhile[\n",
    "    (spec_worthwhile[\"userid\"].isin(list(all_legs.userid.unique())))\n",
    "]  # 3164\n",
    "print(\"only users with at least a leg:\", len(spec_worthwhile.userid.unique()))\n",
    "\n",
    "# add the transport category\n",
    "spec_worthwhile[\"transp_category\"] = spec_worthwhile[\"Mot\"].apply(\n",
    "    lambda x: inverted_category_transp_mode_dict.get(int(x))\n",
    ")\n",
    "\n",
    "# if a user has more than one mode of transport associate to the same transport category\n",
    "# take the mean of PEF\n",
    "# in the example, user 1sN4Fx4vabPZcUu9tFQdcbaYXq73 has walking and running\n",
    "# associated to the same transp_category = Walking so\n",
    "# the new motsFit will be 50 + 100 / 2 = 75\n",
    "spec_worthwhile = (\n",
    "    spec_worthwhile.groupby([\"userid\", \"transp_category\"])[\n",
    "        \"motsFit\", \"motsProd\", \"motsRelax\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`gen_worthwhile`**\n",
    "\n",
    "- Take users with at least a leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gwv_file = \"gen_worthwhile.pkl\"\n",
    "gwv_df = pd.read_pickle(input_path + gwv_file)\n",
    "\n",
    "gwv_df.rename(\n",
    "    columns={\"fitness\": \"genFit\", \"productivity\": \"genProd\", \"enjoyment\": \"genEnj\",},\n",
    "    inplace=True,\n",
    ")\n",
    "print(\"initial users:\", len(gwv_df.userid.unique()))\n",
    "\n",
    "# select users with at least a leg\n",
    "gwv_df = gwv_df[gwv_df.userid.isin(all_legs.userid.unique())]\n",
    "print(\"users with at least a leg: \", len(gwv_df.userid.unique()))\n",
    "\n",
    "gwv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`values_from_trip`**\n",
    "\n",
    "- Remove legs with valueFromTrip = 'Unknown'\n",
    "- Remove legs with transport category = None\n",
    "- Remove trips with more than a leg\n",
    "- Merge Paid_work and Personal_tasks into Productivity taking the **maximum** value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read values_from_trip\n",
    "values_from_trip = pd.read_pickle(input_path + \"values_from_trip.pkl\")\n",
    "print(\"initial legs: \", values_from_trip.legid.nunique())\n",
    "\n",
    "# remove legs with valueFromTrip = 'Unknown'\n",
    "values_from_trip = values_from_trip[values_from_trip.valueFromTrip != \"Unknown\"]\n",
    "print(\"without unknown: \", values_from_trip.legid.nunique())\n",
    "\n",
    "# remove legs with transport category = None\n",
    "legs_without_transp_cat = all_legs[\"legid\"][all_legs.transp_category.isna()]\n",
    "values_from_trip = values_from_trip[\n",
    "    ~values_from_trip.legid.isin(legs_without_transp_cat)\n",
    "]\n",
    "print(\"with valid transport category: \", values_from_trip.legid.nunique())\n",
    "print()\n",
    "# remove trips with more than a leg\n",
    "trips_count = values_from_trip.groupby(\"tripid\").size().reset_index(name=\"count\")\n",
    "trips_to_remove = trips_count[\"tripid\"][trips_count[\"count\"] > 4]\n",
    "print(\"trips with more than a leg: \", len(trips_to_remove))\n",
    "values_from_trip = values_from_trip[~values_from_trip.tripid.isin(trips_to_remove)]\n",
    "print(\"legs: \", values_from_trip.legid.nunique())\n",
    "print(\"trips: \", values_from_trip.tripid.nunique())\n",
    "\n",
    "\n",
    "tmp = values_from_trip[[\"legid\", \"value\", \"valueFromTrip\"]]\n",
    "values_from_trip_pivot = pd.pivot(\n",
    "    data=tmp, index=\"legid\", columns=\"valueFromTrip\", values=\"value\"\n",
    ").reset_index()\n",
    "# add transport category and userid\n",
    "values_from_trip_pivot = values_from_trip_pivot.merge(\n",
    "    all_legs[[\"legid\", \"userid\", \"transp_category\"]], on=\"legid\"\n",
    ").drop_duplicates()\n",
    "# Merge Paid_work and Personal_tasks into Productivity taking the **maximum** value\n",
    "values_from_trip_pivot[\"Productivity\"] = values_from_trip_pivot[\n",
    "    [\"Paid_work\", \"Personal_tasks\"]\n",
    "].max(axis=1)\n",
    "values_from_trip_pivot.drop([\"Paid_work\", \"Personal_tasks\"], axis=1, inplace=True)\n",
    "print(\"users: \", values_from_trip_pivot.userid.nunique())\n",
    "\n",
    "values_from_trip_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final set of users\n",
    "\n",
    "Users that have **all** these conditions:\n",
    "\n",
    "- Specific ww values\n",
    "- Generic ww values\n",
    "- Values from trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_users = set(spec_worthwhile.userid.unique())\n",
    "gen_users = set(gwv_df.userid.unique())\n",
    "values_users = set(values_from_trip_pivot.userid.unique())\n",
    "\n",
    "print(\"spec:\", len(spec_users))\n",
    "print(\"gen:\", len(gen_users))\n",
    "print(\"values:\", len(values_users))\n",
    "print()\n",
    "#### INTERSECTION\n",
    "\n",
    "final_sample_users = spec_users.intersection((gen_users.intersection(values_users)))\n",
    "print(\"--- Final users: \", len(final_sample_users))\n",
    "\n",
    "\n",
    "# SAVE USERS LIST\n",
    "with open(out_path + \"final_users_sample.txt\", \"w\") as f:\n",
    "    for usn in final_sample_users:\n",
    "        f.write(\"%s\\n\" % usn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users profiles for onBoarding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select users for clustering\n",
    "spec_worthwhile = spec_worthwhile[spec_worthwhile.userid.isin(final_sample_users)]\n",
    "gwv_df = gwv_df[gwv_df.userid.isin(final_sample_users)]\n",
    "\n",
    "# check\n",
    "print(spec_worthwhile.userid.nunique())\n",
    "print(gwv_df.userid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector for each user\n",
    "users_profile_spec_ww = pd.pivot(\n",
    "    spec_worthwhile,\n",
    "    index=\"userid\",\n",
    "    columns=\"transp_category\",\n",
    "    values=[\"motsFit\", \"motsProd\", \"motsRelax\"],\n",
    ").reset_index()\n",
    "users_profile_spec_ww = users_profile_spec_ww.fillna(0)\n",
    "\n",
    "users_profile_spec_ww.columns = [\n",
    "    \"userid\",\n",
    "    \"fit_cycling_emerging_micromobility\",\n",
    "    \"fit_private_motorized\",\n",
    "    \"fit_public_transp_long_dist\",\n",
    "    \"fit_public_transp_short_dist\",\n",
    "    \"fit_walking\",\n",
    "    \"prod_cycling_emerging_micromobility\",\n",
    "    \"prod_private_motorized\",\n",
    "    \"prod_public_transp_long_dist\",\n",
    "    \"prod_public_transp_short_dist\",\n",
    "    \"prod_walking\",\n",
    "    \"enj_cycling_emerging_micromobility\",\n",
    "    \"enj_private_motorized\",\n",
    "    \"enj_public_transp_long_dist\",\n",
    "    \"enj_public_transp_short_dist\",\n",
    "    \"enj_walking\",\n",
    "]\n",
    "\n",
    "## Add GENERIC ww\n",
    "users_profile_spec_ww = users_profile_spec_ww.merge(gwv_df, on=\"userid\")\n",
    "print(users_profile_spec_ww.shape)\n",
    "users_profile_spec_ww.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE\n",
    "users_profile_spec_ww.to_csv(out_path + \"users_profile_spec_gen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users profiles for trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select users from final_sample_users\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    values_from_trip_pivot.userid.isin(final_sample_users)\n",
    "]\n",
    "\n",
    "print(values_from_trip_pivot.userid.nunique())\n",
    "tranps_cat_count_trips = (\n",
    "    values_from_trip_pivot.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    ")\n",
    "tranps_cat_count_trips[\"rel_count\"] = tranps_cat_count_trips[\"count\"].apply(\n",
    "    lambda x: np.round(x / tranps_cat_count_trips[\"count\"].sum(), 2)\n",
    ")\n",
    "tranps_cat_count_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_from_trip_pivot2 = (\n",
    "    values_from_trip_pivot.groupby([\"userid\", \"transp_category\"])[\n",
    "        [\"Enjoyment\", \"Fitness\", \"Productivity\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "users_profile_trips = pd.pivot(\n",
    "    data=values_from_trip_pivot2,\n",
    "    index=\"userid\",\n",
    "    columns=\"transp_category\",\n",
    "    values=[\"Enjoyment\", \"Fitness\", \"Productivity\"],\n",
    ").reset_index()\n",
    "\n",
    "users_profile_trips.fillna(0, inplace=True)\n",
    "users_profile_trips.columns = [\n",
    "    \"userid\",\n",
    "    \"enj_cycling_emerging_micromobility\",\n",
    "    \"enj_private_motorized\",\n",
    "    \"enj_public_transp_long_dist\",\n",
    "    \"enj_public_transp_short_dist\",\n",
    "    \"enj_walking\",\n",
    "    \"fit_cycling_emerging_micromobility\",\n",
    "    \"fit_private_motorized\",\n",
    "    \"fit_public_transp_long_dist\",\n",
    "    \"fit_public_transp_short_dist\",\n",
    "    \"fit_walking\",\n",
    "    \"prod_cycling_emerging_micromobility\",\n",
    "    \"prod_private_motorized\",\n",
    "    \"prod_public_transp_long_dist\",\n",
    "    \"prod_public_transp_short_dist\",\n",
    "    \"prod_walking\",\n",
    "]\n",
    "\n",
    "## Add GENERIC ww\n",
    "users_profile_trips = users_profile_trips.merge(gwv_df, on=\"userid\")\n",
    "print(users_profile_trips.shape)\n",
    "users_profile_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE\n",
    "users_profile_trips.to_csv(out_path + \"users_profile_trips.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legs - duration and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_legs = all_legs[all_legs.userid.isin(final_sample_users)]\n",
    "print(\"total legs: \", final_legs.legid.nunique())\n",
    "reviewed_legs = all_legs[all_legs.legid.isin(values_from_trip_pivot.legid.unique())]\n",
    "print(\"reviewed legs: \", len(reviewed_legs))\n",
    "# print(\"trips: \", values_from_trip_pivot.tripid.nunique())\n",
    "\n",
    "reviewed_legs = reviewed_legs[\n",
    "    [\"legid\", \"inferred_leg_duration_min\", \"trueDistance\", \"legDistance\"]\n",
    "]  # esiste anche legDistance\n",
    "reviewed_legs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration = reviewed_legs['inferred_leg_duration_min'].sort_values()\n",
    "reviewed_legs2 = reviewed_legs[\n",
    "    (reviewed_legs.inferred_leg_duration_min < 300)\n",
    "    & (reviewed_legs.trueDistance < 400000)\n",
    "]\n",
    "\n",
    "plt.scatter(reviewed_legs2[\"inferred_leg_duration_min\"], reviewed_legs2[\"trueDistance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    reviewed_legs.inferred_leg_duration_min[\n",
    "        reviewed_legs.inferred_leg_duration_min < 175\n",
    "    ],\n",
    "    bins=50,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reviewed_legs.trueDistance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users' demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_demographics = pd.read_csv(anon_df_path + \"user_details.csv\")\n",
    "# take only users in the final sample\n",
    "users_demographics = users_demographics[\n",
    "    users_demographics.userid.isin(final_sample_users)\n",
    "]\n",
    "# take only useful columns\n",
    "users_demographics = users_demographics[\n",
    "    [\n",
    "        \"userid\",\n",
    "        \"gender\",\n",
    "        \"age_range\",\n",
    "        \"lang\",\n",
    "        \"education_level\",\n",
    "        \"marital_status_household\",\n",
    "        \"labour_status_household\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "users_demographics[\"education_level\"] = users_demographics[\"education_level\"].apply(\n",
    "    lambda x: \"High school\"\n",
    "    if x == \"High school (12th grade)\"\n",
    "    else \"Basic\"\n",
    "    if x == \"Basic (up to 10th grade)\"\n",
    "    else \"University\"\n",
    "    if x == \"University\"\n",
    "    else None\n",
    ")\n",
    "users_demographics[\"marital_status_household\"] = users_demographics[\n",
    "    \"marital_status_household\"\n",
    "].apply(\n",
    "    lambda x: \"Partner\"\n",
    "    if x == \"En pareja\"\n",
    "    else \"Married\"\n",
    "    if x == \"Naimisissa\"\n",
    "    else \"Single\"\n",
    "    if x == \"Slobodný/á\"\n",
    "    else \"Married\"\n",
    "    if x == \"Ženatý/vydatá\"\n",
    "    else \"Partner\"\n",
    "    if x == \"Registered partnership\"\n",
    "    else x\n",
    ")\n",
    "users_demographics[\"labour_status_household\"] = users_demographics[\n",
    "    \"labour_status_household\"\n",
    "].apply(\n",
    "    lambda x: \"Employed FT\"\n",
    "    if x == \"Employed full Time\"\n",
    "    else \"Employed PT\"\n",
    "    if x == \"Employed part-time\"\n",
    "    else x\n",
    ")\n",
    "users_demographics[\"lang\"] = users_demographics[\"lang\"].apply(\n",
    "    lambda x: \"spa\" if x == \"esp\" else x\n",
    ")\n",
    "\n",
    "print(users_demographics.shape)\n",
    "users_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save user demographics for clustering\n",
    "users_demographics.to_csv(out_path + \"users_demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTS\n",
    "ncols = 3\n",
    "nrows = 2\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(17, 10))\n",
    "\n",
    "\n",
    "# gender\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"gender\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[0][0].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[0][0].set_xticks(range(len(tmp)))\n",
    "axes[0][0].set_xticklabels(list(tmp.gender))\n",
    "axes[0][0].set_title(\"Gender\")\n",
    "\n",
    "# Age\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"age_range\").size().reset_index(name=\"count\")\n",
    ")  # .sort_values(by='age_r', ascending=False)\n",
    "axes[0][1].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[0][1].set_xticks(range(len(tmp)))\n",
    "axes[0][1].set_xticklabels(list(tmp.age_range), rotation=45)\n",
    "axes[0][1].set_title(\"Age\")\n",
    "\n",
    "# Language\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"lang\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[0][2].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[0][2].set_xticks(range(len(tmp)))\n",
    "axes[0][2].set_xticklabels(list(tmp.lang), rotation=45)\n",
    "axes[0][2].set_title(\"Language\")\n",
    "\n",
    "# Educ level\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"education_level\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[1][0].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[1][0].set_xticks(range(len(tmp)))\n",
    "axes[1][0].set_xticklabels(list(tmp.education_level))\n",
    "axes[1][0].set_title(\"Education Level\")\n",
    "\n",
    "# Marital staus\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"marital_status_household\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[1][1].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[1][1].set_xticks(range(len(tmp)))\n",
    "axes[1][1].set_xticklabels(list(tmp.marital_status_household), rotation=45)\n",
    "axes[1][1].set_title(\"Marital Status\")\n",
    "\n",
    "# Labour status\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"labour_status_household\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[1][2].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[1][2].set_xticks(range(len(tmp)))\n",
    "axes[1][2].set_xticklabels(list(tmp.labour_status_household), rotation=45)\n",
    "axes[1][2].set_title(\"Labour Status\")\n",
    "\n",
    "plt.savefig(out_path + \"plot_demographics.png\", bbox_to_anchor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (\n",
    "    users_demographics.groupby(\"education_level\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### PLOTS\n",
    "ncols = 6\n",
    "nrows = 1\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(20, 4))\n",
    "\n",
    "\n",
    "# gender\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"gender\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[0].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[0].set_xticks(range(len(tmp)))\n",
    "axes[0].set_xticklabels(list(tmp.gender))\n",
    "axes[0].set_title(\"Gender\")\n",
    "\n",
    "# Age\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"age_range\").size().reset_index(name=\"count\")\n",
    ")  # .sort_values(by='age_r', ascending=False)\n",
    "axes[1].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[1].set_xticks(range(len(tmp)))\n",
    "axes[1].set_xticklabels(list(tmp.age_range), rotation=45)\n",
    "axes[1].set_title(\"Age\")\n",
    "\n",
    "# Language\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"lang\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[2].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[2].set_xticks(range(len(tmp)))\n",
    "axes[2].set_xticklabels(list(tmp.lang), rotation=55)\n",
    "axes[2].set_title(\"Language\")\n",
    "\n",
    "# Educ level\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"education_level\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[3].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[3].set_xticks(range(len(tmp)))\n",
    "axes[3].set_xticklabels(list(tmp.education_level), rotation=45)\n",
    "axes[3].set_title(\"Education Level\")\n",
    "\n",
    "# Marital staus\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"marital_status_household\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[4].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[4].set_xticks(range(len(tmp)))\n",
    "axes[4].set_xticklabels(list(tmp.marital_status_household), rotation=45)\n",
    "axes[4].set_title(\"Marital Status\")\n",
    "\n",
    "# Labour status\n",
    "tmp = (\n",
    "    users_demographics.groupby(\"labour_status_household\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "axes[5].bar(range(len(tmp)), tmp[\"count\"])\n",
    "axes[5].set_xticks(range(len(tmp)))\n",
    "axes[5].set_xticklabels(list(tmp.labour_status_household), rotation=45)\n",
    "axes[5].set_title(\"Labour Status\")\n",
    "\n",
    "plt.savefig(\n",
    "    out_path + \"plot_demographics.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transport categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## oboarding\n",
    "tc = spec_worthwhile.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "tc.to_csv(out_path + \"transport_category_count_ob.csv\", index=False)\n",
    "\n",
    "## trips\n",
    "tc = values_from_trip_pivot.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "tc.to_csv(out_path + \"transport_category_count_tr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers = 3011\n",
    "tc_df = (\n",
    "    values_from_trip_pivot.groupby(\"transp_category\")\n",
    "    .size()\n",
    "    .reset_index(name=\"leg_count\")\n",
    ")\n",
    "tc_df[\"leg_rel_count\"] = tc_df[\"leg_count\"].apply(\n",
    "    lambda x: np.round((x / tc_df[\"leg_count\"].sum()) * 100, 2)\n",
    ")\n",
    "\n",
    "# users with legs\n",
    "tmp = (\n",
    "    values_from_trip_pivot.groupby(\"transp_category\")[\"userid\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"user_count_leg\")\n",
    ")\n",
    "tc_df = tc_df.merge(tmp, on=\"transp_category\")\n",
    "tc_df[\"user_rel_count_leg\"] = tc_df[\"user_count_leg\"].apply(\n",
    "    lambda x: np.round((x / nusers) * 100, 2)\n",
    ")\n",
    "\n",
    "# onboarding\n",
    "tmp = (\n",
    "    spec_worthwhile.groupby(\"transp_category\").size().reset_index(name=\"user_count_ob\")\n",
    ")\n",
    "tc_df = tc_df.merge(tmp, on=\"transp_category\")\n",
    "tc_df[\"user_rel_count_ob\"] = tc_df[\"user_count_ob\"].apply(\n",
    "    lambda x: np.round((x / nusers) * 100, 2)\n",
    ")\n",
    "\n",
    "# save\n",
    "tc_df.to_csv(out_path + \"tc_table_all_for_paper\")\n",
    "\n",
    "tc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MALE\n",
    "male_df = users_demographics[users_demographics.gender == \"Male\"]\n",
    "nusers = len(male_df)\n",
    "print(nusers)\n",
    "\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    values_from_trip_pivot.userid.isin(male_df.userid.unique())\n",
    "]\n",
    "spec_worthwhile = spec_worthwhile[spec_worthwhile.userid.isin(male_df.userid.unique())]\n",
    "\n",
    "tc_df = (\n",
    "    values_from_trip_pivot.groupby(\"transp_category\")\n",
    "    .size()\n",
    "    .reset_index(name=\"leg_count\")\n",
    ")\n",
    "tc_df[\"leg_rel_count\"] = tc_df[\"leg_count\"].apply(\n",
    "    lambda x: np.round((x / tc_df[\"leg_count\"].sum()) * 100, 2)\n",
    ")\n",
    "\n",
    "# users with legs\n",
    "tmp = (\n",
    "    values_from_trip_pivot.groupby(\"transp_category\")[\"userid\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"user_count_leg\")\n",
    ")\n",
    "tc_df = tc_df.merge(tmp, on=\"transp_category\")\n",
    "tc_df[\"user_rel_count_leg\"] = tc_df[\"user_count_leg\"].apply(\n",
    "    lambda x: np.round((x / nusers) * 100, 2)\n",
    ")\n",
    "\n",
    "# onboarding\n",
    "tmp = (\n",
    "    spec_worthwhile.groupby(\"transp_category\").size().reset_index(name=\"user_count_ob\")\n",
    ")\n",
    "tc_df = tc_df.merge(tmp, on=\"transp_category\")\n",
    "tc_df[\"user_rel_count_ob\"] = tc_df[\"user_count_ob\"].apply(\n",
    "    lambda x: np.round((x / nusers) * 100, 2)\n",
    ")\n",
    "\n",
    "# save\n",
    "tc_df.to_csv(out_path + \"tc_table_male_for_paper.csv\", index=False)\n",
    "\n",
    "tc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

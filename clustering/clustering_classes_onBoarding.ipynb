{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5.1 - 5.2\n",
    "\n",
    "### SPRINT 1 - Individual Value Proposition:\n",
    "Identificaion of clusters of users based on specific worthwhileness values (Self-declared value perception) and transport mode categories\n",
    "\n",
    "### T5.2: Clustering based on specific worthwhileness values (self-declared)\n",
    "\n",
    "### Steps\n",
    "\n",
    "- [Read users' profiles](#read_users)\n",
    "\n",
    "- [Dimensionality reduction - UMAP](#umap)\n",
    "\n",
    "    - [kmeans](#umap_kmeans)\n",
    "    - [hierarchical](#umap_hier)\n",
    "\n",
    "- [Final setting](#final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import clustering_functions\n",
    "import importlib\n",
    "import itertools\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "input_path = \"../../2019-12-16.out/clustering/\"\n",
    "out_path = \"../../2019-12-16.out/clustering/results_onBoarding/\"\n",
    "anon_df_path = \"../../anon-dataset/2019-12-16.anon/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read_users' ></a>\n",
    "### Read users' profiles\n",
    "\n",
    "Each user is represented with a vector of values, corresponding to PEF values for each category of transport, so it is a vector of **15 positions**.\n",
    "<br> **0 if** the user has not selected that category as regularly used **OR** if the user selected 0 importance for that variable.\n",
    "\n",
    "<br> We also added the generic values of PEF given by the user, so the final lenght of the vector will be of **18 elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read demographics of users\n",
    "users_demographics = pd.read_csv(input_path + \"users_demographics.csv\")\n",
    "print(users_demographics.shape)\n",
    "\n",
    "# transport categories\n",
    "tc = pd.read_csv(input_path + \"transport_category_count_ob.csv\")\n",
    "transp_cat = list(tc[\"transp_category\"])\n",
    "\n",
    "# read users profile\n",
    "users_profile = pd.read_csv(input_path + \"users_profile_spec_gen.csv\")\n",
    "print(users_profile.shape)\n",
    "users_profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERT INTO CLASSES**\n",
    "\n",
    "- 0: values from 0 to 32\n",
    "- 1: values from 33 to 65\n",
    "- 2: values from 66 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with right=True the classes are (-2, 32], (32, 65], (66,100]\n",
    "users_profile_classes = users_profile.copy()\n",
    "for col in users_profile_classes.columns[1:]:\n",
    "\n",
    "    users_profile_classes[col] = pd.cut(\n",
    "        users_profile_classes[col], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    "    )\n",
    "\n",
    "print(\"users: \", users_profile_classes.userid.nunique())\n",
    "users_profile_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = users_profile_classes.drop([\"userid\"], 1)\n",
    "print(X_transformed.shape)\n",
    "print(\"na in the dataset: \", X_transformed.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap' ></a>\n",
    "## Dimensionality reduction - UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "# main parameters: n_neighbors, min_dist, n_epochs, n_components\n",
    "# min_dist is important for the visualization. We can set min_dist = 0\n",
    "\n",
    "n_components = 2\n",
    "n_neighbors = 10\n",
    "umap_dr = umap.UMAP(\n",
    "    n_neighbors=n_neighbors, min_dist=0.0, n_components=n_components, random_state=42\n",
    ")\n",
    "\n",
    "# apply to data\n",
    "reduced_data_umap = pd.DataFrame(umap_dr.fit_transform(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = 1\n",
    "n_neighbors_lst = [10, 20, 60]\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 4))\n",
    "axes = axes.ravel()\n",
    "for i in range(len(n_neighbors_lst)):\n",
    "\n",
    "    standard_embedding = umap.UMAP(\n",
    "        random_state=42, n_neighbors=n_neighbors_lst[i], min_dist=0.0\n",
    "    ).fit_transform(X_transformed)\n",
    "\n",
    "    axes[i].scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.9)\n",
    "    axes[i].set_title(\"Neighbors: \" + str(n_neighbors_lst[i]))\n",
    "\n",
    "plt.savefig(\n",
    "    out_path + \"umap_neigh_dim\" + str(n_components) + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap_kmeans' ></a>\n",
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict_red_umap = {}\n",
    "metrics_dict = {\"distortion\", \"silhouette\", \"calinski_harabasz\"}\n",
    "for metric in metrics_dict:\n",
    "    kmeans_dict_red_umap[metric] = {}\n",
    "    kopt = clustering_functions.kmeans_elbow(reduced_data_umap, metric=metric)\n",
    "    kmeans_dict_red_umap[metric][\"kopt\"] = kopt\n",
    "    if kopt != None:\n",
    "\n",
    "        labels, centroids = clustering_functions.kmeans(kopt, reduced_data_umap)\n",
    "        kmeans_dict_red_umap[metric][\"kopt\"] = kopt\n",
    "        kmeans_dict_red_umap[metric][\"silhouette\"] = metrics.silhouette_score(\n",
    "            reduced_data_umap, labels\n",
    "        )\n",
    "        kmeans_dict_red_umap[metric][\n",
    "            \"calinski_harabasz\"\n",
    "        ] = metrics.calinski_harabasz_score(reduced_data_umap, labels)\n",
    "\n",
    "kmeans_dict_red_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### initialization\n",
    "k = 5\n",
    "method = \"kmeans\"\n",
    "\n",
    "\n",
    "labels, centroids = clustering_functions.kmeans(k, reduced_data_umap)\n",
    "\n",
    "all_data_clustered = users_profile.copy()\n",
    "all_data_clustered[\"cluster\"] = labels\n",
    "\n",
    "cluster_df_umap = reduced_data_umap.copy()\n",
    "cluster_df_umap.columns = [\"comp_1\", \"comp_2\"]\n",
    "cluster_df_umap[\"cluster\"] = labels\n",
    "\n",
    "print(\n",
    "    \"Silhouette score:\",\n",
    "    np.round(metrics.silhouette_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "print(\n",
    "    \"Calinski Harabasz score:\",\n",
    "    np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "\n",
    "## Save all data\n",
    "all_data_clustered.to_csv(\n",
    "    out_path\n",
    "    + \"data_for_matching_trips_umap_\"\n",
    "    + method\n",
    "    + \"_dim\"\n",
    "    + str(n_components)\n",
    "    + \"_neigh\"\n",
    "    + str(n_neighbors)\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### VISUALIZATION\n",
    "\n",
    "data_for_plot = all_data_clustered[[\"userid\", \"cluster\"]]\n",
    "data_for_plot.columns = [\"userid\", \"cluster\"]\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    cluster_df_umap, on=[cluster_df_umap.index, \"cluster\"]\n",
    ").iloc[:, 1:]\n",
    "\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    users_demographics[[\"userid\", \"gender\", \"age_range\"]], on=\"userid\", how=\"left\"\n",
    ")\n",
    "\n",
    "# data_for_plot.head()\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "f.subplots_adjust(top=0.9)\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"gender\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"age_range\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "\n",
    "# plt.suptitle(method)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.despine(left=True)\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \"_ALL.png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='umap_hier' ></a>\n",
    "### hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_umap.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_lst = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "affinity_lst = [\"euclidean\", \"manhattan\", \"cosine\"]\n",
    "# all comb\n",
    "all_comb = list(itertools.product(linkage_lst, affinity_lst))\n",
    "all_comb.remove((\"ward\", \"manhattan\"))\n",
    "all_comb.remove((\"ward\", \"cosine\"))\n",
    "\n",
    "rows_lst = []\n",
    "cols = [\"n_clusters\"]\n",
    "for comb in all_comb:\n",
    "    comb_name = comb[0] + \"_\" + comb[1]\n",
    "    cols.append(comb_name + \"_silhouette\")\n",
    "    cols.append(comb_name + \"_calinski_harabasz\")\n",
    "\n",
    "for k in range(2, 16):\n",
    "    # hier_dict['n_cluster_'+str(k)] = {}\n",
    "    row = [k]\n",
    "    for comb in all_comb:\n",
    "        comb_name = comb[0] + \"_\" + comb[1]\n",
    "\n",
    "        labels = clustering_functions.hierarchical(\n",
    "            reduced_data_umap, k, affinity=comb[1], linkage=comb[0]\n",
    "        )\n",
    "        row.append(np.round(metrics.silhouette_score(reduced_data_umap, labels), 2))\n",
    "        row.append(\n",
    "            np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2)\n",
    "        )\n",
    "\n",
    "    rows_lst.append(row)\n",
    "hier_df_red_umap = pd.DataFrame(rows_lst, columns=cols)\n",
    "hier_df_red_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier_df_red_umap.iloc[:, [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]].max()\n",
    "# hier_df_red_umap.iloc[:, [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='final' ></a>\n",
    "## FINAL hierarchical clustering with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hierarchical clustering with ward_euclidean and 5 clusters\n",
    "k = 5\n",
    "affinity = \"euclidean\"\n",
    "linkage = \"ward\"\n",
    "method = \"hierarchical\"\n",
    "\n",
    "labels = clustering_functions.hierarchical(\n",
    "    reduced_data_umap, k, affinity=affinity, linkage=linkage\n",
    ")\n",
    "# memorize in a df\n",
    "cluster_df_umap = reduced_data_umap.copy()\n",
    "cluster_df_umap.columns = [\"comp_1\", \"comp_2\"]\n",
    "cluster_df_umap[\"cluster\"] = labels\n",
    "\n",
    "# add labels to the complete dataset\n",
    "all_data_clustered = users_profile_classes.copy()\n",
    "all_data_clustered[\"cluster\"] = labels\n",
    "\n",
    "print(\n",
    "    \"Silhouette score:\",\n",
    "    np.round(metrics.silhouette_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "print(\n",
    "    \"Calinski Harabasz score:\",\n",
    "    np.round(metrics.calinski_harabasz_score(reduced_data_umap, labels), 2),\n",
    ")\n",
    "\n",
    "\n",
    "all_data_clustered.to_csv(\n",
    "    out_path\n",
    "    + \"data_for_matching_trips_umap_\"\n",
    "    + method\n",
    "    + \"_dim\"\n",
    "    + str(n_components)\n",
    "    + \"_neigh\"\n",
    "    + str(n_neighbors)\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZATION\n",
    "\n",
    "data_for_plot = all_data_clustered[[\"userid\", \"cluster\"]]\n",
    "data_for_plot.columns = [\"userid\", \"cluster\"]\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    cluster_df_umap, on=[cluster_df_umap.index, \"cluster\"]\n",
    ").iloc[:, 1:]\n",
    "\n",
    "data_for_plot = data_for_plot.merge(\n",
    "    users_demographics[[\"userid\", \"gender\", \"age_range\"]], on=\"userid\", how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "f.subplots_adjust(top=0.9)\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"gender\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    style=\"age_range\",\n",
    "    # palette=sns.color_palette(\"hls\", 5),\n",
    "    data=data_for_plot,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8,\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "\n",
    "# plt.suptitle(method)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    out_path\n",
    "    + \"plot_\"\n",
    "    + method\n",
    "    + \"_cl\"\n",
    "    + str(k)\n",
    "    + \"_neigh_\"\n",
    "    + str(n_neighbors)\n",
    "    + \".png\",\n",
    "    bbox_to_anchor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SUMMARY TABLES\n",
    "\n",
    "for c in range(0, len(all_data_clustered[\"cluster\"].unique())):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    print(\"Users in cluster\", c, \" : \", cl_df.shape[0])\n",
    "    print()\n",
    "    tmp = pd.DataFrame(\n",
    "        index=transp_cat,\n",
    "        columns=[\n",
    "            \"count\",\n",
    "            \"relfreq_tot\",\n",
    "            \"relfreq_tc\",\n",
    "            \"meanP\",\n",
    "            \"meanE\",\n",
    "            \"meanF\",\n",
    "            \"meanGenP\",\n",
    "            \"meanGenE\",\n",
    "            \"meanGenF\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    for i in transp_cat:  # for each transport category\n",
    "        users_with_tc = cl_df[\n",
    "            (cl_df[\"fit_\" + i] != 0)\n",
    "            | (cl_df[\"prod_\" + i] != 0)\n",
    "            | (cl_df[\"enj_\" + i] != 0)\n",
    "        ]\n",
    "\n",
    "        tmp.loc[i] = [\n",
    "            len(users_with_tc),\n",
    "            np.round(len(users_with_tc) / cl_df.shape[0], 2),\n",
    "            np.round(len(users_with_tc) / int(tc[\"count\"][tc.transp_category == i]), 2),\n",
    "            np.round(users_with_tc[\"prod_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"enj_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"fit_\" + i].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genProd\"].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genEnj\"].astype(\"float\").mean(), 2),\n",
    "            np.round(users_with_tc[\"genFit\"].astype(\"float\").mean(), 2),\n",
    "        ]\n",
    "\n",
    "    tmp.to_csv(\n",
    "        out_path + \"summary_table_onboarding_\" + method + \"_cl\" + str(c) + \"_mean.csv\"\n",
    "    )\n",
    "\n",
    "# example of summaty table\n",
    "# relfreq_tot: divided by total users in the cluster\n",
    "# relfreq_tc: divided by total of selection\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    out_path + \"summary_table_onboarding_\" + method + \"_cl\" + str(4) + \"_mean.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with user trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### read dataset of users for trip clustering\n",
    "\n",
    "users_profile_trips = pd.read_csv(input_path + \"users_profile_trips.csv\")\n",
    "print(users_profile_trips.shape)\n",
    "# convert in int\n",
    "for col in users_profile_trips.columns[1:]:\n",
    "    users_profile_trips[col] = users_profile_trips[col].apply(\n",
    "        lambda x: int(np.round(x))\n",
    "    )\n",
    "\n",
    "# convert in class 0-1-2 the generic values\n",
    "# with right=True the classes are (-2, 32], (32, 65], (66,100]\n",
    "users_profile_trips[\"genFit\"] = pd.cut(\n",
    "    users_profile_trips[\"genFit\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "users_profile_trips[\"genProd\"] = pd.cut(\n",
    "    users_profile_trips[\"genProd\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "users_profile_trips[\"genEnj\"] = pd.cut(\n",
    "    users_profile_trips[\"genEnj\"], [-2, 32, 65, 100], labels=[0, 1, 2], right=True\n",
    ")\n",
    "\n",
    "\n",
    "### add cluster from onBoarding data\n",
    "users_profile_trips = users_profile_trips.merge(\n",
    "    all_data_clustered[[\"userid\", \"cluster\"]], on=\"userid\"\n",
    ")\n",
    "\n",
    "# save for heatmaps on matching\n",
    "users_profile_trips.to_csv(out_path + \"users_profile_trips_matching.csv\", index=False)\n",
    "\n",
    "users_profile_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = 2\n",
    "names = [\n",
    "    \"Cycling and micro\",\n",
    "    \"Private motorized\",\n",
    "    \"Public long dist\",\n",
    "    \"Public short dist\",\n",
    "    \"Walking\",\n",
    "]\n",
    "namesx = [\"P\", \"E\", \"F\", \"GenP\", \"GenE\", \"GenF\"]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=(20, 10), sharex=True, sharey=True\n",
    ")\n",
    "axes = axes.ravel()\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "cbar_ax = fig.add_axes([0.91, 0.3, 0.03, 0.4])\n",
    "\n",
    "for i in range(ncols):\n",
    "\n",
    "    tmp = pd.read_csv(\n",
    "        out_path + \"summary_table_onboarding_hierarchical_cl\" + str(i) + \"_mean.csv\"\n",
    "    )\n",
    "    df_hm = tmp.iloc[:, -6:].astype(\"float\")\n",
    "\n",
    "    # if i == 4:\n",
    "    sns.heatmap(\n",
    "        df_hm,\n",
    "        ax=axes[i],\n",
    "        vmin=0,\n",
    "        vmax=1.9,\n",
    "        yticklabels=names,\n",
    "        xticklabels=\"\",\n",
    "        cbar=False,\n",
    "    )\n",
    "    # else:\n",
    "    #    sns.heatmap(df_hm, ax=axes[i], vmin=0, vmax=1.9, yticklabels=names, xticklabels='', cbar=False)\n",
    "\n",
    "\n",
    "for i in range(ncols):\n",
    "\n",
    "    tmp = (\n",
    "        users_profile_trips[users_profile_trips.cluster == i]\n",
    "        .mean()\n",
    "        .reset_index(name=\"tc_mean\")\n",
    "    )\n",
    "\n",
    "    row_lst = []\n",
    "    for c in range(len(transp_cat)):\n",
    "\n",
    "        row = list(tmp[\"tc_mean\"].iloc[[c, c + 5, c + 10]])\n",
    "        row_lst.append(row)\n",
    "\n",
    "    df_hm = pd.DataFrame(row_lst)\n",
    "    df_hm.columns = [\"meanP\", \"meanE\", \"meanF\"]\n",
    "    df_hm[\"genP\"] = [2] * 5\n",
    "    df_hm[\"genE\"] = [2] * 5\n",
    "    df_hm[\"genF\"] = [2] * 5\n",
    "    # tmp2 = pd.read_csv(out_path + \"summary_table_onboarding_hierarchical_cl\" + str(i) + \"_mean.csv\")\n",
    "    # tmp2 = tmp2.iloc[:, -3:].astype('float')\n",
    "    # df_hm = df_hm.merge(tmp2, on=tmp2.index)\n",
    "    # df_hm.drop('key_0', axis=1, inplace=True)\n",
    "\n",
    "    # if i == 4:\n",
    "    sns.heatmap(\n",
    "        df_hm,\n",
    "        ax=axes[i + 5],\n",
    "        vmin=0,\n",
    "        vmax=1.9,\n",
    "        yticklabels=names,\n",
    "        xticklabels=namesx,\n",
    "        cbar=False,\n",
    "    )\n",
    "    # else:\n",
    "    #    sns.heatmap(df_hm, ax=axes[i+5], vmin=0, vmax=1.9, yticklabels=names, xticklabels=namesx, cbar=False)\n",
    "\n",
    "\n",
    "# plt.savefig(input_path + \"heatmaps_users.png\", bbox_to_anchor=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1.9] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### Number of Transport Categories (TC) selected by each users\n",
    "# ex. cluster 0: users selected 4 or 5 TC as preferred\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "# hist\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=(17, 10), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "r = 0\n",
    "for c in range(0, ncols):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    transp_df_clust = spec_worthwhile[[\"userid\", \"transp_category\"]][\n",
    "        spec_worthwhile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    tmp = pd.DataFrame(transp_df_clust.groupby(\"userid\").count()[\"transp_category\"])\n",
    "    tmp2 = tmp.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "    axes[r][c].bar(tmp2[\"transp_category\"], tmp2[\"count\"])\n",
    "    axes[r][c].set_title(\"Number of TC - cluster \" + str(c), fontsize=14)\n",
    "    axes[r][c].set_xticks(range(1, len(transp_cat) + 1))\n",
    "    axes[r][c - ncols].tick_params(labelsize=13)\n",
    "\n",
    "r = 1\n",
    "for c in range(ncols, k):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"cluster\"] == c]\n",
    "    transp_df_clust = spec_worthwhile[[\"userid\", \"transp_category\"]][\n",
    "        spec_worthwhile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    tmp = pd.DataFrame(transp_df_clust.groupby(\"userid\").count()[\"transp_category\"])\n",
    "    tmp2 = tmp.groupby(\"transp_category\").size().reset_index(name=\"count\")\n",
    "    axes[r][c - ncols].bar(tmp2[\"transp_category\"], tmp2[\"count\"])\n",
    "    axes[r][c - ncols].set_title(\"Number of TC - cluster \" + str(c), fontsize=14)\n",
    "    axes[r][c - ncols].set_xticks(range(1, len(transp_cat) + 1))\n",
    "    axes[r][c - ncols].tick_params(labelsize=13)\n",
    "\n",
    "\n",
    "plt.savefig(out_path + \"tc_per_user_classes.png\", bbox_to_anchor=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Association Table\n",
    "# for each combination of transport mode, find how many users selected that combination\n",
    "\n",
    "all_comb_tr = [\n",
    "    (transp_cat[i], transp_cat[j])\n",
    "    for i in range(len(transp_cat))\n",
    "    for j in range(i, len(transp_cat))\n",
    "]\n",
    "\n",
    "for c in range(k):\n",
    "\n",
    "    cl_df = all_data_clustered[all_data_clustered[\"Hcluster_umap\"] == c]\n",
    "    transp_df_clust = spec_worthwhile[[\"userid\", \"transp_category\"]][\n",
    "        spec_worthwhile.userid.isin(list(cl_df.userid.unique()))\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        transp_df_clust.groupby([\"userid\", \"transp_category\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    basket = (\n",
    "        df.groupby([\"userid\", \"transp_category\"])[\"count\"]\n",
    "        .sum()\n",
    "        .unstack()\n",
    "        .reset_index()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    cont_table = pd.DataFrame(columns=transp_cat, index=transp_cat)\n",
    "    for comb in all_comb_tr:\n",
    "        cont_table.loc[comb[0], comb[1]] = len(\n",
    "            basket[(basket[comb[0]] == 1) & (basket[comb[1]] == 1)]\n",
    "        )\n",
    "        cont_table.loc[comb[1], comb[0]] = len(\n",
    "            basket[(basket[comb[0]] == 1) & (basket[comb[1]] == 1)]\n",
    "        )\n",
    "        # save\n",
    "        cont_table.to_csv(\n",
    "            out_path + \"transport_modes_associations_cl\" + str(c) + \".csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from scipy import optimize\n",
    "from scipy import spatial\n",
    "import copy\n",
    "import plotly.graph_objects as go\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input path and data\n",
    "# input_path = \"../../umap-data/\"\n",
    "\n",
    "input_path = \"../../2019-12-16.out/clustering/\"\n",
    "input_path_ob = \"../../2019-12-16.out/clustering/results_onBoarding/\"\n",
    "input_path_tr = \"../../2019-12-16.out/clustering/results_trips/\"\n",
    "\n",
    "cluster_onboard_file = (\n",
    "    \"results_onBoarding/data_for_matching_onBoarding_umap_hierarchical_dim2_neigh10.csv\"\n",
    ")\n",
    "cluster_trip_file = (\n",
    "    \"results_trips/data_for_matching_trips_umap_hierarchical_dim2_neigh60.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"userid\",\n",
    "    \"enj_cycling_emerging_micromobility\",\n",
    "    \"enj_private_motorized\",\n",
    "    \"enj_public_transp_long_dist\",\n",
    "    \"enj_public_transp_short_dist\",\n",
    "    \"enj_walking\",\n",
    "    \"fit_cycling_emerging_micromobility\",\n",
    "    \"fit_private_motorized\",\n",
    "    \"fit_public_transp_long_dist\",\n",
    "    \"fit_public_transp_short_dist\",\n",
    "    \"fit_walking\",\n",
    "    \"prod_cycling_emerging_micromobility\",\n",
    "    \"prod_private_motorized\",\n",
    "    \"prod_public_transp_long_dist\",\n",
    "    \"prod_public_transp_short_dist\",\n",
    "    \"prod_walking\",\n",
    "    \"genFit\",\n",
    "    \"genProd\",\n",
    "    \"genEnj\",\n",
    "    \"cluster\",\n",
    "]\n",
    "\n",
    "coltypes = {\n",
    "    \"userid\": \"str\",\n",
    "    \"enj_cycling_emerging_micromobility\": \"int\",\n",
    "    \"enj_private_motorized\": \"int\",\n",
    "    \"enj_public_transp_long_dist\": \"int\",\n",
    "    \"enj_public_transp_short_dist\": \"int\",\n",
    "    \"enj_walking\": \"int\",\n",
    "    \"fit_cycling_emerging_micromobility\": \"int\",\n",
    "    \"fit_private_motorized\": \"int\",\n",
    "    \"fit_public_transp_long_dist\": \"int\",\n",
    "    \"fit_public_transp_short_dist\": \"int\",\n",
    "    \"fit_walking\": \"int\",\n",
    "    \"prod_cycling_emerging_micromobility\": \"int\",\n",
    "    \"prod_private_motorized\": \"int\",\n",
    "    \"prod_public_transp_long_dist\": \"int\",\n",
    "    \"prod_public_transp_short_dist\": \"int\",\n",
    "    \"prod_walking\": \"int\",\n",
    "    \"genFit\": \"int\",\n",
    "    \"genProd\": \"int\",\n",
    "    \"genEnj\": \"int\",\n",
    "    \"cluster\": \"int\",\n",
    "}\n",
    "\n",
    "cluster_onboard_path = os.path.join(input_path, cluster_onboard_file)\n",
    "onboard_df = pd.read_csv(cluster_onboard_path, usecols=columns)\n",
    "onboard_df = onboard_df.astype(coltypes)\n",
    "\n",
    "cluster_trip_path = os.path.join(input_path, cluster_trip_file)\n",
    "trip_df = pd.read_csv(cluster_trip_path, usecols=columns)\n",
    "trip_df = trip_df.astype(coltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboard_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(onboard_df, trip_df, on=[\"userid\"], suffixes=(\"_ob\", \"_tr\"))\n",
    "print(merge_df.shape)\n",
    "merge_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check data\n",
    "merge_df.groupby(\"cluster_ob\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.groupby(\"cluster_tr\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df = merge_df[[\"userid\", \"cluster_ob\", \"cluster_tr\"]]\n",
    "# take the number of clusters\n",
    "ncluster_tr = common_df[\"cluster_tr\"].max() + 1\n",
    "ncluster_ob = common_df[\"cluster_ob\"].max() + 1\n",
    "\n",
    "common_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of the matrices of intersection and union with all zeros\n",
    "intersection = np.zeros((ncluster_ob, ncluster_tr))\n",
    "union = np.zeros((ncluster_ob, ncluster_tr))\n",
    "\n",
    "# fill the matrices with the number of users in common or in total\n",
    "for clob in range(ncluster_ob):\n",
    "    for cltr in range(ncluster_tr):\n",
    "        # intersection\n",
    "        rescell = \"ob{}_eq_tr{}\".format(clob, cltr)\n",
    "        common_df[rescell] = common_df.apply(\n",
    "            lambda x: 1 if (x[\"cluster_ob\"] == clob and x[\"cluster_tr\"] == cltr) else 0,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        count = common_df.loc[common_df[\"cluster_ob\"] == clob][rescell].sum()\n",
    "        intersection[clob][cltr] = -count\n",
    "        # print('({}, {}): {}'.format(clob, cltr, count))\n",
    "\n",
    "        # union\n",
    "        union[clob][cltr] = -len(\n",
    "            common_df[(common_df.cluster_ob == clob) | (common_df.cluster_tr == cltr)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = scipy.optimize.linear_sum_assignment(intersection)\n",
    "ob_match_tr_nusers = dict(zip(row_ind, col_ind))\n",
    "\n",
    "print(row_ind, col_ind)\n",
    "print(ob_match_tr_nusers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with symmetric difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmdiff = -(union - intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = scipy.optimize.linear_sum_assignment(symmdiff)\n",
    "ob_match_tr_symmdiff = dict(zip(row_ind, col_ind))\n",
    "\n",
    "print(row_ind, col_ind)\n",
    "print(ob_match_tr_symmdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = np.zeros((ncluster_ob, ncluster_tr))\n",
    "\n",
    "for clob in range(ncluster_ob):\n",
    "    for cltr in range(ncluster_tr):\n",
    "\n",
    "        jaccard[clob][cltr] = -intersection[clob][cltr] / union[clob][cltr]\n",
    "jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = scipy.optimize.linear_sum_assignment(jaccard)\n",
    "ob_match_tr_jaccard = dict(zip(row_ind, col_ind))\n",
    "\n",
    "print(row_ind, col_ind)\n",
    "print(ob_match_tr_nusers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find centroids for each cluster in ob and tr datasets\n",
    "# for each cluster the centroid is a vector of 18 elements\n",
    "# in which each element is the mean of the values of users in that cluster\n",
    "group_ob = onboard_df.groupby(\"cluster\", as_index=False).mean()\n",
    "group_tr = trip_df.groupby(\"cluster\", as_index=False).mean()\n",
    "group_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## initialize matrix of distances\n",
    "distances = np.zeros((ncluster_ob, ncluster_tr))\n",
    "\n",
    "# take useful cols\n",
    "finalcols = copy.deepcopy(columns)\n",
    "finalcols.remove(\"userid\")\n",
    "finalcols.remove(\"cluster\")\n",
    "\n",
    "\n",
    "for clob in range(ncluster_ob):\n",
    "    for cltr in range(ncluster_tr):\n",
    "\n",
    "        cluster_ob_coord = (\n",
    "            group_ob.loc[group_ob[\"cluster\"] == clob]\n",
    "            .drop(\"cluster\", axis=1)[finalcols]\n",
    "            .values.tolist()[0]\n",
    "        )\n",
    "        cluster_tr_coord = (\n",
    "            group_tr.loc[group_ob[\"cluster\"] == cltr]\n",
    "            .drop(\"cluster\", axis=1)[finalcols]\n",
    "            .values.tolist()[0]\n",
    "        )\n",
    "\n",
    "        dist = scipy.spatial.distance.euclidean(cluster_ob_coord, cluster_tr_coord)\n",
    "        distances[clob][cltr] = dist\n",
    "        print(\"({}, {}): {}\".format(clob, cltr, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = scipy.optimize.linear_sum_assignment(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = scipy.optimize.linear_sum_assignment(distances)\n",
    "ob_match_tr_distances = dict(zip(row_ind, col_ind))\n",
    "\n",
    "print(row_ind, col_ind)\n",
    "print(ob_match_tr_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/plotly/4-interactive-sankey-diagram-made-in-python-3057b9ee8616\n",
    "\n",
    "tmp = common_df.groupby([\"cluster_ob\", \"cluster_tr\"]).size().reset_index(name=\"values\")\n",
    "tmp[\"cluster_tr\"] = tmp[\"cluster_tr\"].apply(lambda x: x + 5)\n",
    "tmp[\"color\"] = [\n",
    "    \"paleturquoise\",\n",
    "    \"paleturquoise\",\n",
    "    \"paleturquoise\",\n",
    "    \"dodgerblue\",\n",
    "    \"paleturquoise\",\n",
    "    \"navajowhite\",\n",
    "    \"navajowhite\",\n",
    "    \"darkorange\",\n",
    "    \"navajowhite\",\n",
    "    \"navajowhite\",\n",
    "    \"forestgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"lightgreen\",\n",
    "    \"thistle\",\n",
    "    \"purple\",\n",
    "    \"thistle\",\n",
    "    \"thistle\",\n",
    "    \"thistle\",\n",
    "    \"mistyrose\",\n",
    "    \"mistyrose\",\n",
    "    \"mistyrose\",\n",
    "    \"mistyrose\",\n",
    "    \"firebrick\",\n",
    "]\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Sankey(\n",
    "            node=dict(\n",
    "                pad=15,\n",
    "                thickness=20,\n",
    "                line=dict(color=\"black\", width=0.5),\n",
    "                label=[\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"T1\", \"T2\", \"T3\", \"T4\", \"T5\"],\n",
    "                color=[\n",
    "                    \"dodgerblue\",\n",
    "                    \"darkorange\",\n",
    "                    \"forestgreen\",\n",
    "                    \"purple\",\n",
    "                    \"firebrick\",\n",
    "                    \"forestgreen\",\n",
    "                    \"purple\",\n",
    "                    \"darkorange\",\n",
    "                    \"dodgerblue\",\n",
    "                    \"firebrick\",\n",
    "                ],\n",
    "            ),\n",
    "            link=dict(\n",
    "                source=tmp.cluster_ob,  # indices correspond to labels, eg A1, A2, A2, B1, ...\n",
    "                target=tmp.cluster_tr,\n",
    "                value=tmp[\"values\"],\n",
    "                color=tmp[\"color\"],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500, width=500)\n",
    "\n",
    "fig.show()\n",
    "plt.savefig(input_path + \"alluvial.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_trace = dict(\n",
    "#     type=\"sankey\",\n",
    "#     domain=dict(x=[0, 1], y=[0, 1]),\n",
    "#     orientation=\"h\",\n",
    "#     valueformat=\".0f\",\n",
    "#     node=dict(\n",
    "#         pad=10,\n",
    "#         thickness=30,\n",
    "#         line=dict(color=\"black\", width=0),\n",
    "#         label=scottish_df[\"Node, Label\"].dropna(axis=0, how=\"any\"),\n",
    "#         color=scottish_df[\"Color\"],\n",
    "#     ),\n",
    "#     link=dict(\n",
    "#         source=scottish_df[\"Source\"].dropna(axis=0, how=\"any\"),\n",
    "#         target=scottish_df[\"Target\"].dropna(axis=0, how=\"any\"),\n",
    "#         value=scottish_df[\"Value\"].dropna(axis=0, how=\"any\"),\n",
    "#         color=scottish_df[\"Link Color\"].dropna(axis=0, how=\"any\"),\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# layout = dict(\n",
    "#     title=\"Scottish Referendum Voters who now want Independence\",\n",
    "#     height=772,\n",
    "#     font=dict(size=10),\n",
    "# )\n",
    "\n",
    "# fig = dict(data=[data_trace], layout=layout)\n",
    "# py.iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with centroids and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### visualization with centroids\n",
    "centroids_df = pd.concat([group_ob, group_tr], keys=\"cluster\").reset_index(drop=True)\n",
    "centroids_df[\"cluster\"] = centroids_df.index\n",
    "print(centroids_df.shape)\n",
    "\n",
    "X_transformed = centroids_df.drop(\"cluster\", axis=1)\n",
    "\n",
    "# UMAP\n",
    "import umap.umap_ as umap\n",
    "\n",
    "n_components = 2\n",
    "n_neighbors = 30\n",
    "umap_dr = umap.UMAP(\n",
    "    min_dist=0.0, n_components=n_components, random_state=42, n_neighbors=3\n",
    ")\n",
    "\n",
    "# apply to data\n",
    "reduced_data_umap = pd.DataFrame(\n",
    "    umap_dr.fit_transform(X_transformed), columns=[\"comp_1\", \"comp_2\"]\n",
    ")\n",
    "# reduced_data_umap['cluster'] = reduced_data_umap.index\n",
    "reduced_data_umap[\"cluster\"] = [0, 1, 2, 3, 4, 2, 3, 1, 0, 4]\n",
    "\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"comp_1\",\n",
    "    y=\"comp_2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=reduced_data_umap,\n",
    "    legend=\"full\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps\n",
    "\n",
    "Three HM:\n",
    "\n",
    "- Trips profile\n",
    "- Matching onboarding\n",
    "- Trips info of same users onboarding profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input_path_ob:\", input_path_ob)\n",
    "print(\"input_path:\", input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## read trips info of onboarding profiles\n",
    "users_profile_trips = pd.read_csv(input_path_ob + \"users_profile_trips_matching.csv\")\n",
    "\n",
    "ncols = 5\n",
    "nrows = 3\n",
    "names = [\n",
    "    \"Cycling and micro\",\n",
    "    \"Private motorized\",\n",
    "    \"Public long dist\",\n",
    "    \"Public short dist\",\n",
    "    \"Walking\",\n",
    "]\n",
    "namesx = [\"P\", \"E\", \"F\", \"GenP\", \"GenE\", \"GenF\"]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=(22, 10), sharex=True, sharey=True\n",
    ")\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "axes = axes.ravel()\n",
    "# cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "\n",
    "###### TRIP PROFILES\n",
    "for i in range(ncols):\n",
    "\n",
    "    cl = ob_match_tr_distances[i]\n",
    "    tmp = pd.read_csv(\n",
    "        input_path_tr + \"summary_table_trips_hierarchical_cl\" + str(cl) + \"_mean.csv\"\n",
    "    )\n",
    "    df_hm = tmp.iloc[:, -6:].astype(\"float\")\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_hm,\n",
    "        ax=axes[i],\n",
    "        vmin=0,\n",
    "        vmax=1.9,\n",
    "        yticklabels=names,\n",
    "        xticklabels=namesx,\n",
    "        cmap=\"coolwarm\",\n",
    "        cbar=False,\n",
    "    )\n",
    "\n",
    "\n",
    "###### ONBOARDING PROFILES\n",
    "for i in range(ncols):\n",
    "\n",
    "    tmp = pd.read_csv(\n",
    "        input_path_ob\n",
    "        + \"summary_table_onboarding_hierarchical_cl\"\n",
    "        + str(i)\n",
    "        + \"_mean.csv\"\n",
    "    )\n",
    "    df_hm = tmp.iloc[:, -6:].astype(\"float\")\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_hm,\n",
    "        ax=axes[i + 5],\n",
    "        vmin=0,\n",
    "        vmax=1.9,\n",
    "        yticklabels=names,\n",
    "        xticklabels=\"\",\n",
    "        cmap=\"coolwarm\",\n",
    "        cbar=False,\n",
    "    )\n",
    "\n",
    "\n",
    "###### TRIP PROFILES\n",
    "for i in range(ncols):\n",
    "\n",
    "    tmp = (\n",
    "        users_profile_trips[users_profile_trips.cluster == i]\n",
    "        .mean()\n",
    "        .reset_index(name=\"tc_mean\")\n",
    "    )\n",
    "    row_lst = []\n",
    "    for c in range(len(names)):\n",
    "\n",
    "        row = list(tmp[\"tc_mean\"].iloc[[c, c + 5, c + 10]])\n",
    "        row_lst.append(row)\n",
    "\n",
    "    df_hm = pd.DataFrame(row_lst)\n",
    "    df_hm.columns = [\"meanP\", \"meanE\", \"meanF\"]\n",
    "    df_hm[\"genP\"] = [1] * 5\n",
    "    df_hm[\"genE\"] = [1] * 5\n",
    "    df_hm[\"genF\"] = [1] * 5\n",
    "\n",
    "    im = sns.heatmap(\n",
    "        df_hm,\n",
    "        ax=axes[i + 10],\n",
    "        vmin=0,\n",
    "        vmax=1.9,\n",
    "        yticklabels=names,\n",
    "        xticklabels=namesx,\n",
    "        cmap=\"coolwarm\",\n",
    "        cbar=False,\n",
    "    )\n",
    "\n",
    "# Row and column headers in matplotlib's subplots\n",
    "# See:\n",
    "# https://stackoverflow.com/a/25814386/2377454\n",
    "axes[0].set_title(\"(B1, T4)\", size=\"xx-large\")\n",
    "axes[1].set_title(\"(B2, T3)\", size=\"xx-large\")\n",
    "axes[2].set_title(\"(B3, T1)\", size=\"xx-large\")\n",
    "axes[3].set_title(\"(B4, T2)\", size=\"xx-large\")\n",
    "axes[4].set_title(\"(B5, T5)\", size=\"xx-large\")\n",
    "\n",
    "axes[0].set_ylabel(\"Evaluation\", rotation=90, size=\"xx-large\")\n",
    "axes[5].set_ylabel(\"Onboarding\", rotation=90, size=\"xx-large\")\n",
    "axes[10].set_ylabel(\"User average\", rotation=90, size=\"xx-large\")\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "mappable = im.get_children()[0]\n",
    "plt.colorbar(mappable, orientation=\"vertical\")\n",
    "plt.savefig(\n",
    "    input_path + \"heatmaps_trips_onboarding_users.png\",\n",
    "    bbox_to_anchor=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = 2\n",
    "names = [\n",
    "    \"Cycling and micro\",\n",
    "    \"Private motorized\",\n",
    "    \"Public long dist\",\n",
    "    \"Public short dist\",\n",
    "    \"Walking\",\n",
    "]\n",
    "namesx = [\"P\", \"E\", \"F\", \"GenP\", \"GenE\", \"GenF\"]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=(20, 10), sharex=True, sharey=True\n",
    ")\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(ncols):\n",
    "\n",
    "    tmp = pd.read_csv(\n",
    "        input_path_ob\n",
    "        + \"summary_table_onboarding_hierarchical_cl\"\n",
    "        + str(i)\n",
    "        + \"_mean.csv\"\n",
    "    )\n",
    "    df_hm = tmp.iloc[:, -6:].astype(\"float\")\n",
    "\n",
    "    if i == 4:\n",
    "        sns.heatmap(\n",
    "            df_hm,\n",
    "            ax=axes[i],\n",
    "            vmin=0,\n",
    "            vmax=1.9,\n",
    "            yticklabels=names,\n",
    "            xticklabels=\"\",\n",
    "            cbar=True,\n",
    "        )\n",
    "    else:\n",
    "        sns.heatmap(\n",
    "            df_hm,\n",
    "            ax=axes[i],\n",
    "            vmin=0,\n",
    "            vmax=1.9,\n",
    "            yticklabels=names,\n",
    "            xticklabels=\"\",\n",
    "            cbar=False,\n",
    "        )\n",
    "\n",
    "\n",
    "for i in range(ncols):\n",
    "\n",
    "    cl = ob_match_tr_distances[i]\n",
    "    tmp = pd.read_csv(\n",
    "        input_path_tr + \"summary_table_trips_hierarchical_cl\" + str(cl) + \"_mean.csv\"\n",
    "    )\n",
    "    df_hm = tmp.iloc[:, -6:].astype(\"float\")\n",
    "\n",
    "    if i == 4:\n",
    "        sns.heatmap(\n",
    "            df_hm,\n",
    "            ax=axes[i + 5],\n",
    "            vmin=0,\n",
    "            vmax=1.9,\n",
    "            yticklabels=names,\n",
    "            xticklabels=namesx,\n",
    "            cbar=True,\n",
    "        )\n",
    "    else:\n",
    "        sns.heatmap(\n",
    "            df_hm,\n",
    "            ax=axes[i + 5],\n",
    "            vmin=0,\n",
    "            vmax=1.9,\n",
    "            yticklabels=names,\n",
    "            xticklabels=namesx,\n",
    "            cbar=False,\n",
    "        )\n",
    "\n",
    "    # sns.heatmap(df_hm, ax=axes[i+5], vmin=0, vmax=1.9)\n",
    "\n",
    "\n",
    "axes[0].set_title(\"B1 - T4\")\n",
    "axes[1].set_title(\"B2 - T3\")\n",
    "axes[2].set_title(\"B3 - T1\")\n",
    "axes[3].set_title(\"B4 - T2\")\n",
    "axes[4].set_title(\"B5 - T5\")\n",
    "\n",
    "plt.savefig(input_path + \"heatmaps.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "tmp_ob = tmp = pd.read_csv(\n",
    "    input_path_ob + \"summary_table_onboarding_hierarchical_cl\" + str(i) + \"_mean.csv\"\n",
    ")\n",
    "tmp_tr = tmp = pd.read_csv(\n",
    "    input_path_tr\n",
    "    + \"summary_table_trips_hierarchical_cl\"\n",
    "    + str(ob_match_tr_distances[i])\n",
    "    + \"_mean.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "## system libraries\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import bisect\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from datetime import date, datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "## numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "## plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# geo libraries\n",
    "import geopandas as gpd\n",
    "\n",
    "## module to read GeoTIF files\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "\n",
    "## special libraries\n",
    "from bson import json_util\n",
    "\n",
    "# reports\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebool options\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "rcParams[\"axes.titlepad\"] = 45\n",
    "rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "CUTTING_DATE = \"2019-05-01\"  # remove trips and data published before this date\n",
    "\n",
    "data_campaigns_path = os.path.join(\"../..\", \"data-campaigns/\")\n",
    "meta_data_path = os.path.join(data_campaigns_path, \"meta-data/\")\n",
    "shape_data = os.path.join(data_campaigns_path, \"shapefiles/\")\n",
    "gps_data = os.path.join(data_campaigns_path, \"2020-01-15.GPS/\")\n",
    "net_radition_data_path = os.path.join(data_campaigns_path, \"net-radiation/\")\n",
    "\n",
    "# preprocessed data\n",
    "input_path = os.path.join(\"../..\", \"2019-12-16.out/\")\n",
    "out_path = os.path.join(\"../..\", \"2019-12-16.out/\")\n",
    "\n",
    "# raw input data\n",
    "raw_data_path = os.path.join(data_campaigns_path, \"2019-10-30.all/\")\n",
    "raw_data_update_path = os.path.join(data_campaigns_path, \"2019-12-16.update/\")\n",
    "\n",
    "# weather data\n",
    "weather_dataset_path1 = os.path.join(\"../../data-campaigns/2019-10-25.weather\")\n",
    "weather_dataset_path2 = os.path.join(\"../../data-campaigns/2019-12-18.weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "trips_users = \"trips_users_df.pkl\"\n",
    "trips = \"trips_df.pkl\"\n",
    "\n",
    "# read datasets\n",
    "legs_df = pd.read_pickle(input_path + legs)\n",
    "trips_users_df = pd.read_pickle(input_path + trips_users)\n",
    "trips_df = pd.read_pickle(input_path + trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "legs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trips_users_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_bson_filename1 = \"weather.bson\"\n",
    "weather_data_filename1 = \"weather.json\"\n",
    "weather_data_bson_path1 = os.path.join(\n",
    "    weather_dataset_path1, weather_data_bson_filename1\n",
    ")\n",
    "weather_data_path1 = os.path.join(weather_dataset_path1, weather_data_filename1)\n",
    "\n",
    "print(weather_data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_bson_filename2 = \"weather.repr.bson\"\n",
    "weather_data_filename2 = \"weather.json\"\n",
    "weather_data_bson_path2 = os.path.join(\n",
    "    weather_dataset_path2, weather_data_bson_filename2\n",
    ")\n",
    "weather_data_path2 = os.path.join(weather_dataset_path2, weather_data_filename2)\n",
    "\n",
    "print(weather_data_bson_path2)\n",
    "print(weather_data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bson_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        bsondata = \"[\" + f.read() + \"]\"\n",
    "\n",
    "        data = json.loads(bsondata, object_hook=json_util.object_hook)\n",
    "\n",
    "        return json.loads(json_util.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from:\n",
    "# How can I use Python to transform MongoDB's bsondump into JSON?\n",
    "# https://stackoverflow.com/a/11886476/2377454\n",
    "def read_bson_repr_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        # read the entire input; in a real application,\n",
    "        # you would want to read a chunk at a time\n",
    "        bsondata = \"[\" + f.read() + \"]\"\n",
    "\n",
    "        # convert the TenGen JSON to Strict JSON\n",
    "        # here, I just convert the ObjectId and Date structures,\n",
    "        # but it's easy to extend to cover all structures listed at\n",
    "        # http://www.mongodb.org/display/DOCS/Mongo+Extended+JSON\n",
    "        jsondata = re.sub(\n",
    "            r\"ObjectId\\s*\\(\\s*\\\"(\\S+)\\\"\\s*\\)\", r'{\"$oid\": \"\\1\"}', bsondata\n",
    "        )\n",
    "        jsondata = re.sub(r\"Date\\s*\\(\\s*(\\S+)\\s*\\)\", r'{\"$date\": \\1}', jsondata)\n",
    "        jsondata = re.sub(\n",
    "            r\"NumberInt\\s*\\(\\s*(\\S+)\\s*\\)\", r'{\"$numberInt\": \"\\1\"}', jsondata\n",
    "        )\n",
    "\n",
    "        # now we can parse this as JSON, and use MongoDB's object_hook\n",
    "        # function to get rich Python data structures inside a dictionary\n",
    "        data = json.loads(jsondata, object_hook=json_util.object_hook)\n",
    "\n",
    "        return json.loads(json_util.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CLEAN_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_CLEAN_DATASET:\n",
    "    weather_data1 = read_bson_file(weather_data_bson_path1)\n",
    "    weather_clean_data1 = \"weather_clean.json\"\n",
    "    weather_clean_data_path1 = os.path.join(weather_dataset_path1, weather_clean_data1)\n",
    "\n",
    "    with open(weather_clean_data_path1, \"w+\") as outfp:\n",
    "        json.dump(weather_data1, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_CLEAN_DATASET:\n",
    "    weather_data2 = read_bson_repr_file(weather_data_bson_path2)\n",
    "\n",
    "    weather_clean_data2 = \"weather_clean.json\"\n",
    "    weather_clean_data_path2 = os.path.join(weather_dataset_path2, weather_clean_data2)\n",
    "\n",
    "    with open(weather_clean_data_path2, \"w+\") as outfp:\n",
    "        json.dump(weather_data2, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weather data 1:\", weather_data_path1)\n",
    "print(\"weather data 2:\", weather_data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df1 = pd.read_json(weather_data_path1, orient=\"records\")\n",
    "weather_df1.head(10)\n",
    "\n",
    "print(\"weather_df1: {}\".format(weather_df1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df2 = pd.read_json(weather_data_path2, orient=\"records\")\n",
    "weather_df2.head(10)\n",
    "\n",
    "print(\"weather_df2: {}\".format(weather_df2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_all_df = pd.concat([weather_df1, weather_df2])\n",
    "print(\"weather_all_df: {}\".format(weather_all_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_all_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(weather_all_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df = weather_all_df[[\"city\", \"requestTimestamp\"]].copy()\n",
    "\n",
    "# create colum id\n",
    "weather_parsed_df[\"id\"] = weather_all_df[\"_id\"].apply(lambda x: x.get(\"$oid\", None))\n",
    "\n",
    "weather_parsed_df[\"weather.dt\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x.get(\"dt\", None)\n",
    ")\n",
    "\n",
    "# weather main\n",
    "weather_parsed_df[\"weather.main.temp\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"temp\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.temp_min\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"temp_min\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.temp_max\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"temp_max\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.pressure\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"pressure\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.sea_level\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"sea_level\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.grnd_level\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"grnd_level\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.humidity\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"humidity\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.main.temp_kf\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"main\"].get(\"temp_kf\", None)\n",
    ")\n",
    "\n",
    "# weather weather\n",
    "# - weather_weather_id\n",
    "# - weather_weather_main\n",
    "# - weather_weather_description\n",
    "# - weather_weather_icon\n",
    "weather_parsed_df[\"weather.weather.id\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"weather\"][0].get(\"id\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.weather.main\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"weather\"][0].get(\"main\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.weather.description\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"weather\"][0].get(\"description\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.weather.icon\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"weather\"][0].get(\"icon\", None)\n",
    ")\n",
    "\n",
    "# weather clouds\n",
    "weather_parsed_df[\"weather.clouds.all\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"clouds\"].get(\"all\", None)\n",
    ")\n",
    "\n",
    "# weather wind\n",
    "weather_parsed_df[\"weather.wind.speed\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"wind\"].get(\"speed\", None)\n",
    ")\n",
    "weather_parsed_df[\"weather.wind.deg\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"wind\"].get(\"deg\", None)\n",
    ")\n",
    "\n",
    "# weather sys\n",
    "weather_parsed_df[\"weather.sys.pod\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x[\"sys\"].get(\"pod\", None)\n",
    ")\n",
    "\n",
    "# weather dt_tx\n",
    "weather_parsed_df[\"weather.dt_tx\"] = weather_all_df[\"weather\"].apply(\n",
    "    lambda x: x.get(\"dt_txt\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Number of weather records (w/ duplicates): {}\".format(weather_parsed_df.shape[0])\n",
    ")\n",
    "weather_parsed_df.drop_duplicates(subset=[\"id\"], keep=\"first\", inplace=True)\n",
    "print(\n",
    "    \"Number of weather records (no duplicates): {}\".format(weather_parsed_df.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_parsed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "new_weather_parsed_df = weather_parsed_df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"requestTimestamp\",\n",
    "        \"city\",\n",
    "        \"weather.dt\",\n",
    "        \"weather.main.temp\",\n",
    "        \"weather.main.temp_min\",\n",
    "        \"weather.main.temp_max\",\n",
    "        \"weather.main.pressure\",\n",
    "        \"weather.main.sea_level\",\n",
    "        \"weather.main.grnd_level\",\n",
    "        \"weather.main.humidity\",\n",
    "        \"weather.main.temp_kf\",\n",
    "        \"weather.weather.id\",\n",
    "        \"weather.weather.main\",\n",
    "        \"weather.weather.description\",\n",
    "        \"weather.weather.icon\",\n",
    "        \"weather.clouds.all\",\n",
    "        \"weather.wind.speed\",\n",
    "        \"weather.wind.deg\",\n",
    "        \"weather.sys.pod\",\n",
    "        \"weather.dt_tx\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df.to_pickle(out_path + \"weather_parsed_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_parsed_filename = \"weather_raw.csv\"\n",
    "new_weather_parsed_filename_path = out_path + new_weather_parsed_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_parsed_df.to_csv(new_weather_parsed_filename_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather scenario data\n",
    "\n",
    "1. neutral/good\n",
    "     - clouds: none or clear sky\n",
    "     - rain: none or light\n",
    "     - wind: light breeze\n",
    "     - temperature: comfortable temperature\n",
    "2. cold\n",
    "    - clouds: any\n",
    "    - rain: any\n",
    "    - wind: any\n",
    "    - temperature: cool\n",
    "\n",
    "3. warm\n",
    "    - clouds: any\n",
    "    - rain: any\n",
    "    - wind: any\n",
    "    - temperature: warm\n",
    "\n",
    "4. uncomfortable temperature\n",
    "    - clouds: any\n",
    "    - rain: any\n",
    "    - wind: any\n",
    "    - temperature: uncomfortably cold or uncomfortably hot\n",
    "\n",
    "5. rainy/snowy\n",
    "    - clouds: any\n",
    "    - rain: moderate or heavy\n",
    "    - wind: any\n",
    "    - temperature: cool\n",
    "\n",
    "6. cloudy\n",
    "    - clouds: partially cloudy or completely cloudy\n",
    "    - rain: any\n",
    "    - wind: any\n",
    "    - temperature: any\n",
    "\n",
    "7. windy\n",
    "    - clouds: any\n",
    "    - rain: any\n",
    "    - wind: strong breeze or gale\n",
    "    - temperature: any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of weather scenario metadata:\n",
    "\n",
    "```python\n",
    "weather_scenarios = \\\n",
    "{'neutral/good':\n",
    "  {'clouds': ['none', 'clear sky'],\n",
    "   'precipitation': ['none', 'light'],\n",
    "   'wind': ['light breeze'],\n",
    "   'temperature': ['comfortable']\n",
    "   },\n",
    " 'cold':\n",
    "  {'clouds': ['any'],\n",
    "   'precipitation': ['any'],\n",
    "   'wind': ['any'],\n",
    "   'temperature': ['cool']\n",
    "   },\n",
    " 'warm':\n",
    "  {'clouds': ['any'],\n",
    "   'precipitation': ['any'],\n",
    "   'wind': ['any'],\n",
    "   'temperature': ['warm']\n",
    "   },\n",
    " 'uncomfortable temperature':\n",
    "  {'clouds': ['any'],\n",
    "   'precipitation': ['any'],\n",
    "   'wind': ['any'],\n",
    "   'temperature': ['uncomfortably cold', 'uncomfortably hot']\n",
    "   },\n",
    " 'rainy/snowy':\n",
    "  {'clouds': ['any'],\n",
    "   'precipitation': ['moderate', 'heavy'],\n",
    "   'wind': ['any'],\n",
    "   'temperature': ['any']\n",
    "   },\n",
    " 'cloudy':\n",
    "  {'clouds': ['partially cloudy', 'completely cloudy'],\n",
    "   'precipitation': ['any'],\n",
    "   'wind': ['any'],\n",
    "   'temperature': ['any']\n",
    "   },\n",
    " 'windy':\n",
    "  {'clouds': ['any'],\n",
    "   'precipitation': ['any'],\n",
    "   'wind': ['strong breeze', 'gale'],\n",
    "   'temperature': ['any']\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `meta-data` to `weather_scenarios.json`:\n",
    "\n",
    "```python\n",
    "weather_scenarios_metadata_filename = 'weather_scenarios.json'\n",
    "weather_scenarios_metadata_path = os.path.join(meta_data_path, weather_scenarios_metadata_filename)\n",
    "with open(weather_scenarios_metadata_path, 'w+') as outfp:\n",
    "    json.dump(weather_scenarios, outfp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios = {\n",
    "    \"neutral/good\": {\n",
    "        \"clouds\": [\"none\", \"clear sky\"],\n",
    "        \"precipitation\": [\"none\", \"light\"],\n",
    "        \"wind\": [\"light breeze\"],\n",
    "        \"temperature\": [\"comfortable\"],\n",
    "    },\n",
    "    \"cold\": {\n",
    "        \"clouds\": [\"any\"],\n",
    "        \"precipitation\": [\"any\"],\n",
    "        \"wind\": [\"any\"],\n",
    "        \"temperature\": [\"cool\"],\n",
    "    },\n",
    "    \"warm\": {\n",
    "        \"clouds\": [\"any\"],\n",
    "        \"precipitation\": [\"any\"],\n",
    "        \"wind\": [\"any\"],\n",
    "        \"temperature\": [\"warm\"],\n",
    "    },\n",
    "    \"uncomfortable temperature\": {\n",
    "        \"clouds\": [\"any\"],\n",
    "        \"precipitation\": [\"any\"],\n",
    "        \"wind\": [\"any\"],\n",
    "        \"temperature\": [\"uncomfortably cold\", \"uncomfortably hot\"],\n",
    "    },\n",
    "    \"rainy/snowy\": {\n",
    "        \"clouds\": [\"any\"],\n",
    "        \"precipitation\": [\"moderate\", \"heavy\"],\n",
    "        \"wind\": [\"any\"],\n",
    "        \"temperature\": [\"any\"],\n",
    "    },\n",
    "    \"cloudy\": {\n",
    "        \"clouds\": [\"partially cloudy\", \"completely cloudy\"],\n",
    "        \"precipitation\": [\"any\"],\n",
    "        \"wind\": [\"any\"],\n",
    "        \"temperature\": [\"any\"],\n",
    "    },\n",
    "    \"windy\": {\n",
    "        \"clouds\": [\"any\"],\n",
    "        \"precipitation\": [\"any\"],\n",
    "        \"wind\": [\"strong breeze\", \"gale\"],\n",
    "        \"temperature\": [\"any\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "weather_scenarios_metadata_filename = \"weather_scenarios.json\"\n",
    "weather_scenarios_metadata_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_metadata_filename\n",
    ")\n",
    "with open(weather_scenarios_metadata_path, \"w+\") as outfp:\n",
    "    json.dump(weather_scenarios, outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of cloud metadata:\n",
    "\n",
    "```python\n",
    "weather_scenarios_clouds = \\\n",
    "{'clear sky': {'category': 'clear sky',\n",
    "               'main': 'clear'\n",
    "               },\n",
    " 'few clouds': {'category': 'partially cloudy',\n",
    "                'main': 'clear'\n",
    "                },\n",
    " 'scattered clouds': {'category': 'partially cloudy',\n",
    "                      'main': 'clouds'\n",
    "                      },\n",
    " 'broken clouds': {'category': 'partially cloudy',\n",
    "                   'main': 'clouds'\n",
    "                   },\n",
    " 'overcast clouds': {'category': 'completely cloudy',\n",
    "                     'main': 'clouds'\n",
    "                     }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `meta-data` to `weather_scenarios_clouds.json`:\n",
    "\n",
    "```python\n",
    "weather_scenarios_clouds_filename = 'weather_scenarios_clouds.json'\n",
    "weather_scenarios_clouds_path = os.path.join(meta_data_path, weather_scenarios_clouds_filename )\n",
    "with open(weather_scenarios_clouds_path, 'w+') as outfp:\n",
    "    json.dump(weather_scenarios_clouds, outfp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of precipitation metadata:\n",
    "\n",
    "```python\n",
    "weather_scenarios_precipitation = \\\n",
    "{'light rain': {'category': 'light',\n",
    "                'main': 'rain'\n",
    "                },\n",
    " 'moderate rain': {'category': 'moderate',\n",
    "                   'main': 'rain'\n",
    "                   },\n",
    " 'heavy intensity rain': {'category': 'heavy',\n",
    "                          'main': 'rain'\n",
    "                          },\n",
    " 'light snow': {'category': 'light',\n",
    "                'main': 'snow'\n",
    "                },\n",
    " 'snow': {'category': 'heavy',\n",
    "          'main': 'snow'\n",
    "          }\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `meta-data` to `weather_scenarios_precipitation.json`:\n",
    "\n",
    "```python\n",
    "weather_scenarios_precipitation_filename = 'weather_scenarios_precipitation.json'\n",
    "weather_scenarios_precipitation_path = os.path.join(meta_data_path, weather_scenarios_precipitation_filename )\n",
    "with open(weather_scenarios_precipitation_path, 'w+') as outfp:\n",
    "    json.dump(weather_scenarios_precipitation, outfp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of wind metadata:\n",
    "\n",
    "```python\n",
    "weather_scenarios_wind = \\\n",
    "{'calm': {'category': 'light breeze',\n",
    "          'speed': [0, 0.5],\n",
    "          'beaufort number': 0,\n",
    "          },\n",
    " 'light air': {'category': 'light breeze',\n",
    "               'speed': [0.5, 1.5],\n",
    "               'beaufort number': 1,\n",
    "               },\n",
    " 'light breeze': {'category': 'light breeze',\n",
    "                  'speed': [1.5, 3.3],\n",
    "                  'beaufort number': 2,\n",
    "                  },\n",
    " 'gentle breeze': {'category': 'light breeze',\n",
    "                   'speed': [3.3, 5.5],\n",
    "                   'beaufort number': 3,\n",
    "                   },\n",
    " 'moderate breeze': {'category': 'strong breeze',\n",
    "                     'speed': [5.5, 7.9],\n",
    "                     'beaufort number': 4,\n",
    "                     },\n",
    " 'fresh breeze': {'category': 'strong breeze',\n",
    "                  'speed': [7.9, 10.7],\n",
    "                  'beaufort number': 5,\n",
    "                  },\n",
    " 'strong breeze': {'category': 'strong breeze',\n",
    "                   'speed': [10.7, 13.8],\n",
    "                   'beaufort number': 6,\n",
    "                   },\n",
    " 'high wind': {'category': 'gale',\n",
    "               'speed': [13.8, 17.1],\n",
    "               'beaufort number': 7,\n",
    "               },\n",
    " 'gale': {'category': 'gale',\n",
    "          'speed': [17.1, 20.7],\n",
    "          'beaufort number': 8,\n",
    "          },\n",
    " 'strong/severe gale': {'category': 'gale',\n",
    "                        'speed': [20.7, 24.4],\n",
    "                        'beaufort number': 9,\n",
    "                        },\n",
    " 'storm': {'category': 'gale',\n",
    "           'speed': [24.4, 28.4],\n",
    "           'beaufort number': 10,\n",
    "           },\n",
    " 'violent storm': {'category': 'gale',\n",
    "                   'speed': [28.4, 32.6],\n",
    "                   'beaufort number': 11,\n",
    "                   },\n",
    " 'hurricane force': {'category': 'gale',\n",
    "                     'speed': [32.6, 50],\n",
    "                     'beaufort number': 12,\n",
    "                     }\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `meta-data` to `weather_scenarios_wind.json`:\n",
    "\n",
    "```python\n",
    "weather_scenarios_wind_filename = 'weather_scenarios_wind.json'\n",
    "weather_scenarios_wind_path = os.path.join(meta_data_path, weather_scenarios_wind_filename )\n",
    "with open(weather_scenarios_wind_path, 'w+') as outfp:\n",
    "    json.dump(weather_scenarios_wind, outfp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature and Apparent Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparent temperature (AT) is the temperature equivalent perceived by humans, caused by the combined effects of air temperature, relative humidity and wind speed. Apparent Temperature was invented by Robert Steadman and it was published in 1984. It takes into consideration four environmental factors: wind, temperature, humidity and radiation from the sun.\n",
    "\n",
    "The formula for the AT is:\n",
    "$$AT = T_a + 0.348 \\cdot e - 0.70 \\cdot ws + 0.70\\frac{Q}{ws+10}- 4.25$$\n",
    "\n",
    "where:\n",
    "- $Ta =$ Dry bulb temperature (°C)\n",
    "- $e =$ Water vapour pressure (hPa) (humidity)\n",
    "- $ws =$ Wind speed (m/s) at an elevation of 10 meters\n",
    "- $Q =$ Net radiation absorbed per unit area of body surface (W/m2)\n",
    "\n",
    "$E$ is computed like this\n",
    "$$e=\\frac{rh}{100} \\cdot 6.105 \\cdot e^{\\frac{17.27 \\cdot T_a}{237.7 + T_a}}$$\n",
    "\n",
    "where:\n",
    "- $rh =$ Relative Humidity (%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water vapour pressure\n",
    "# e=\\frac{rh}{100}*6.105*e^{\\frac{17.27*T_a}{237.7+T_a}}\n",
    "def water_vapour_pressure(rh, Ta):\n",
    "    return (rh / 100.0) * 6.105 * math.exp((17.27 * Ta) / (237.7 + Ta))\n",
    "\n",
    "\n",
    "# apparent temperature\n",
    "# AT=T_a+0.348*e-0.70*ws+0.70\\frac{Q}{ws+10}-4.25\n",
    "def apparent_temperature(rh, Ta, ws, Q):\n",
    "    e = water_vapour_pressure(rh, Ta)\n",
    "\n",
    "    return Ta + 0.348 * e - 0.70 * ws + 0.70 * (Q / (ws + 10.0)) - 4.25\n",
    "\n",
    "\n",
    "# get_net_radiation_wrap = lambda row: get_net_radiation(row.time, row.centroid_x, row.centroid_y)\n",
    "apparent_temperature_wrap = lambda row: apparent_temperature(\n",
    "    row.rh, row.Ta, row.ws, row.Q\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of apparent temperature metadata:\n",
    "\n",
    "```python\n",
    "weather_scenarios_apparent_temperature = \\\n",
    "{\n",
    "  \"uncomfortably cold\": {\n",
    "    \"main\": \"uncomfortable temperature\",\n",
    "    \"range\": [-273.15, 0.0],\n",
    "  },\n",
    "  \"cool\": {\n",
    "    \"main\": \"comfortable temperature\",\n",
    "    \"range\": [0.0, 15.0],\n",
    "  },\n",
    "  \"comfortable\": {\n",
    "    \"main\": \"comfortable temperature\",\n",
    "    \"range\": [15.0, 25.0],\n",
    "  },\n",
    "  \"warm\": {\n",
    "    \"main\": \"comfortable temperature\",\n",
    "    \"range\": [25.0, 32.0],\n",
    "  },\n",
    "  \"uncomfortably hot\": {\n",
    "    \"main\": \"uncomfortable temperature\",\n",
    "    \"range\": [32.0, 100.0],\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to `meta-data` to `weather_scenarios_apparent_temperature.json`:\n",
    "\n",
    "```python\n",
    "weather_scenarios_apparent_temperature_filename = 'weather_scenarios_apparent_temperature.json'\n",
    "weather_scenarios_apparent_temperature_path = os.path.join(meta_data_path, weather_scenarios_apparent_temperature_filename )\n",
    "with open(weather_scenarios_apparent_temperature_path, 'w+') as outfp:\n",
    "    json.dump(weather_scenarios_apparent_temperature, outfp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_metadata_filename = \"weather_scenarios.json\"\n",
    "weather_scenarios_metadata_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_metadata_filename\n",
    ")\n",
    "with open(weather_scenarios_metadata_path, \"r\") as infp:\n",
    "    weather_scenarios = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weather_parsed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_clouds_filename = \"weather_scenarios_clouds.json\"\n",
    "weather_scenarios_clouds_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_clouds_filename\n",
    ")\n",
    "\n",
    "with open(weather_scenarios_clouds_path, \"r\") as infp:\n",
    "    weather_scenarios_clouds = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_clouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_precipitation_filename = \"weather_scenarios_precipitation.json\"\n",
    "weather_scenarios_precipitation_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_precipitation_filename\n",
    ")\n",
    "\n",
    "with open(weather_scenarios_precipitation_path, \"r\") as infp:\n",
    "    weather_scenarios_precipitation = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_precipitation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_wind_filename = \"weather_scenarios_wind.json\"\n",
    "weather_scenarios_wind_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_wind_filename\n",
    ")\n",
    "\n",
    "with open(weather_scenarios_wind_path, \"r\") as infp:\n",
    "    weather_scenarios_wind = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature and Apparent Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_apparent_temperature_filename = (\n",
    "    \"weather_scenarios_apparent_temperature.json\"\n",
    ")\n",
    "weather_scenarios_apparent_temperature_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_apparent_temperature_filename\n",
    ")\n",
    "\n",
    "with open(weather_scenarios_apparent_temperature_path, \"r\") as infp:\n",
    "    weather_scenarios_apparent_temperature = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_apparent_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[[\"weather.weather.main\", \"id\"]].groupby(\n",
    "    \"weather.weather.main\", as_index=False\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[[\"weather.weather.description\", \"id\"]].groupby(\n",
    "    \"weather.weather.description\", as_index=False\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.clouds.all\"].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.wind.speed\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.wind.deg\"].hist(bins=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.main.temp\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.main.temp_min\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.main.temp_max\"].hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.main.temp_kf\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df[\"weather.main.humidity\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Apparent Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_df_all = pd.read_pickle(input_path + \"shapes_df_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapes_df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_cities = pd.read_pickle(input_path + \"gps_cities.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_cities.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read net radiation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NASA - NEO: NASA Earth Observatory**\n",
    "\n",
    "* [NASA NEO](https://neo.sci.gsfc.nasa.gov/)\n",
    "  * Dataset description: [Net radiation data](https://neo.sci.gsfc.nasa.gov/view.php?datasetId=CERES_NETFLUX_D&date=2019-12-01),\n",
    "  * Data-like File Formats: [CSV and floating point GeoTIFFs description](https://neo.sci.gsfc.nasa.gov/blog/2013/12/23/csv-and-floating-point-geotiffs/)\n",
    "  * [Bulk data download](https://neo.sci.gsfc.nasa.gov/about/bulk.php)\n",
    "    * [FTP](https://neo.sci.gsfc.nasa.gov/archive/geotiff.float/CERES_NETFLUX_D/) ([README.txt](https://neo.sci.gsfc.nasa.gov/archive/geotiff.float/README.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_radiation_filename = \"CERES_NETFLUX_D_2019-04-08.FLOAT.TIFF\"\n",
    "net_radition_tiff_path = os.path.join(net_radition_data_path, net_radiation_filename)\n",
    "\n",
    "print(net_radition_tiff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_REGEX = re.compile(r\"CERES_NETFLUX_D_(.+)\\.FLOAT\\.TIFF\")\n",
    "\n",
    "\n",
    "def tiff_get_date(tiff_filename):\n",
    "    file_file_basename = os.path.basename(tiff_filename)\n",
    "    tiff_date_str = DATE_REGEX.match(file_file_basename).group(1)\n",
    "    tiff_date = datetime.strptime(tiff_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    return tiff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_files = glob(net_radition_data_path + \"CERES_NETFLUX_D_*.FLOAT.TIFF\")\n",
    "\n",
    "parsed_tiff_files = {}\n",
    "for tiff_file in sorted(tiff_files):\n",
    "    tiff_date = tiff_get_date(tiff_file)\n",
    "    tiff_date_str = tiff_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    dataset = None\n",
    "    with rasterio.open(net_radition_tiff_path) as dataset:\n",
    "\n",
    "        # Read the dataset's valid data mask as a ndarray.\n",
    "        mask = dataset.dataset_mask()\n",
    "\n",
    "        # Extract feature shapes and values from the array.\n",
    "        for geom, val in rasterio.features.shapes(mask, transform=dataset.transform):\n",
    "\n",
    "            # Transform shapes from the dataset's own coordinate\n",
    "            # reference system to CRS84 (EPSG:4326).\n",
    "            geom = rasterio.warp.transform_geom(\n",
    "                dataset.crs, \"EPSG:4326\", geom, precision=6\n",
    "            )\n",
    "\n",
    "            # Print GeoJSON shapes to stdout.\n",
    "            # print(geom)\n",
    "\n",
    "        parsed_tiff_files[tiff_date_str] = {\n",
    "            \"band1\": dataset.read(1),\n",
    "            \"index\": dataset.index,\n",
    "        }\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "# Find the closest Key in dictionary\n",
    "# https://www.geeksforgeeks.org/python-find-the-closest-key-in-dictionary/\n",
    "\n",
    "\n",
    "def get_closest_key(mydict, key):\n",
    "    res = mydict.get(key, None)\n",
    "    if res is None:\n",
    "        dict_keys = sorted([datetime.strptime(k, \"%Y-%m-%d\") for k in mydict.keys()])\n",
    "\n",
    "    while res is None:\n",
    "        residx = bisect.bisect_left(dict_keys, datetime.strptime(key, \"%Y-%m-%d\"))\n",
    "\n",
    "        if residx < 0:\n",
    "            residx = 0\n",
    "        elif residx >= len(dict_keys):\n",
    "            residx = len(dict_keys) - 1\n",
    "\n",
    "        reskey = dict_keys[residx]\n",
    "        res = mydict[reskey.strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* '2018-12-31' is None:\", parsed_tiff_files.get(\"2018-12-31\", None) is None)\n",
    "print(\"* '2019-12-17' is None:\", parsed_tiff_files.get(\"2019-12-17\", None) is None)\n",
    "print(\"* '2019-12-18' is None:\", parsed_tiff_files.get(\"2019-12-18\", None) is None)\n",
    "print(\"* '2019-12-29' is None:\", parsed_tiff_files.get(\"2019-12-29\", None) is None)\n",
    "print(\"* '2019-12-30' is None:\", parsed_tiff_files.get(\"2019-12-30\", None) is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"* '2018-12-31' == '2019-01-01': \",\n",
    "    (\n",
    "        (\n",
    "            get_closest_key(parsed_tiff_files, \"2018-12-31\").get(\"band1\", None)\n",
    "            is not None\n",
    "        )\n",
    "        and (\n",
    "            get_closest_key(parsed_tiff_files, \"2018-12-31\").get(\"band1\", None)\n",
    "            == parsed_tiff_files.get(\"2019-01-01\", None).get(\"band1\", None)\n",
    "        ).all()\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"* '2019-12-18' == '2019-12-17': \",\n",
    "    (\n",
    "        (\n",
    "            get_closest_key(parsed_tiff_files, \"2019-12-18\").get(\"band1\", None)\n",
    "            is not None\n",
    "        )\n",
    "        and (\n",
    "            get_closest_key(parsed_tiff_files, \"2019-12-18\").get(\"band1\", None)\n",
    "            == parsed_tiff_files.get(\"2019-12-17\", None).get(\"band1\", None)\n",
    "        ).all()\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"* '2019-12-30' == '2019-12-17': \",\n",
    "    (\n",
    "        (\n",
    "            get_closest_key(parsed_tiff_files, \"2019-12-18\").get(\"band1\", None)\n",
    "            is not None\n",
    "        )\n",
    "        and (\n",
    "            get_closest_key(parsed_tiff_files, \"2019-12-30\").get(\"band1\")\n",
    "            == parsed_tiff_files.get(\"2019-12-17\", None).get(\"band1\", None)\n",
    "        ).all()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "example_tiff_dataset = parsed_tiff_files[\"2019-01-01\"]\n",
    "\n",
    "# x, y = -64.6861800, 10.1362500\n",
    "y, x = 0, 0\n",
    "row, col = example_tiff_dataset[\"index\"](x, y)\n",
    "example_tiff_dataset[\"band1\"][row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_parsed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cities = list(weather_parsed_df[\"city\"].unique())\n",
    "print(\"Number of distinct cities:\", len(weather_cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mail from André \"MoTiV - base de dados sobre temperatura ambiente\" on Thu, 19 Mar 2020 14:51:23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesPRT = [\"Lisbon\", \"Porto\"]\n",
    "citiesSVK = [\n",
    "    \"Žilina\",\n",
    "    \"Bratislava\",\n",
    "    \"Trnava\",\n",
    "    \"Nitra\",\n",
    "    \"Trenčín\",\n",
    "    \"Banská Bystrica\",\n",
    "    \"Košice\",\n",
    "    \"Prešov\",\n",
    "]\n",
    "citiesFIN = [\"Helsinki\", \"Tampere\", \"Turku\", \"Oulu\", \"Etelä-Suomi\"]\n",
    "citiesESP = [\"Barcelona\", \"Girona\", \"Tarragona\", \"Lleida\"]\n",
    "citiesBEL = [\"Antwerp\", \"Brugge\", \"Brussels\", \"Gent\", \"Leuven\"]\n",
    "citiesCHE = [\n",
    "    \"Lausanne\",\n",
    "    \"Genève\",\n",
    "    \"Montreux\",\n",
    "    \"Fribourg\",\n",
    "    \"Bern\",\n",
    "    \"Basel\",\n",
    "    \"Zurich\",\n",
    "    \"Neuchâtel\",\n",
    "    \"Yverdon-les-Bains\",\n",
    "]\n",
    "citiesITA = [\"Milan\"]\n",
    "citiesFRA = [\n",
    "    \"Paris\",\n",
    "    \"Lyon\",\n",
    "    \"Grenoble\",\n",
    "    \"Nevers\",\n",
    "    \"Nantes\",\n",
    "    \"Bordeaux\",\n",
    "    \"Toulouse\",\n",
    "    \"Strasbourg\",\n",
    "    \"Amiens\",\n",
    "    \"Angers\",\n",
    "    \"Lille\",\n",
    "    \"Brest\",\n",
    "    \"Marseille\",\n",
    "    \"Saint Brieuc\",\n",
    "    \"Montpellier\",\n",
    "]\n",
    "citiesNOR = [\n",
    "    \"Oslo\",\n",
    "    \"Bergen\",\n",
    "    \"Trondheim\",\n",
    "    \"Stavager\",\n",
    "    \"Drammen\",\n",
    "    \"Fredrikstad\",\n",
    "    \"Porsgrunn\",\n",
    "    \"Skien\",\n",
    "    \"Kristiansand\",\n",
    "    \"Ålesund\",\n",
    "    \"Tønsberg\",\n",
    "]\n",
    "citiesHRV = [\n",
    "    \"Zagreb\",\n",
    "    \"Velika Gorica\",\n",
    "    \"Samobor\",\n",
    "    \"Zaprešić\",\n",
    "    \"Dugo selo\",\n",
    "    \"Zagrebačka županija\",\n",
    "    \"Split\",\n",
    "    \"Rijeka\",\n",
    "    \"Osijek\",\n",
    "    \"Varaždin\",\n",
    "    \"Zadar\",\n",
    "]\n",
    "\n",
    "mail_cities_lists = [\n",
    "    citiesPRT,\n",
    "    citiesSVK,\n",
    "    citiesFIN,\n",
    "    citiesESP,\n",
    "    citiesBEL,\n",
    "    citiesCHE,\n",
    "    citiesITA,\n",
    "    citiesFRA,\n",
    "    citiesNOR,\n",
    "    citiesHRV,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_all_cities = flatten(mail_cities_lists)\n",
    "print(\"Number of distinct cities:\", len(mail_all_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weather_cities-mail_all_cities:\", set(weather_cities) - set(mail_all_cities))\n",
    "print(\"mail_all_cities-weather_cities:\", set(mail_all_cities) - set(weather_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_parsed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date = weather_parsed_df[[\"id\", \"city\", \"weather.dt_tx\"]].copy()\n",
    "\n",
    "weather_city_date[\"date\"] = weather_city_date[\"weather.dt_tx\"].apply(lambda x: x[:10])\n",
    "weather_city_date.drop([\"weather.dt_tx\"], axis=1, inplace=True)\n",
    "weather_city_date.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"weather_city_date.shape:\", weather_city_date.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_city_date.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date.groupby(\"city\").agg({\"date\": [np.min, np.max]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_city_centroid = shapes_df_all[\n",
    "    [\"fuaname\", \"fuaname_en\", \"iso3\", \"centroid_x\", \"centroid_y\"]\n",
    "].copy()\n",
    "shapes_city_centroid.columns = [\n",
    "    \"city\",\n",
    "    \"city_en\",\n",
    "    \"country\",\n",
    "    \"centroid_x\",\n",
    "    \"centroid_y\",\n",
    "]\n",
    "\n",
    "print(\"shapes_city_centroid.shape:\", shapes_city_centroid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_cities = (\n",
    "#     set(weather_cities)\n",
    "#     - set(shapes_city_centroid.city.values)\n",
    "#     - set(shapes_city_centroid.city_en.values)\n",
    "# )\n",
    "# print(\"Number of missing cities:\", len(missing_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1_df = pd.merge(\n",
    "    weather_city_date,\n",
    "    shapes_city_centroid,\n",
    "    left_on=\"city\",\n",
    "    right_on=\"city\",\n",
    "    how=\"left\",\n",
    ")\n",
    "tmp1_df.drop([\"city_en\"], axis=1, inplace=True)\n",
    "\n",
    "tmp2_df = pd.merge(\n",
    "    weather_city_date,\n",
    "    shapes_city_centroid,\n",
    "    left_on=\"city\",\n",
    "    right_on=\"city_en\",\n",
    "    how=\"left\",\n",
    ")\n",
    "tmp2_df.drop([\"city_y\", \"city_en\"], axis=1, inplace=True)\n",
    "\n",
    "# rename columns in tmp2_df\n",
    "tmp2_df.columns = tmp1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid = pd.concat([tmp1_df, tmp2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to drop duplicates but keep the rows if a particular other column is not null (Pandas)\n",
    "# See:\n",
    "# https://stackoverflow.com/a/56852739/2377454\n",
    "weather_city_date_centroid = weather_city_date_centroid.sort_values(\n",
    "    by=[\"id\", \"country\"], na_position=\"last\"\n",
    ").drop_duplicates(\"id\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid[\n",
    "    weather_city_date_centroid[\"id\"] == \"5d23820c5c15650738bafbfa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weather_city_date_centroid.shape:\", weather_city_date_centroid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some cities we don't have coordinates and they have 'country', 'centroid_x', 'centroid_y' set to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_city_date_centroid[weather_city_date_centroid[\"country\"].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_radiation(date, x, y):\n",
    "    val = 0\n",
    "\n",
    "    if (not pd.isnull(x)) and (not pd.isnull(y)):\n",
    "        tiff = get_closest_key(parsed_tiff_files, date)\n",
    "\n",
    "        row, col = tiff[\"index\"](x, y)\n",
    "        val = tiff[\"band1\"][row, col]\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "get_net_radiation_wrap = lambda row: get_net_radiation(\n",
    "    row.date, row.centroid_x, row.centroid_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid[\n",
    "    weather_city_date_centroid[\"id\"] == \"5d2382c05c15650738bafc0e\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_net_radiation(\"2019-07-08\", 2.094905, 41.439964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid[\n",
    "    weather_city_date_centroid[\"id\"] == \"5d2382c05c15650738bafc0e\"\n",
    "][[\"date\", \"centroid_x\", \"centroid_y\"]].apply(get_net_radiation_wrap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid[\"net_radiation\"] = weather_city_date_centroid[\n",
    "    [\"date\", \"centroid_x\", \"centroid_y\"]\n",
    "].apply(get_net_radiation_wrap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_city_date_centroid[weather_city_date_centroid[\"country\"].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_netradiation_df = weather_parsed_df.merge(\n",
    "    weather_city_date_centroid, on=[\"id\", \"city\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_netradiation_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_data_df = weather_netradiation_df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"weather.main.humidity\",\n",
    "        \"weather.main.temp\",\n",
    "        \"weather.wind.speed\",\n",
    "        \"net_radiation\",\n",
    "    ]\n",
    "].copy()\n",
    "at_data_df.columns = [\"id\", \"rh\", \"Ta\", \"ws\", \"Q\"]\n",
    "at_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apparent_temperature(rh, Ta, ws, Q):\n",
    "at_data_df[\"apparent_temperature\"] = at_data_df[[\"id\", \"rh\", \"Ta\", \"ws\", \"Q\"]].apply(\n",
    "    apparent_temperature_wrap, axis=1\n",
    ")\n",
    "\n",
    "at_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_final = at_data_df[[\"id\", \"apparent_temperature\"]].merge(\n",
    "    weather_netradiation_df, on=[\"id\"]\n",
    ")\n",
    "\n",
    "tmp_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df = tmp_final[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"requestTimestamp\",\n",
    "        \"city\",\n",
    "        \"centroid_x\",\n",
    "        \"centroid_y\",\n",
    "        \"country\",\n",
    "        \"weather.dt\",\n",
    "        \"weather.dt_tx\",\n",
    "        \"date\",\n",
    "        \"weather.main.temp\",\n",
    "        \"weather.main.temp_min\",\n",
    "        \"weather.main.temp_max\",\n",
    "        \"weather.main.temp_kf\",\n",
    "        \"weather.main.pressure\",\n",
    "        \"weather.main.sea_level\",\n",
    "        \"weather.main.grnd_level\",\n",
    "        \"weather.main.humidity\",\n",
    "        \"weather.weather.id\",\n",
    "        \"weather.weather.main\",\n",
    "        \"weather.weather.description\",\n",
    "        \"weather.weather.icon\",\n",
    "        \"weather.clouds.all\",\n",
    "        \"weather.wind.speed\",\n",
    "        \"weather.wind.deg\",\n",
    "        \"weather.sys.pod\",\n",
    "        \"apparent_temperature\",\n",
    "        \"net_radiation\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "weather_final_df.columns = [\n",
    "    \"id\",\n",
    "    \"request_timestamp\",\n",
    "    \"city\",\n",
    "    \"centroid_x\",\n",
    "    \"centroid_y\",\n",
    "    \"country\",\n",
    "    \"timestamp_seconds\",\n",
    "    \"timestamp_string\",\n",
    "    \"date\",\n",
    "    \"temp\",\n",
    "    \"temp_min\",\n",
    "    \"temp_max\",\n",
    "    \"temp_kf\",\n",
    "    \"pressure\",\n",
    "    \"sea_level\",\n",
    "    \"grnd_level\",\n",
    "    \"humidity\",\n",
    "    \"weather_id\",\n",
    "    \"weather_main\",\n",
    "    \"weather_description\",\n",
    "    \"weather_icon\",\n",
    "    \"clouds_all\",\n",
    "    \"wind_speed\",\n",
    "    \"wind_deg\",\n",
    "    \"sys_pod\",\n",
    "    \"apparent_temperature\",\n",
    "    \"net_radiation\",\n",
    "]\n",
    "\n",
    "weather_final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df.id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect weather scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cloud_category(description):\n",
    "\n",
    "    key = description.lower()\n",
    "    cloud_category = None\n",
    "    cloud_main = None\n",
    "    if weather_scenarios_clouds.get(key, None) is not None:\n",
    "        cloud_category = weather_scenarios_clouds[key][\"category\"]\n",
    "        cloud_main = weather_scenarios_clouds[key][\"main\"]\n",
    "\n",
    "    return cloud_category, cloud_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking function return into pandas dataframe columns\n",
    "# See:\n",
    "# https://stackoverflow.com/a/43009150/2377454\n",
    "weather_final_df[\"cloud_category\"], weather_final_df[\"cloud_main\"] = zip(\n",
    "    *weather_final_df[\"weather_description\"].apply(map_cloud_category)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_final_df[[\"weather_description\", \"cloud_category\", \"cloud_main\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_precipitation_category(description):\n",
    "\n",
    "    key = description.lower()\n",
    "    precipitation_category = None\n",
    "    precipitation_main = None\n",
    "    if weather_scenarios_precipitation.get(key, None) is not None:\n",
    "        precipitation_category = weather_scenarios_precipitation[key][\"category\"]\n",
    "        precipitation_main = weather_scenarios_precipitation[key][\"main\"]\n",
    "\n",
    "    return precipitation_category, precipitation_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking function return into pandas dataframe columns\n",
    "# See:\n",
    "# https://stackoverflow.com/a/43009150/2377454\n",
    "(\n",
    "    weather_final_df[\"precipitation_category\"],\n",
    "    weather_final_df[\"precipitation_main\"],\n",
    ") = zip(*weather_final_df[\"weather_description\"].apply(map_precipitation_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\n",
    "    [\"weather_description\", \"precipitation_category\", \"precipitation_main\"]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speeds = [\n",
    "    v_min\n",
    "    for (v_min, v_max) in [\n",
    "        weather_scenarios_wind[k][\"speed\"] for k in weather_scenarios_wind.keys()\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(\"wind_speeds:\", wind_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wind_ranges = {\n",
    "    weather_scenarios_wind[k][\"speed\"][0]: {\n",
    "        \"beaufort number\": weather_scenarios_wind[k][\"beaufort number\"],\n",
    "        \"description\": k,\n",
    "        \"category\": weather_scenarios_wind[k][\"category\"],\n",
    "    }\n",
    "    for k in weather_scenarios_wind.keys()\n",
    "}\n",
    "\n",
    "\n",
    "weather_scenarios_wind_ranges = OrderedDict()\n",
    "for v in wind_speeds:\n",
    "    weather_scenarios_wind_ranges[v] = tmp_wind_ranges[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_wind_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wind_speeds:\", wind_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given boundaries, find interval\n",
    "# See:\n",
    "# https://stackoverflow.com/a/13942715/2377454\n",
    "def map_wind_category(wind_speed):\n",
    "\n",
    "    if wind_speed <= 0:\n",
    "        wind_speed = 0\n",
    "\n",
    "    wind_speed_corrected = [float(v - 0.001) for v in wind_speeds]\n",
    "\n",
    "    pos = bisect.bisect_left(wind_speed_corrected, wind_speed)\n",
    "\n",
    "    # since we start from zero, we need to shift by 1\n",
    "    pos = pos - 1\n",
    "\n",
    "    if pos >= len(wind_speed_corrected):\n",
    "        pos = len(wind_speed_corrected) - 1\n",
    "    elif pos <= 0:\n",
    "        pos = 0\n",
    "\n",
    "    key = wind_speeds[pos]\n",
    "    # print('key: {}, pos: {}'.format(key, pos))\n",
    "\n",
    "    wind_category = None\n",
    "    wind_description = None\n",
    "    wind_beaufort_number = None\n",
    "    if weather_scenarios_wind_ranges.get(key, None) is not None:\n",
    "        wind_category = weather_scenarios_wind_ranges[key][\"category\"]\n",
    "        wind_description = weather_scenarios_wind_ranges[key][\"description\"]\n",
    "        wind_beaufort_number = weather_scenarios_wind_ranges[key][\"beaufort number\"]\n",
    "\n",
    "    return wind_category, wind_description, wind_beaufort_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in np.arange(0, 33, 0.1):\n",
    "    cat, desc, num = map_wind_category(v)\n",
    "    print(\n",
    "        \"map_wind_category({}) -> (cat: {}, desc: {}, num: {})\".format(\n",
    "            v, cat, desc, num\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\"wind_speed\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weather_final_df[\"wind_category\"],\n",
    "    weather_final_df[\"wind_description\"],\n",
    "    weather_final_df[\"wind_beaufort_number\"],\n",
    ") = zip(*weather_final_df[\"wind_speed\"].apply(map_wind_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_final_df[\n",
    "    [\"wind_speed\", \"wind_category\", \"wind_description\", \"wind_beaufort_number\"]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_apparent_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_ranges = [\n",
    "    t_min\n",
    "    for (t_min, t_max) in [\n",
    "        weather_scenarios_apparent_temperature[k][\"range\"]\n",
    "        for k in weather_scenarios_apparent_temperature.keys()\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(\"temperature_ranges:\", temperature_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_temperature_ranges = {\n",
    "    weather_scenarios_apparent_temperature[k][\"range\"][0]: {\n",
    "        \"category\": k,\n",
    "        \"main\": weather_scenarios_apparent_temperature[k][\"main\"],\n",
    "    }\n",
    "    for k in weather_scenarios_apparent_temperature.keys()\n",
    "}\n",
    "\n",
    "\n",
    "weather_scenarios_apparent_temperature_ranges = OrderedDict()\n",
    "for t in temperature_ranges:\n",
    "    weather_scenarios_apparent_temperature_ranges[t] = tmp_temperature_ranges[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios_apparent_temperature_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_temperature_category(temperature):\n",
    "\n",
    "    temperature_ranges_corrected = [float(t - 0.001) for t in temperature_ranges]\n",
    "\n",
    "    pos = bisect.bisect_left(temperature_ranges_corrected, temperature)\n",
    "\n",
    "    # since we start from zero, we need to shift by 1\n",
    "    pos = pos - 1\n",
    "\n",
    "    if pos >= len(temperature_ranges_corrected):\n",
    "        pos = len(temperature_ranges_corrected) - 1\n",
    "    elif pos <= 0:\n",
    "        pos = 0\n",
    "\n",
    "    key = temperature_ranges[pos]\n",
    "    # print('key: {}, pos: {}'.format(key, pos))\n",
    "\n",
    "    temperature_category = None\n",
    "    temperature_main = None\n",
    "    if weather_scenarios_apparent_temperature_ranges.get(key, None) is not None:\n",
    "        temperature_category = weather_scenarios_apparent_temperature_ranges[key][\n",
    "            \"category\"\n",
    "        ]\n",
    "        temperature_main = weather_scenarios_apparent_temperature_ranges[key][\"main\"]\n",
    "\n",
    "    return temperature_category, temperature_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(-10, 40, 2):\n",
    "    cat, main = map_temperature_category(t)\n",
    "    print(\"map_temperature_category({}) -> (cat: {}, desc: {})\".format(t, cat, main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\"apparent_temperature\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weather_final_df[\"temperature_category\"],\n",
    "    weather_final_df[\"temperature_description\"],\n",
    ") = zip(*weather_final_df[\"apparent_temperature\"].apply(map_temperature_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\n",
    "    [\"apparent_temperature\", \"temperature_category\", \"temperature_description\"]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\n",
    "    [\n",
    "        \"cloud_category\",\n",
    "        \"precipitation_category\",\n",
    "        \"temperature_category\",\n",
    "        \"temperature_description\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes two arguments:\n",
    "#   * weather_characteristic: one of clouds, rain, wind, or temperature\n",
    "#   * weather_condition: the condition for that weather characteristics\n",
    "# return the matching scenarios\n",
    "def match_scenarios(weather_characteristic, weather_condition):\n",
    "\n",
    "    wcond = weather_condition\n",
    "    if weather_condition is None:\n",
    "        wcond = \"none\"\n",
    "    wcond = wcond.lower()\n",
    "\n",
    "    matching_scenarios = set()\n",
    "    for scenario, weather_dict in weather_scenarios.items():\n",
    "        if \"any\" in map(\n",
    "            str.lower, weather_dict[weather_characteristic]\n",
    "        ) or wcond in map(str.lower, weather_dict[weather_characteristic]):\n",
    "\n",
    "            matching_scenarios.add(scenario)\n",
    "\n",
    "    return matching_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"clouds\", \"clear sky\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"clouds\", None)\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"clouds\", \"completely cloudy\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"clouds\", \"partially cloudy\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"precipitation\", \"light\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"precipitation\", None)\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"precipitation\", \"moderate\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"precipitation\", \"heavy\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"wind\", None)\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"wind\", \"light breeze\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"wind\", \"strong breeze\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"wind\", \"gale\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"temperature\", \"comfortable\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"temperature\", \"cool\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"temperature\", \"warmºa\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))\n",
    "args = (\"temperature\", \"uncomfortably cold\")\n",
    "print(\"{} is {} -> {}\".format(*args, match_scenarios(*args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_weather_scenarios(clouds, precipitation, wind, temperature):\n",
    "    match_clouds = match_scenarios(\"clouds\", clouds)\n",
    "    match_precipitation = match_scenarios(\"precipitation\", precipitation)\n",
    "    match_wind = match_scenarios(\"wind\", wind)\n",
    "    match_temperature = match_scenarios(\"temperature\", temperature)\n",
    "\n",
    "    match_scenario = set.intersection(\n",
    "        match_clouds, match_precipitation, match_wind, match_temperature\n",
    "    )\n",
    "\n",
    "    scenario = list()\n",
    "    if len(match_scenario) >= 1:\n",
    "        scenario = sorted(match_scenario)\n",
    "\n",
    "    return scenario\n",
    "\n",
    "\n",
    "# map_weather_scenarios = lambda row: map_weather_scenarios(louds, precipitation, wind, temperature)\n",
    "map_weather_scenarios_wrap = lambda row: map_weather_scenarios(\n",
    "    row.cloud_category,\n",
    "    row.precipitation_category,\n",
    "    row.wind_category,\n",
    "    row.temperature_category,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"clear sky\", None, \"light breeze\", \"comfortable\")\n",
    "print(map_weather_scenarios(*args))\n",
    "args = (\"clear sky\", None, \"gale\", \"comfortable\")\n",
    "print(map_weather_scenarios(*args))\n",
    "args = (\"partially cloudy\", None, \"light breeze\", \"comfortable\")\n",
    "print(map_weather_scenarios(*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\"weather_scenario\"] = weather_final_df[\n",
    "    [\n",
    "        \"cloud_category\",\n",
    "        \"precipitation_category\",\n",
    "        \"wind_category\",\n",
    "        \"temperature_category\",\n",
    "    ]\n",
    "].apply(map_weather_scenarios_wrap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[\n",
    "    [\n",
    "        \"cloud_category\",\n",
    "        \"precipitation_category\",\n",
    "        \"wind_category\",\n",
    "        \"temperature_category\",\n",
    "        \"weather_scenario\",\n",
    "    ]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = weather_final_df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"cloud_category\",\n",
    "        \"precipitation_category\",\n",
    "        \"wind_category\",\n",
    "        \"temperature_category\",\n",
    "        \"weather_scenario\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "tmp[\"weather_scenario_count\"] = tmp[\"weather_scenario\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.groupby(\"weather_scenario_count\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc[tmp[\"weather_scenario_count\"] == 1].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df.to_pickle(out_path + \"weather_final_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Weather to Legs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_df[[\"legid\", \"city\", \"startDate\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_df[[\"id\", \"city\", \"timestamp_seconds\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid = (\n",
    "    legs_df[[\"legid\", \"city\", \"startDate\"]].merge(weather_final_df[[\"id\", \"city\"]])[\n",
    "        [\"id\", \"legid\", \"city\", \"startDate\"]\n",
    "    ]\n",
    ").copy()\n",
    "weather_id_legid.columns = [\"id\", \"legid\", \"city\", \"start_leg_ms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_id_legid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_id_legid.groupby(\"city\").count()[[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid[\"start_leg_seconds\"] = weather_id_legid[\"start_leg_ms\"].apply(\n",
    "    lambda x: int(round(int(x) / 1000.0, 0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_timestamps_array = np.asarray(\n",
    "    sorted(set(weather_final_df[\"timestamp_seconds\"].to_list()))\n",
    ")\n",
    "print(\"len(all_timestamps_array):\", len(all_timestamps_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "all_weather_cities = sorted(set(weather_final_df[\"city\"].values))\n",
    "\n",
    "timestamps_per_city_array = dict()\n",
    "\n",
    "for city in all_weather_cities:\n",
    "    city_timestamp_list = weather_final_df.loc[weather_final_df[\"city\"] == city][\n",
    "        \"timestamp_seconds\"\n",
    "    ].to_list()\n",
    "    city_timestamp_array = np.asarray(sorted(set(city_timestamp_list)))\n",
    "\n",
    "    # print('{} -> {}'.format(city, len(city_timestamp_array)))\n",
    "    timestamps_per_city_array[city] = city_timestamp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_IN_SECONDS = 86400\n",
    "DIFFLIMIT = 1 * DAY_IN_SECONDS\n",
    "\n",
    "# Find nearest value in numpy array\n",
    "# https://stackoverflow.com/a/2566508/2377454\n",
    "#\n",
    "# Calculate differences between timestamp and available values for a given city\n",
    "# bound them to be at most 1 day.\n",
    "# If no value is available return NaN.\n",
    "#\n",
    "def find_city_nearest_time(city, ts):\n",
    "    tsarray = timestamps_per_city_array[city]\n",
    "\n",
    "    diffarray = np.abs(tsarray - ts)\n",
    "    diffarray = diffarray[np.where(diffarray <= DIFFLIMIT)]\n",
    "\n",
    "    res = np.nan\n",
    "    if diffarray.size > 0:\n",
    "        idx = diffarray.argmin()\n",
    "        res = tsarray[idx]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# find_city_nearest_time_wrap = lambda row: find_city_nearest_time(city, ts)\n",
    "find_city_nearest_time_wrap = lambda row: find_city_nearest_time(\n",
    "    row.city, row.start_leg_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid[[\"city\", \"start_leg_seconds\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_city_nearest_time(\"Brussels\", 1557239471)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = (\n",
    "    weather_id_legid[[\"city\", \"start_leg_seconds\"]][1000:2000]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test.apply(find_city_nearest_time_wrap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid[\"start_leg_closest_seconds\"] = weather_id_legid[\n",
    "    [\"city\", \"start_leg_seconds\"]\n",
    "].apply(find_city_nearest_time_wrap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"start_leg_ms\" in weather_id_legid.columns:\n",
    "    weather_id_legid.drop([\"start_leg_ms\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weather_id_legid[[\"id\", \"start_leg_seconds\", \"start_leg_closest_seconds\"]]\n",
    "    .groupby([\"start_leg_seconds\", \"start_leg_closest_seconds\"])\n",
    "    .count()\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_id_legid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas join on columns with different names\n",
    "# See:\n",
    "#   https://stackoverflow.com/a/40570281/2377454\n",
    "#\n",
    "# ```\n",
    "# pd.merge(df1, df2, left_on=  ['userid', 'column1'],\n",
    "#                    right_on= ['username', 'column1'],\n",
    "#                    how= 'left')\n",
    "# ```\n",
    "\n",
    "tmp_weather_with_legs_df = pd.merge(\n",
    "    left=weather_id_legid,\n",
    "    right=weather_final_df,\n",
    "    left_on=[\"id\", \"city\", \"start_leg_closest_seconds\"],\n",
    "    right_on=[\"id\", \"city\", \"timestamp_seconds\"],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_weather_with_legs_df = tmp_weather_with_legs_df.rename({\"id\": \"weather_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_weather_with_legs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "missing_legids = set(weather_id_legid.legid.values) - set(\n",
    "    tmp_weather_with_legs_df.legid.values\n",
    ")\n",
    "print(\"# of missing legids:\", len(missing_legids))\n",
    "\n",
    "missing_legids = set(legs_df.legid.values) - set(tmp_weather_with_legs_df.legid.values)\n",
    "print(\"# of missing legids with respect to legs_df:\", len(missing_legids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"tmp_weather_with_legs_df-weather_final_df:\",\n",
    "    set(tmp_weather_with_legs_df.columns) - set(weather_final_df.columns),\n",
    ")\n",
    "print(\n",
    "    \"weather_final_df-tmp_weather_with_legs_df:\",\n",
    "    set(weather_final_df.columns) - set(tmp_weather_with_legs_df.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\"legid\"] + list(weather_final_df.columns)\n",
    "\n",
    "tmp_weather_with_legs_df[new_columns].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\n",
    "    \"id\",\n",
    "    \"legid\",\n",
    "    \"request_timestamp\",\n",
    "    \"city\",\n",
    "    \"centroid_x\",\n",
    "    \"centroid_y\",\n",
    "    \"country\",\n",
    "    \"timestamp_seconds\",\n",
    "    \"timestamp_string\",\n",
    "    \"date\",\n",
    "    \"weather_id\",\n",
    "    \"weather_scenario\",\n",
    "    \"weather_main\",\n",
    "    \"weather_description\",\n",
    "    \"weather_icon\",\n",
    "    \"temp\",\n",
    "    \"temp_min\",\n",
    "    \"temp_max\",\n",
    "    \"temp_kf\",\n",
    "    \"apparent_temperature\",\n",
    "    \"net_radiation\",\n",
    "    \"temperature_category\",\n",
    "    \"temperature_description\",\n",
    "    \"pressure\",\n",
    "    \"sea_level\",\n",
    "    \"grnd_level\",\n",
    "    \"humidity\",\n",
    "    \"clouds_all\",\n",
    "    \"cloud_category\",\n",
    "    \"cloud_main\",\n",
    "    \"precipitation_category\",\n",
    "    \"precipitation_main\",\n",
    "    \"wind_speed\",\n",
    "    \"wind_deg\",\n",
    "    \"wind_beaufort_number\",\n",
    "    \"wind_category\",\n",
    "    \"wind_description\",\n",
    "    \"sys_pod\",\n",
    "]\n",
    "\n",
    "\n",
    "weather_final_with_legs_df = tmp_weather_with_legs_df[new_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_with_legs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_final_with_legs_df.to_pickle(out_path + \"weather_final_with_legs_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

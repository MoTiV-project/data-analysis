{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost\n",
    "\n",
    "**Tutorial:** https://catboost.ai/docs/concepts/tutorials.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import itertools\n",
    "from pandas.io.json import json_normalize\n",
    "import sklearn.metrics as metrics\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from matplotlib import rcParams\n",
    "import json\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))\n",
    "\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "input_path = \"../../2019-12-16.out/\"\n",
    "out_path = \"../../2019-12-16.out/WI_results/\"\n",
    "\n",
    "# Graphical parameters\n",
    "rcParams[\"axes.titlepad\"] = 45\n",
    "rcParams[\"font.size\"] = 16\n",
    "rcParams[\"figure.figsize\"] = 12, 8\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### all_legs ####\n",
    "\n",
    "all_legs = pd.read_pickle(input_path + legs)\n",
    "\n",
    "# remove \"unknown\" as transport category (?)\n",
    "all_legs = all_legs[all_legs.transp_category != \"Unknown\"]\n",
    "\n",
    "# select only useful wasted time\n",
    "all_legs = all_legs[(all_legs.wastedTime > 0) & (all_legs.wastedTime < 6)]\n",
    "# convert to int\n",
    "all_legs[\"wastedTime\"] = all_legs[\"wastedTime\"].apply(lambda x: np.round(x))\n",
    "\n",
    "# country - assign 'CHE' to the class Other (AAA)\n",
    "all_legs[\"onCampaigns\"] = all_legs[\"onCampaigns\"].apply(\n",
    "    lambda x: \"AAA\" if x == \"CHE\" else x\n",
    ")\n",
    "top10 = list(all_legs.onCampaigns.unique())\n",
    "\n",
    "\n",
    "#### values_from_trip ####\n",
    "values_from_trip = pd.read_pickle(input_path + \"values_from_trip.pkl\")\n",
    "\n",
    "\n",
    "# add info\n",
    "values_from_trip = values_from_trip.merge(\n",
    "    all_legs[\n",
    "        [\n",
    "            \"legid\",\n",
    "            \"wastedTime\",\n",
    "            \"userid\",\n",
    "            \"gender\",\n",
    "            \"onCampaigns\",\n",
    "            \"age\",\n",
    "            \"transp_category\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"legid\",\n",
    ").drop_duplicates()\n",
    "\n",
    "values_from_trip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. wt ~ E + P + F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = values_from_trip[[\"legid\", \"value\", \"valueFromTrip\"]].drop_duplicates()\n",
    "values_from_trip_pivot = pd.pivot(\n",
    "    data=tmp, index=\"legid\", columns=\"valueFromTrip\", values=\"value\"\n",
    ").reset_index()\n",
    "# add transport category and userid\n",
    "values_from_trip_pivot = values_from_trip_pivot.merge(\n",
    "    all_legs[[\"legid\", \"userid\", \"transp_category\", \"wastedTime\"]], on=\"legid\"\n",
    ").drop_duplicates()\n",
    "# Merge Paid_work and Personal_tasks into Productivity taking the **maximum** value\n",
    "values_from_trip_pivot[\"Productivity\"] = values_from_trip_pivot[\n",
    "    [\"Paid_work\", \"Personal_tasks\"]\n",
    "].max(axis=1)\n",
    "\n",
    "values_from_trip_pivot.drop([\"Paid_work\", \"Personal_tasks\"], axis=1, inplace=True)\n",
    "\n",
    "## select columns\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    [\"Enjoyment\", \"Productivity\", \"Fitness\", \"wastedTime\"]\n",
    "]  # , 'transp_category']]\n",
    "\n",
    "# remove legs with missing values in E+P+F\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    ~(\n",
    "        (values_from_trip_pivot.Enjoyment.isnull())\n",
    "        & (values_from_trip_pivot.Productivity.isnull())\n",
    "        & (values_from_trip_pivot.Fitness.isnull())\n",
    "    )\n",
    "]\n",
    "# remove legs with null tc\n",
    "# values_from_trip_pivot = values_from_trip_pivot[~ values_from_trip_pivot.transp_category.isnull()]\n",
    "\n",
    "# convert E P F into int values\n",
    "values_from_trip_pivot[\"Enjoyment\"] = values_from_trip_pivot[\"Enjoyment\"].astype(np.int)\n",
    "values_from_trip_pivot[\"Productivity\"] = values_from_trip_pivot[\"Productivity\"].astype(\n",
    "    np.int\n",
    ")\n",
    "values_from_trip_pivot[\"Fitness\"] = values_from_trip_pivot[\"Fitness\"].astype(np.int)\n",
    "\n",
    "values_from_trip_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values_from_trip_pivot.to_csv('values_from_trip_pivot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_from_trip_pivot[\n",
    "    (values_from_trip_pivot.Enjoyment == 0)\n",
    "    & (values_from_trip_pivot.Productivity == 0)\n",
    "    & (values_from_trip_pivot.Fitness == 0)\n",
    "].groupby(\"wastedTime\").size().reset_index(name=\"nlegs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_from_trip_pivot.groupby(\"wastedTime\").size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train - Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "th = 0.8\n",
    "nlegs_train = np.int64(values_from_trip_pivot.shape[0] * th)\n",
    "nlegs_train_lst = random.sample(list(values_from_trip_pivot.index), nlegs_train)\n",
    "\n",
    "train_df = values_from_trip_pivot[values_from_trip_pivot.index.isin(nlegs_train_lst)]\n",
    "test_df = values_from_trip_pivot[~values_from_trip_pivot.index.isin(nlegs_train_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.wastedTime\n",
    "X = train_df.drop(\"wastedTime\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import create_cd\n",
    "\n",
    "feature_names = dict()\n",
    "for column, name in enumerate(train_df):\n",
    "    if column == 0:\n",
    "        continue\n",
    "    feature_names[column - 1] = name\n",
    "\n",
    "create_cd(\n",
    "    label=0,\n",
    "    cat_features=list(range(1, train_df.columns.shape[0])),\n",
    "    feature_names=feature_names,\n",
    "    # output_path=os.path.join(dataset_dir, 'train.cd')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train.cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "th = 0.8\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, train_size=th, random_state=42\n",
    ")\n",
    "\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    loss_function=\"MultiClass\",\n",
    "    # learning_rate=0.1,\n",
    "    custom_loss=\"Accuracy\",\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=100,\n",
    "    plot=True,\n",
    ")\n",
    "print(\"Model is fitted: \" + str(model.is_fitted()))\n",
    "print(\"Model params:\")\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERFITTING: Se il test error aumenta nel corso delle iterazioni\n",
    "# e se l'ottimo viene raggiunto nelle prime iterazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## il modello automaticamente taglia dopo l'overfitting\n",
    "print(\"Tree count: \" + str(model.tree_count_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_probs = model.predict_proba(X_test)\n",
    "print(predictions[:10])\n",
    "print(predictions_probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {}\n",
    "params[\"loss_function\"] = \"MultiClass\"\n",
    "params[\"iterations\"] = 80\n",
    "params[\"custom_loss\"] = \"Accuracy\"\n",
    "params[\"random_seed\"] = 63\n",
    "params[\"learning_rate\"] = 0.5\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    # stratified=False,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = np.min(cv_data[\"test-MultiClass-mean\"])\n",
    "best_iter = np.argmin(cv_data[\"test-MultiClass-mean\"])\n",
    "\n",
    "print(\n",
    "    \"Best validation Logloss score, not stratified: {:.4f}Â±{:.4f} on step {}\".format(\n",
    "        best_value, cv_data[\"test-MultiClass-std\"][best_iter], best_iter\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    early_stopping_rounds=20,  # stop when there is no improvement after 20 iterations\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass\n",
    "\n",
    "\n",
    "For multiclass problems with many classes sometimes it's better to solve classification problem using ranking. To do that we will build a dataset with groups. Every group will represent one object from our initial dataset. But it will have one additional categorical feature - possible class value. Target values will be equal to 1 if the class value is equal to the correct class, and 0 otherwise. Thus each group will have exactly one 1 in labels, and some zeros. You can put all possible class values in the group or you can try setting only hard negatives if there are too many labels. We'll show this approach on an example of binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def build_multiclass_ranking_dataset(\n",
    "    X, y, cat_features, label_values=[0, 1], start_group_id=0\n",
    "):\n",
    "    ranking_matrix = []\n",
    "    ranking_labels = []\n",
    "    group_ids = []\n",
    "\n",
    "    X_train_matrix = X.values\n",
    "    y_train_vector = y.values\n",
    "\n",
    "    for obj_idx in range(X.shape[0]):\n",
    "        obj = list(X_train_matrix[obj_idx])\n",
    "\n",
    "        for label in label_values:\n",
    "            obj_of_given_class = deepcopy(obj)\n",
    "            obj_of_given_class.append(label)\n",
    "            ranking_matrix.append(obj_of_given_class)\n",
    "            ranking_labels.append(float(y_train_vector[obj_idx] == label))\n",
    "            group_ids.append(start_group_id + obj_idx)\n",
    "\n",
    "    final_cat_features = deepcopy(cat_features)\n",
    "    final_cat_features.append(\n",
    "        X.shape[1]\n",
    "    )  # new feature that we are adding should be categorical.\n",
    "    return Pool(\n",
    "        ranking_matrix,\n",
    "        ranking_labels,\n",
    "        cat_features=final_cat_features,\n",
    "        group_id=group_ids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupwise_train_pool = build_multiclass_ranking_dataset(\n",
    "    X_train, y_train, cat_features, [1, 2, 3, 4, 5]\n",
    ")\n",
    "groupwise_eval_pool = build_multiclass_ranking_dataset(\n",
    "    X_validation, y_validation, cat_features, [1, 2, 3, 4, 5], X_train.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {\"iterations\": 100, \"learning_rate\": 0.01, \"loss_function\": \"QuerySoftMax\"}\n",
    "\n",
    "model = CatBoost(params)\n",
    "model.fit(\n",
    "    X=groupwise_train_pool, verbose=False, eval_set=groupwise_eval_pool, plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "obj = list(X_validation.values[0])\n",
    "ratings = []\n",
    "for label in [1, 2, 3, 4, 5]:\n",
    "    obj_with_label = deepcopy(obj)\n",
    "    obj_with_label.append(label)\n",
    "    rating = model.predict([obj_with_label])[0]\n",
    "    ratings.append(rating)\n",
    "print(\"Raw values:\", np.array(ratings))\n",
    "\n",
    "\n",
    "def soft_max(values):\n",
    "    return [math.exp(val) / sum([math.exp(val) for val in values]) for val in values]\n",
    "\n",
    "\n",
    "print(\"Probabilities\", np.array(soft_max(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned dataset\n",
    "\n",
    "Remove from the data all the legs with E, P, F = 0 and wt > 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = values_from_trip_pivot[\n",
    "    ~(\n",
    "        (values_from_trip_pivot.Enjoyment == 0)\n",
    "        & (values_from_trip_pivot.Fitness == 0)\n",
    "        & (values_from_trip_pivot.Productivity == 0)\n",
    "        & (values_from_trip_pivot.wastedTime >= 3)\n",
    "    )\n",
    "]\n",
    "cleaned_df.groupby(\"wastedTime\").size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save each TC df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tmp = values_from_trip[[\"legid\", \"value\", \"valueFromTrip\"]].drop_duplicates()\n",
    "tmp = tmp[tmp.valueFromTrip != \"Unknown\"]\n",
    "values_from_trip_pivot = pd.pivot(\n",
    "    data=tmp, index=\"legid\", columns=\"valueFromTrip\", values=\"value\"\n",
    ").reset_index()\n",
    "# add transport category and userid\n",
    "values_from_trip_pivot = values_from_trip_pivot.merge(\n",
    "    all_legs[[\"legid\", \"userid\", \"transp_category\", \"wastedTime\"]], on=\"legid\"\n",
    ").drop_duplicates()\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    ~values_from_trip_pivot.transp_category.isnull()\n",
    "]\n",
    "# Merge Paid_work and Personal_tasks into Productivity taking the **maximum** value\n",
    "values_from_trip_pivot[\"Productivity\"] = values_from_trip_pivot[\n",
    "    [\"Paid_work\", \"Personal_tasks\"]\n",
    "].max(axis=1)\n",
    "\n",
    "values_from_trip_pivot.drop([\"Paid_work\", \"Personal_tasks\"], axis=1, inplace=True)\n",
    "\n",
    "# select columns\n",
    "values_from_trip_pivot = values_from_trip_pivot[\n",
    "    [\"Enjoyment\", \"Productivity\", \"Fitness\", \"wastedTime\", \"transp_category\"]\n",
    "]\n",
    "\n",
    "cleaned_df = values_from_trip_pivot[\n",
    "    ~(\n",
    "        (values_from_trip_pivot.Enjoyment == 0)\n",
    "        & (values_from_trip_pivot.Fitness == 0)\n",
    "        & (values_from_trip_pivot.Productivity == 0)\n",
    "        & (values_from_trip_pivot.wastedTime >= 3)\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "for i in list(cleaned_df.transp_category.unique()):\n",
    "    print(i)\n",
    "\n",
    "    tc_df = cleaned_df[cleaned_df.transp_category == i]\n",
    "    tc_df = tc_df.iloc[:, :-1]\n",
    "    # save\n",
    "    tc_df.to_csv(out_path + \"OLR_results/\" + i + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "th = 0.8\n",
    "nlegs_train = np.int64(cleaned_df.shape[0] * th)\n",
    "nlegs_train_lst = random.sample(list(cleaned_df.index), nlegs_train)\n",
    "\n",
    "train_df = cleaned_df[cleaned_df.index.isin(nlegs_train_lst)]\n",
    "test_df = cleaned_df[~cleaned_df.index.isin(nlegs_train_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.wastedTime\n",
    "X = train_df.drop(\"wastedTime\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import create_cd\n",
    "\n",
    "feature_names = dict()\n",
    "for column, name in enumerate(train_df):\n",
    "    if column == 0:\n",
    "        continue\n",
    "    feature_names[column - 1] = name\n",
    "\n",
    "create_cd(\n",
    "    label=0,\n",
    "    cat_features=list(range(1, train_df.columns.shape[0])),\n",
    "    feature_names=feature_names,\n",
    "    # output_path=os.path.join(dataset_dir, 'train.cd')\n",
    ")\n",
    "\n",
    "!cat train.cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "th = 0.8\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, train_size=th, random_state=42\n",
    ")\n",
    "\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    loss_function=\"MultiClass\",\n",
    "    # learning_rate=0.1,\n",
    "    custom_loss=\"AUC\",\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=100,\n",
    "    plot=True,\n",
    ")\n",
    "print(\"Model is fitted: \" + str(model.is_fitted()))\n",
    "print(\"Model params:\")\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_probs = model.predict_proba(X_test)\n",
    "print(predictions[:10])\n",
    "print(predictions_probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.groupby(\"wastedTime\").size().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

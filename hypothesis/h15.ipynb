{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H15\n",
    "\n",
    "**Obj:** Travel comfort factors\n",
    "<br> To explore how VTT is influenced on the perceived comfort of the locations or while travelling.\n",
    "\n",
    "## Questions\n",
    "\n",
    "- [Q1](#Q1): What are the top positive and negative experience factors?\n",
    "- [Q2](#Q2): What is the ranking of 'today's weather' as an experience factor among all other factors?\n",
    "- [Q3](#Q3): What is the distribution of top satisfaction/dissatisfaction factors related to Crowdedness and Seating availability in public transport modes?\n",
    "- [Q4](#Q4): What is the distribution of top satisfaction/dissatisfaction factors related to Perceived Safety in cycling modes and public transport modes?\n",
    "- [Q5](#Q5): What is the distribution of top satisfaction/dissatisfaction factors related to Traffic congestion in car modes?\n",
    "- [Q6](#Q6): What are the main enabling factors for activities ?\n",
    "- [Q7](#Q7): What is the correlation between worthwhileness assessments and satisfaction factors?\n",
    "- [Q8](#Q8): What is the correlation between worthwhileness assessments and ‘today’s weather’ as an experience factor?\n",
    "- [Q9](#Q9): What is the correlation between worthwhileness assessments and satisfaction factors and activities?\n",
    "- [Q13](#Q13): What is the distribution of worthwhileness and mood ratings among different weather scenarios?\n",
    "- [Q14](#Q14): What is the distribution of transport modes and worthwhileness ratings among different weather scenarios?\n",
    "\n",
    "**oss:** all analysis should be done for all users and also by gender\n",
    "\n",
    "**VTT: \"Value of Travel Time\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "import importlib\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from pandas.io.json import json_normalize\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "input_path = \"../../2019-12-16.out/\"\n",
    "out_path = \"../../2019-12-16.out/hypothesis/H15/\"\n",
    "img_path = \"../../2019-12-16.out/hypothesis/H15/\"\n",
    "\n",
    "# Graphical parameters\n",
    "rcParams[\"axes.titlepad\"] = 45\n",
    "rcParams[\"font.size\"] = 16\n",
    "rcParams[\"figure.figsize\"] = 12, 8\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.abspath(out_path))\n",
    "except FileExistsError:\n",
    "    print(\"Directory '{}' already exists\".format(out_path), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legs = pd.read_pickle(input_path + legs)\n",
    "# trips_users_df = pd.read_pickle(input_path + 'trips_users_df.pkl')\n",
    "trips_df = pd.read_pickle(input_path + \"trips_df.pkl\")\n",
    "## select only trips in all_legs\n",
    "# trips_df = trips_df[trips_df['tripid'].isin(all_legs['tripid'])]\n",
    "\n",
    "# transport categories\n",
    "with open(input_path + \"category_transp_mode_dict.json\", \"r\") as f:\n",
    "    category_transp_mode_dict = json.load(f)\n",
    "\n",
    "inverted_category_transp_mode_dict = dict(\n",
    "    (v, k) for k in category_transp_mode_dict for v in category_transp_mode_dict[k]\n",
    ")\n",
    "\n",
    "#### remove \"unknown\" as transport category (?)\n",
    "\n",
    "print(\"Legs:\", all_legs.shape[0])\n",
    "print(\"Trips: \", len(all_legs.tripid.unique()))\n",
    "print(\"Users:\", len(all_legs.userid.unique()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read experience factors\n",
    "all_factors = pd.read_pickle(input_path + \"all_factors.pkl\")\n",
    "\n",
    "# delete legs with minus=F and plus=F\n",
    "all_factors = all_factors[\n",
    "    ~((all_factors[\"minus\"] == False) & (all_factors[\"plus\"] == False))\n",
    "]\n",
    "\n",
    "# delete legs with minus=T and plus=T (3% of obs)\n",
    "all_factors = all_factors[\n",
    "    ~((all_factors[\"minus\"] == True) & (all_factors[\"plus\"] == True))\n",
    "]\n",
    "\n",
    "# select only useful cols\n",
    "all_factors = all_factors[\n",
    "    [\n",
    "        \"correctedModeOfTransport_str\",\n",
    "        \"legid\",\n",
    "        \"minus\",\n",
    "        \"plus\",\n",
    "        \"tripid\",\n",
    "        \"factor\",\n",
    "        \"legStartDay\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# add info\n",
    "all_factors = all_factors.merge(\n",
    "    all_legs[\n",
    "        [\"legid\", \"wastedTime\", \"gender\", \"age\", \"onCampaigns\", \"transp_category\"]\n",
    "    ],\n",
    "    on=\"legid\",\n",
    ")\n",
    "\n",
    "## add purpose\n",
    "# read purposes -> trip_obj_grouped.pkl\n",
    "# trip_objs = pd.read_pickle(input_path + 'trip_objs_grouped.pkl')\n",
    "# add purpose to values_from_trip\n",
    "# all_factors = all_factors.merge(trip_objs[['tripid', 'objective_str']], on='tripid').drop_duplicates()\n",
    "\n",
    "# select useful wastedTime\n",
    "all_factors = all_factors[(all_factors.wastedTime > 0) & (all_factors.wastedTime < 6)]\n",
    "all_factors[\"wastedTime\"] = all_factors[\"wastedTime\"].apply(lambda x: np.round(x, 0))\n",
    "\n",
    "# remove legs with \"None\" transport category\n",
    "all_factors = all_factors[(all_factors.transp_category.notna())]\n",
    "\n",
    "# checks\n",
    "print(\"all records:\", len(all_factors))\n",
    "xx = all_factors[(all_factors[\"minus\"] == False) & (all_factors[\"plus\"] == True)]\n",
    "print(\"only plus: \", len(xx))\n",
    "xx = all_factors[(all_factors[\"minus\"] == True) & (all_factors[\"plus\"] == False)]\n",
    "print(\"only minus: \", len(xx))\n",
    "\n",
    "# create a column with the impact (minus)\n",
    "# all_factors['impact'] = np.nan\n",
    "# for idx, row in all_factors.iterrows():\n",
    "\n",
    "# only plus\n",
    "#    if (row['minus'] == False) & (row['plus'] == True):\n",
    "#        all_factors.loc[idx, 'impact'] = 'plus'\n",
    "#    # only minus\n",
    "#    if (row['minus'] == True) & (row['plus'] == False):\n",
    "#        all_factors.loc[idx, 'impact'] = 'minus'\n",
    "\n",
    "\n",
    "impact_lst = [\"plus\", \"minus\"]\n",
    "# all_factors.groupby('impact').size()\n",
    "\n",
    "all_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define for plots\n",
    "age_range = list(all_legs.age.unique())\n",
    "\n",
    "# assign 'CHE' to the class Other (AAA)\n",
    "all_legs[\"onCampaigns\"] = all_legs[\"onCampaigns\"].apply(\n",
    "    lambda x: \"AAA\" if x == \"CHE\" else x\n",
    ")\n",
    "top10 = list(all_legs.onCampaigns.unique())\n",
    "\n",
    "# transp_category list\n",
    "tc_lst = all_factors.transp_category.unique()\n",
    "\n",
    "# gender list\n",
    "gender_lst = [\"Male\", \"Female\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q1' ></a>\n",
    "### Q1:   What are the top positive and negative experience factors?\n",
    "\n",
    "The top positive and negative experience factors are already available in **tables attached to H2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_factors = all_factors[\n",
    "    (all_factors[\"minus\"] == False) & (all_factors[\"plus\"] == True)\n",
    "]\n",
    "minus_factors = all_factors[\n",
    "    (all_factors[\"minus\"] == True) & (all_factors[\"plus\"] == False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### BY GENDER\n",
    "path = out_path + \"gender/\"\n",
    "\n",
    "for g in gender_lst:\n",
    "\n",
    "    tmpP = plus_factors[plus_factors.gender == g]\n",
    "    tmp = (\n",
    "        tmpP.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_plus_\" + g.lower() + \".csv\", index=False)\n",
    "\n",
    "    tmpM = minus_factors[minus_factors.gender == g]\n",
    "    tmp = (\n",
    "        tmpM.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_minus_\" + g.lower() + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### BY COUNTRY\n",
    "path = out_path + \"country/\"\n",
    "\n",
    "for c in top10:\n",
    "\n",
    "    tmpP = plus_factors[plus_factors.onCampaigns == c]\n",
    "    tmp = (\n",
    "        tmpP.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_plus_\" + c + \".csv\", index=False)\n",
    "\n",
    "    tmpM = minus_factors[minus_factors.onCampaigns == c]\n",
    "    tmp = (\n",
    "        tmpM.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_minus_\" + c + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### BY TRANSPORT CATEGORY\n",
    "path = out_path + \"transp_category/\"\n",
    "\n",
    "for tc in tc_lst:\n",
    "\n",
    "    tmpP = plus_factors[plus_factors.transp_category == tc]\n",
    "    tmp = (\n",
    "        tmpP.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_plus_\" + tc + \".csv\", index=False)\n",
    "\n",
    "    tmpM = minus_factors[minus_factors.transp_category == tc]\n",
    "    tmp = (\n",
    "        tmpM.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"nlegs\")\n",
    "    )\n",
    "    # save\n",
    "    tmp.to_csv(path + \"h15_q1_table_minus_\" + tc + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q2' ></a>\n",
    "### Q2: What is the ranking of 'today's weather' as an experience factor among all other factors?\n",
    "\n",
    "**ALREADY ANSWERED**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q3' ></a>\n",
    "### Q3: What is the distribution of top satisfaction/dissatisfaction factors related to Crowdedness and Seating availability in public transport modes?\n",
    "\n",
    "To explore comfort travel factors in public transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowdness = all_factors[all_factors.factor == \"Crowdedness_Seating\"]\n",
    "# remove single with mode:car and with crowdness factor.\n",
    "crowdness = crowdness[crowdness.transp_category != \"private_motorized\"]\n",
    "\n",
    "# create a column with the impact\n",
    "crowdness[\"impact\"] = np.nan\n",
    "for idx, row in crowdness.iterrows():\n",
    "\n",
    "    # only plus\n",
    "    if (row[\"minus\"] == False) & (row[\"plus\"] == True):\n",
    "        crowdness.loc[idx, \"impact\"] = \"plus\"\n",
    "    # only minus\n",
    "    if (row[\"minus\"] == True) & (row[\"plus\"] == False):\n",
    "        crowdness.loc[idx, \"impact\"] = \"minus\"\n",
    "\n",
    "crowdness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all and gender\n",
    "mode_lst = [\n",
    "    \"bus\",\n",
    "    \"bus_long\",\n",
    "    \"ferry\",\n",
    "    \"high_speed_train\",\n",
    "    \"intercity_train\",\n",
    "    \"subway\",\n",
    "    \"train\",\n",
    "    \"tram\",\n",
    "]\n",
    "count_mode_dict = dict(all_legs.groupby(\"correctedModeOfTransport_str\").size())\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 7), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# all\n",
    "tmp = (\n",
    "    crowdness.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"correctedModeOfTransport_str\", y=\"count\", hue=\"impact\", data=tmp, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"All\")\n",
    "axes[0].set_xticklabels(mode_lst)\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_xlabel(\"Mode of transport\")\n",
    "axes[0].legend(loc=\"best\", fontsize=\"x-small\")\n",
    "\n",
    "# gender\n",
    "for i in range(len(gender_lst)):\n",
    "\n",
    "    tmp_df = crowdness[crowdness.gender == gender_lst[i]]\n",
    "    tmp = (\n",
    "        tmp_df.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "    sns.barplot(\n",
    "        x=\"correctedModeOfTransport_str\",\n",
    "        y=\"count\",\n",
    "        hue=\"impact\",\n",
    "        data=tmp,\n",
    "        ax=axes[i + 1],\n",
    "    )\n",
    "    axes[i + 1].legend(\"\")\n",
    "    axes[i + 1].set_title(gender_lst[i])\n",
    "    axes[i + 1].set_xticklabels(mode_lst)\n",
    "    axes[i + 1].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[i + 1].set_xlabel(\"Mode of transport\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q3_abs_all_gender.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all and gender\n",
    "mode_lst = [\n",
    "    \"bus\",\n",
    "    \"bus_long\",\n",
    "    \"ferry\",\n",
    "    \"high_speed_train\",\n",
    "    \"intercity_train\",\n",
    "    \"subway\",\n",
    "    \"train\",\n",
    "    \"tram\",\n",
    "]\n",
    "count_mode_dict = dict(all_legs.groupby(\"correctedModeOfTransport_str\").size())\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 7), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# all\n",
    "tmp = (\n",
    "    crowdness.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "tmp[\"rel_count\"] = tmp.apply(\n",
    "    lambda row: row[\"count\"] / count_mode_dict[row[\"correctedModeOfTransport_str\"]],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"correctedModeOfTransport_str\", y=\"rel_count\", hue=\"impact\", data=tmp, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"All\")\n",
    "axes[0].set_xticklabels(mode_lst)\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_xlabel(\"Mode of transport\")\n",
    "axes[0].legend(loc=\"best\", fontsize=\"x-small\")\n",
    "\n",
    "# gender\n",
    "for i in range(len(gender_lst)):\n",
    "\n",
    "    tmp_df = crowdness[crowdness.gender == gender_lst[i]]\n",
    "    tmp = (\n",
    "        tmp_df.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    tmp[\"rel_count\"] = tmp.apply(\n",
    "        lambda row: row[\"count\"] / count_mode_dict[row[\"correctedModeOfTransport_str\"]],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    sns.barplot(\n",
    "        x=\"correctedModeOfTransport_str\",\n",
    "        y=\"rel_count\",\n",
    "        hue=\"impact\",\n",
    "        data=tmp,\n",
    "        ax=axes[i + 1],\n",
    "    )\n",
    "    axes[i + 1].legend(\"\")\n",
    "    axes[i + 1].set_title(gender_lst[i])\n",
    "    axes[i + 1].set_xticklabels(mode_lst)\n",
    "    axes[i + 1].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[i + 1].set_xlabel(\"Mode of transport\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q3_all_gender.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY COUNTRY\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(18, 10), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(len(top10)):\n",
    "\n",
    "    tmp = crowdness[crowdness.onCampaigns == top10[i]]\n",
    "    val_count = (\n",
    "        tmp.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    # val_count['rel_count'] = val_count.apply(lambda row: row['count'] / count_mode_dict[row['correctedModeOfTransport_str']], axis=1)\n",
    "\n",
    "    sns.barplot(\n",
    "        x=\"correctedModeOfTransport_str\",\n",
    "        y=\"count\",\n",
    "        hue=\"impact\",\n",
    "        data=val_count,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].set_title(top10[i])\n",
    "    axes[i].set_xticklabels(mode_lst)\n",
    "    axes[i].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[i].set_xlabel(\"Mode of transport\")\n",
    "    axes[i].legend(\"\")\n",
    "\n",
    "    axes[0].legend(loc=\"best\", fontsize=\"x-small\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q3_country.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q4' ></a>\n",
    "### Q4: What is the distribution of top satisfaction/dissatisfaction factors related to Perceived Safety in cycling modes and public transport modes?\n",
    "\n",
    "To explore factors related to Perceived Safety in cycling ('Road/path availability and safety', 'Traffic Signals/Crossings' and 'Cars/Other vehicles') and public transport ('Security and Safety')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_lst_cycl = [\n",
    "    \"Road_Path_Availability_And_Safety\",\n",
    "    \"Traffic_Signals_Crossings\",\n",
    "    \"Cars_Other_Vehicles\",\n",
    "]\n",
    "safety_lst_publ = [\"Security_And_Safety\"]\n",
    "\n",
    "safety_cycl = all_factors[\n",
    "    (all_factors.factor.isin(safety_lst_cycl))\n",
    "    & (all_factors.transp_category == \"cycling_emerging_micromobility\")\n",
    "]\n",
    "safety_publ = all_factors[\n",
    "    (all_factors.factor.isin(safety_lst_publ))\n",
    "    & (\n",
    "        all_factors.transp_category.isin(\n",
    "            [\"public_transp_long_dist\", \"public_transp_short_dist\"]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def find_impact(plus, minus):\n",
    "\n",
    "    if (minus == False) & (plus == True):\n",
    "        return \"plus\"\n",
    "    if (minus == True) & (plus == False):\n",
    "        return \"minus\"\n",
    "\n",
    "\n",
    "safety_cycl[\"impact\"] = safety_cycl.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "safety_publ[\"impact\"] = safety_publ.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL AND GENDER - CYCLING\n",
    "# all and gender\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 7))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# all\n",
    "tmp = (\n",
    "    safety_cycl.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"correctedModeOfTransport_str\", y=\"count\", hue=\"impact\", data=tmp, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"All\")\n",
    "# axes[0].set_xticklabels(mode_lst)\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_xlabel(\"Mode of transport\")\n",
    "axes[0].legend(loc=\"best\", fontsize=\"x-small\")\n",
    "\n",
    "# gender\n",
    "for i in range(len(gender_lst)):\n",
    "\n",
    "    tmp_df = safety_cycl[safety_cycl.gender == gender_lst[i]]\n",
    "    tmp = (\n",
    "        tmp_df.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    sns.barplot(\n",
    "        x=\"correctedModeOfTransport_str\",\n",
    "        y=\"count\",\n",
    "        hue=\"impact\",\n",
    "        data=tmp,\n",
    "        ax=axes[i + 1],\n",
    "    )\n",
    "    axes[i + 1].legend(\"\")\n",
    "    axes[i + 1].set_title(gender_lst[i])\n",
    "    #   axes[i+1].set_xticklabels(mode_lst)\n",
    "    axes[i + 1].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[i + 1].set_xlabel(\"Mode of transport\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q4_all_gender_cycl.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL AND GENDER - PUBLIC\n",
    "# all and gender\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 7))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# all\n",
    "tmp = (\n",
    "    safety_publ.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"correctedModeOfTransport_str\", y=\"count\", hue=\"impact\", data=tmp, ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"All\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "axes[0].set_xlabel(\"Mode of transport\")\n",
    "axes[0].legend(loc=\"best\", fontsize=\"x-small\")\n",
    "\n",
    "# gender\n",
    "for i in range(len(gender_lst)):\n",
    "\n",
    "    tmp_df = safety_publ[safety_publ.gender == gender_lst[i]]\n",
    "    tmp = (\n",
    "        tmp_df.groupby([\"correctedModeOfTransport_str\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    sns.barplot(\n",
    "        x=\"correctedModeOfTransport_str\",\n",
    "        y=\"count\",\n",
    "        hue=\"impact\",\n",
    "        data=tmp,\n",
    "        ax=axes[i + 1],\n",
    "    )\n",
    "    axes[i + 1].legend(\"\")\n",
    "    axes[i + 1].set_title(gender_lst[i])\n",
    "    axes[i + 1].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[i + 1].set_xlabel(\"Mode of transport\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q4_all_gender_publ.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q5' ></a>\n",
    "### Q5: What is the distribution of top satisfaction/dissatisfaction factors related to Traffic congestion in car modes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q6' ></a>\n",
    "### Q6: What are the main enabling factors for activities ?\n",
    "\n",
    "When people report an activity, what are the top positive factors that were reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data - ACTIVITIES\n",
    "all_gen_act = pd.read_pickle(input_path + \"all_gen_act.pkl\")\n",
    "\n",
    "\n",
    "# add transport category\n",
    "all_gen_act = all_gen_act.merge(\n",
    "    all_legs[[\"legid\", \"wastedTime\", \"gender\", \"onCampaigns\"]], on=\"legid\",\n",
    ")\n",
    "\n",
    "\n",
    "def find_impact(plus, minus):\n",
    "\n",
    "    if (minus == False) & (plus == True):\n",
    "        return \"plus\"\n",
    "    if (minus == True) & (plus == False):\n",
    "        return \"minus\"\n",
    "\n",
    "\n",
    "# select positive factors\n",
    "all_factors[\"impact\"] = all_factors.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "pos_impact = all_factors[all_factors.impact == \"plus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lst = all_gen_act.code.unique()\n",
    "\n",
    "first = True\n",
    "for act in act_lst:\n",
    "    # select legs with act\n",
    "    act_legs_lst = all_gen_act[\"legid\"][all_gen_act.code == act]\n",
    "\n",
    "    # select positive factors of those legs and count the occurrences.\n",
    "    # take the first 5 factors.\n",
    "    pos_factors_leg = pos_impact[pos_impact.legid.isin(act_legs_lst)]\n",
    "    tmp = (\n",
    "        pos_factors_leg.groupby(\"factor\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=act)[:5]\n",
    "    )\n",
    "\n",
    "    if first:\n",
    "        first = False\n",
    "        heatmap_df = tmp\n",
    "    else:\n",
    "        heatmap_df = heatmap_df.merge(tmp, on=\"factor\", how=\"outer\").drop_duplicates()\n",
    "\n",
    "heatmap_df.fillna(0, inplace=True)\n",
    "heatmap_df.set_index(\"factor\", inplace=True)\n",
    "heatmap_df[list(heatmap_df.columns)] = heatmap_df[list(heatmap_df.columns)].astype(int)\n",
    "heatmap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\"d\")\n",
    "plt.title(\"All users\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q6_all.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY GENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q7' ></a>\n",
    "### Q7: What is the correlation between worthwhileness assessments and satisfaction factors?\n",
    "\n",
    "Study if the impact of these experience factors change according to mode, purpose, territory/country, weekday/weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SATISFACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "tmp = plus_factors.groupby(\"wastedTime\").size().reset_index(name=\"count\")\n",
    "sns.barplot(x=\"wastedTime\", y=\"count\", data=tmp, ax=axes[0])\n",
    "axes[0].set_title(\"All\")\n",
    "\n",
    "tmp = plus_factors.groupby([\"wastedTime\", \"gender\"]).size().reset_index(name=\"count\")\n",
    "tmp = tmp[tmp.gender != \"Other\"]\n",
    "sns.barplot(x=\"wastedTime\", y=\"count\", hue=\"gender\", data=tmp, ax=axes[1])\n",
    "axes[1].set_title(\"By gender\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q7_all_gender_plus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BY COUNTRIES AND TRANSP_CATEGORY\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 6), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "tmp = plus_factors.groupby(\"onCampaigns\")[\"wastedTime\"].mean().reset_index(name=\"avg\")\n",
    "axes[0].scatter(x=tmp.onCampaigns, y=tmp.avg, lw=6)\n",
    "axes[0].set_title(\"countries\")\n",
    "\n",
    "tmp = (\n",
    "    plus_factors.groupby(\"transp_category\")[\"wastedTime\"].mean().reset_index(name=\"avg\")\n",
    ")\n",
    "axes[1].scatter(x=tmp.transp_category, y=tmp.avg, lw=6, marker=\"v\")\n",
    "axes[1].set_title(\"transport categories\")\n",
    "axes[1].set_xticks(range(5))\n",
    "axes[1].set_xticklabels(\n",
    "    [\"cycling\", \"private\", \"public_long\", \"public_short\", \"walking\"]\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q7_country_tc_plus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISSATISFACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "tmp = minus_factors.groupby(\"wastedTime\").size().reset_index(name=\"count\")\n",
    "sns.barplot(x=\"wastedTime\", y=\"count\", data=tmp, ax=axes[0])\n",
    "axes[0].set_title(\"All\")\n",
    "\n",
    "tmp = minus_factors.groupby([\"wastedTime\", \"gender\"]).size().reset_index(name=\"count\")\n",
    "tmp = tmp[tmp.gender != \"Other\"]\n",
    "sns.barplot(x=\"wastedTime\", y=\"count\", hue=\"gender\", data=tmp, ax=axes[1])\n",
    "axes[1].set_title(\"By gender\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q7_all_gender_minus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BY COUNTRIES AND TRANSP_CATEGORY\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 6), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "tmp = minus_factors.groupby(\"onCampaigns\")[\"wastedTime\"].mean().reset_index(name=\"avg\")\n",
    "axes[0].scatter(x=tmp.onCampaigns, y=tmp.avg, lw=6)\n",
    "axes[0].set_title(\"countries\")\n",
    "\n",
    "tmp = (\n",
    "    minus_factors.groupby(\"transp_category\")[\"wastedTime\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"avg\")\n",
    ")\n",
    "axes[1].scatter(x=tmp.transp_category, y=tmp.avg, lw=6, marker=\"v\")\n",
    "axes[1].set_title(\"transport categories\")\n",
    "axes[1].set_xticks(range(5))\n",
    "axes[1].set_xticklabels(\n",
    "    [\"cycling\", \"private\", \"public_long\", \"public_short\", \"walking\"]\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q7_country_tc_minus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q8' ></a>\n",
    "### Q8: What is the correlation between worthwhileness assessments and ‘today’s weather’ as an experience factor?\n",
    "\n",
    "Is weather influencing preceived value of travel time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only today's weather\n",
    "today_weather = all_factors[all_factors[\"factor\"] == \"Reliability_Of_Travel_Time\"]\n",
    "print(\"legs with today weather\", len(today_weather))\n",
    "\n",
    "today_weather[\"impact\"] = today_weather.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "today_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL + GENDER\n",
    "\n",
    "nrows = 1\n",
    "ncols = 3\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 5), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "tmp = today_weather.groupby([\"wastedTime\", \"impact\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "totM = tmp[tmp[\"impact\"] == \"minus\"][\"count\"].sum()\n",
    "totP = tmp[tmp[\"impact\"] == \"plus\"][\"count\"].sum()\n",
    "tmp[\"rel_count\"] = tmp.apply(\n",
    "    lambda x: x[\"count\"] / totM if x[\"impact\"] == \"minus\" else x[\"count\"] / totP, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "sns.barplot(x=\"wastedTime\", y=\"rel_count\", hue=\"impact\", data=tmp, ax=axes[0])\n",
    "axes[0].legend(fontsize=\"x-small\")\n",
    "# axes[0].set_xlabel(fontsize=12)\n",
    "axes[0].set_title(\"All\", fontsize=14)\n",
    "\n",
    "gender_lst = [\"Male\", \"Female\"]\n",
    "for i in range(ncols - 1):\n",
    "    tmp = (\n",
    "        today_weather[today_weather.gender == gender_lst[i]]\n",
    "        .groupby([\"wastedTime\", \"impact\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "    totM = tmp[tmp[\"impact\"] == \"minus\"][\"count\"].sum()\n",
    "    totP = tmp[tmp[\"impact\"] == \"plus\"][\"count\"].sum()\n",
    "    tmp[\"rel_count\"] = tmp.apply(\n",
    "        lambda x: x[\"count\"] / totM if x[\"impact\"] == \"minus\" else x[\"count\"] / totP,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    sns.barplot(x=\"wastedTime\", y=\"rel_count\", hue=\"impact\", data=tmp, ax=axes[i + 1])\n",
    "    axes[i + 1].legend(\"\")\n",
    "    axes[i + 1].set_ylabel(None)\n",
    "    # axes[i+1].set_xlabels(fontsize=12)\n",
    "    axes[i + 1].set_title(gender_lst[i], fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q8_all_gender.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY TRANSPORT CATEGORY\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "axid = 0\n",
    "for idx, c in list(enumerate(tc_lst)):\n",
    "\n",
    "    tmp = today_weather[today_weather.transp_category == c]\n",
    "    tmp = tmp.groupby([\"wastedTime\", \"impact\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    totM = tmp[tmp[\"impact\"] == \"minus\"][\"count\"].sum()\n",
    "    totP = tmp[tmp[\"impact\"] == \"plus\"][\"count\"].sum()\n",
    "    tmp[\"rel_count\"] = tmp.apply(\n",
    "        lambda x: x[\"count\"] / totM if x[\"impact\"] == \"minus\" else x[\"count\"] / totP,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    sns.barplot(x=\"wastedTime\", y=\"rel_count\", hue=\"impact\", data=tmp, ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(c, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"relative count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    if idx == 0:\n",
    "        axes[idx].legend(fontsize=\"x-small\", loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q8_tc.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY COUNTRY\n",
    "\n",
    "nrows = 2\n",
    "ncols = 5\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "axid = 0\n",
    "for idx, c in list(enumerate(top10)):\n",
    "\n",
    "    tmp = today_weather[today_weather.onCampaigns == c]\n",
    "    tmp = tmp.groupby([\"wastedTime\", \"impact\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    totM = tmp[tmp[\"impact\"] == \"minus\"][\"count\"].sum()\n",
    "    totP = tmp[tmp[\"impact\"] == \"plus\"][\"count\"].sum()\n",
    "    tmp[\"rel_count\"] = tmp.apply(\n",
    "        lambda x: x[\"count\"] / totM if x[\"impact\"] == \"minus\" else x[\"count\"] / totP,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    sns.barplot(x=\"wastedTime\", y=\"rel_count\", hue=\"impact\", data=tmp, ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(c, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"relative count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    if idx == 0:\n",
    "        axes[idx].legend(fontsize=\"x-small\", loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q8_country.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q9' ></a>\n",
    "### Q9: What is the correlation between worthwhileness assessments and satisfaction factors and activities?\n",
    "\n",
    "We would like to explore if any specific combination of satisfaction factors and activities is associated with particularly high or low worthwhileness assessments. Is that possible (perhaps to be examined in pairs)?\n",
    "\n",
    "    --- SOLO WT=1 E WT=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "all_gen_act = pd.read_pickle(input_path + \"all_gen_act.pkl\")\n",
    "\n",
    "# add transport category\n",
    "all_gen_act = all_gen_act.merge(\n",
    "    all_legs[[\"legid\", \"wastedTime\", \"gender\", \"onCampaigns\"]], on=\"legid\",\n",
    ")\n",
    "\n",
    "# select only wt=1 and wt=5\n",
    "all_gen_act.wastedTime = all_gen_act.wastedTime.apply(lambda x: np.round(x))\n",
    "all_gen_act_wt1 = all_gen_act[(all_gen_act.wastedTime == 1)]\n",
    "all_gen_act_wt5 = all_gen_act[(all_gen_act.wastedTime == 5)]\n",
    "\n",
    "all_gen_act_wt1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only factors with wt=1 and wt=5\n",
    "all_factors_wt1 = all_factors[all_factors.wastedTime == 1]\n",
    "print(\n",
    "    \"common legs with wt1:\",\n",
    "    len(\n",
    "        set(all_factors_wt1.legid.unique()).intersection(all_gen_act_wt1.legid.unique())\n",
    "    ),\n",
    ")\n",
    "\n",
    "all_factors_wt5 = all_factors[all_factors.wastedTime == 5]\n",
    "print(\n",
    "    \"common legs with wt5:\",\n",
    "    len(\n",
    "        set(all_factors_wt5.legid.unique()).intersection(all_gen_act_wt5.legid.unique())\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WT=1 - PLUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_impact(plus, minus):\n",
    "\n",
    "    if (minus == False) & (plus == True):\n",
    "        return \"plus\"\n",
    "    if (minus == True) & (plus == False):\n",
    "        return \"minus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select onlu plus facotrs\n",
    "all_factors_wt1[\"impact\"] = all_factors_wt1.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "all_factors_wt1_plus = all_factors_wt1[all_factors_wt1.impact == \"plus\"]\n",
    "\n",
    "\n",
    "# all combinations of factor-activity per wt1\n",
    "factor_activity_dict_wt1 = {}\n",
    "wt1_common_legs = set(all_factors_wt1.legid.unique()).intersection(\n",
    "    all_gen_act_wt1.legid.unique()\n",
    ")\n",
    "\n",
    "for lid in wt1_common_legs:\n",
    "\n",
    "    leg_df_factor = all_factors_wt1_plus[all_factors_wt1_plus.legid == lid]\n",
    "    leg_df_act = all_gen_act_wt1[all_gen_act_wt1.legid == lid]\n",
    "\n",
    "    factor_lst = leg_df_factor.factor.unique()\n",
    "    act_lst = leg_df_act.code.unique()\n",
    "\n",
    "    comb_lst = list(itertools.product(factor_lst, act_lst))\n",
    "\n",
    "    for comb in comb_lst:\n",
    "\n",
    "        if comb not in factor_activity_dict_wt1.keys():\n",
    "            factor_activity_dict_wt1[comb] = 0\n",
    "        factor_activity_dict_wt1[comb] += 1\n",
    "\n",
    "# create df\n",
    "row_lst = []\n",
    "for k in factor_activity_dict_wt1.keys():\n",
    "\n",
    "    row = [k[0], k[1], factor_activity_dict_wt1[k]]\n",
    "    row_lst.append(row)\n",
    "\n",
    "factor_activity_df_wt1 = pd.DataFrame(row_lst, columns=[\"factor\", \"activity\", \"count\"])\n",
    "factor_activity_df_wt1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_df = factor_activity_df_wt1.pivot(\n",
    "    index=\"factor\", columns=\"activity\", values=\"count\"\n",
    ")\n",
    "heatmap_df.fillna(0, inplace=True)\n",
    "heatmap_df.sort_values(\n",
    "    by=list(heatmap_df.columns), axis=0, ascending=False, inplace=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(heatmap_df, annot=True)\n",
    "plt.yticks(range(len(heatmap_df)), heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q9_heatmap_wt1_plus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**WT=1 - MINUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select onlu plus facotrs\n",
    "all_factors_wt1[\"impact\"] = all_factors_wt1.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "all_factors_wt1_minus = all_factors_wt1[all_factors_wt1.impact == \"minus\"]\n",
    "\n",
    "\n",
    "# all combinations of factor-activity per wt1\n",
    "factor_activity_dict_wt1 = {}\n",
    "wt1_common_legs = set(all_factors_wt1.legid.unique()).intersection(\n",
    "    all_gen_act_wt1.legid.unique()\n",
    ")\n",
    "\n",
    "for lid in wt1_common_legs:\n",
    "\n",
    "    leg_df_factor = all_factors_wt1_minus[all_factors_wt1_minus.legid == lid]\n",
    "    leg_df_act = all_gen_act_wt1[all_gen_act_wt1.legid == lid]\n",
    "\n",
    "    factor_lst = leg_df_factor.factor.unique()\n",
    "    act_lst = leg_df_act.code.unique()\n",
    "\n",
    "    comb_lst = list(itertools.product(factor_lst, act_lst))\n",
    "\n",
    "    for comb in comb_lst:\n",
    "\n",
    "        if comb not in factor_activity_dict_wt1.keys():\n",
    "            factor_activity_dict_wt1[comb] = 0\n",
    "        factor_activity_dict_wt1[comb] += 1\n",
    "\n",
    "# create df\n",
    "row_lst = []\n",
    "for k in factor_activity_dict_wt1.keys():\n",
    "\n",
    "    row = [k[0], k[1], factor_activity_dict_wt1[k]]\n",
    "    row_lst.append(row)\n",
    "\n",
    "factor_activity_df_wt1 = pd.DataFrame(row_lst, columns=[\"factor\", \"activity\", \"count\"])\n",
    "factor_activity_df_wt1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = factor_activity_df_wt1.pivot(\n",
    "    index=\"factor\", columns=\"activity\", values=\"count\"\n",
    ")\n",
    "heatmap_df.fillna(0, inplace=True)\n",
    "heatmap_df.sort_values(\n",
    "    by=list(heatmap_df.columns), axis=0, ascending=False, inplace=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(heatmap_df, annot=True)\n",
    "plt.yticks(range(len(heatmap_df)), heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q9_heatmap_wt1_minus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**WT=5 - PLUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select onlu plus facotrs\n",
    "all_factors_wt5[\"impact\"] = all_factors_wt5.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "all_factors_wt5_plus = all_factors_wt5[all_factors_wt5.impact == \"plus\"]\n",
    "\n",
    "\n",
    "# all combinations of factor-activity per wt5\n",
    "factor_activity_dict_wt5 = {}\n",
    "wt5_common_legs = set(all_factors_wt5.legid.unique()).intersection(\n",
    "    all_gen_act_wt5.legid.unique()\n",
    ")\n",
    "\n",
    "for lid in wt5_common_legs:\n",
    "\n",
    "    leg_df_factor = all_factors_wt5_plus[all_factors_wt5_plus.legid == lid]\n",
    "    leg_df_act = all_gen_act_wt5[all_gen_act_wt5.legid == lid]\n",
    "\n",
    "    factor_lst = leg_df_factor.factor.unique()\n",
    "    act_lst = leg_df_act.code.unique()\n",
    "\n",
    "    comb_lst = list(itertools.product(factor_lst, act_lst))\n",
    "\n",
    "    for comb in comb_lst:\n",
    "\n",
    "        if comb not in factor_activity_dict_wt5.keys():\n",
    "            factor_activity_dict_wt5[comb] = 0\n",
    "        factor_activity_dict_wt5[comb] += 1\n",
    "\n",
    "# create df\n",
    "row_lst = []\n",
    "for k in factor_activity_dict_wt5.keys():\n",
    "\n",
    "    row = [k[0], k[1], factor_activity_dict_wt5[k]]\n",
    "    row_lst.append(row)\n",
    "\n",
    "factor_activity_df_wt5 = pd.DataFrame(row_lst, columns=[\"factor\", \"activity\", \"count\"])\n",
    "factor_activity_df_wt5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_df = factor_activity_df_wt5.pivot(\n",
    "    index=\"factor\", columns=\"activity\", values=\"count\"\n",
    ")\n",
    "heatmap_df.fillna(0, inplace=True)\n",
    "heatmap_df.sort_values(\n",
    "    by=list(heatmap_df.columns), axis=0, ascending=False, inplace=True\n",
    ")\n",
    "heatmap_df.astype(np.int64, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\".0f\")\n",
    "plt.yticks(range(len(heatmap_df)), heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q9_heatmap_wt5_plus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**WT=5 - MINUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select onlu plus facotrs\n",
    "all_factors_wt5[\"impact\"] = all_factors_wt5.apply(\n",
    "    lambda row: find_impact(row[\"plus\"], row[\"minus\"]), axis=1\n",
    ")\n",
    "all_factors_wt5_minus = all_factors_wt5[all_factors_wt5.impact == \"minus\"]\n",
    "\n",
    "\n",
    "# all combinations of factor-activity per wt5\n",
    "factor_activity_dict_wt5 = {}\n",
    "wt5_common_legs = set(all_factors_wt5.legid.unique()).intersection(\n",
    "    all_gen_act_wt5.legid.unique()\n",
    ")\n",
    "\n",
    "for lid in wt5_common_legs:\n",
    "\n",
    "    leg_df_factor = all_factors_wt5_minus[all_factors_wt5_minus.legid == lid]\n",
    "    leg_df_act = all_gen_act_wt5[all_gen_act_wt5.legid == lid]\n",
    "\n",
    "    factor_lst = leg_df_factor.factor.unique()\n",
    "    act_lst = leg_df_act.code.unique()\n",
    "\n",
    "    comb_lst = list(itertools.product(factor_lst, act_lst))\n",
    "\n",
    "    for comb in comb_lst:\n",
    "\n",
    "        if comb not in factor_activity_dict_wt5.keys():\n",
    "            factor_activity_dict_wt5[comb] = 0\n",
    "        factor_activity_dict_wt5[comb] += 1\n",
    "\n",
    "# create df\n",
    "row_lst = []\n",
    "for k in factor_activity_dict_wt5.keys():\n",
    "\n",
    "    row = [k[0], k[1], factor_activity_dict_wt5[k]]\n",
    "    row_lst.append(row)\n",
    "\n",
    "factor_activity_df_wt5 = pd.DataFrame(row_lst, columns=[\"factor\", \"activity\", \"count\"])\n",
    "factor_activity_df_wt5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = factor_activity_df_wt5.pivot(\n",
    "    index=\"factor\", columns=\"activity\", values=\"count\"\n",
    ")\n",
    "heatmap_df.fillna(0, inplace=True)\n",
    "heatmap_df.sort_values(\n",
    "    by=list(heatmap_df.columns), axis=0, ascending=False, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\".0f\")\n",
    "plt.yticks(range(len(heatmap_df)), heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    img_path + \"h15_q9_heatmap_wt5_minus.png\", bbox_to_anchor=True, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q13' ></a>\n",
    "### Q13: What is the distribution of worthwhileness and mood ratings among different weather scenarios?\n",
    "\n",
    "Information to be extracted following a combination of weather statistics during trips and user profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_pickle(input_path + \"weather_final_with_legs_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_scenarios_metadata_filename = \"weather_scenarios.json\"\n",
    "weather_scenarios_metadata_path = os.path.join(\n",
    "    meta_data_path, weather_scenarios_metadata_filename\n",
    ")\n",
    "with open(weather_scenarios_metadata_path, \"r\") as infp:\n",
    "    weather_scenarios = json.load(infp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weather_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "cws = {\n",
    "    \"neutral/good\": \"#BAFFC9\",\n",
    "    \"cold\": \"#2C85B1\",\n",
    "    \"warm\": \"#FE6D6D\",\n",
    "    \"uncomfortable temperature\": \"#F78003\",\n",
    "    \"rainy/snowy\": \"#AFAFAF\",\n",
    "    \"cloudy\": \"#BAE1FF\",\n",
    "    \"windy\": \"#D4C2E1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_df = pd.read_pickle(input_path + legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws = weather_df[[\"legid\", \"weather_scenario\"]]\n",
    "\n",
    "all_ws_legids = set(all_ws.legid.values)\n",
    "all_ws_legs = legs_df.loc[legs_df[\"legid\"].isin(all_ws_legids)][\n",
    "    [\"legid\", \"tripid\", \"wastedTime\"]\n",
    "]\n",
    "all_ws_legs = all_ws_legs.astype({\"wastedTime\": \"int32\"})\n",
    "all_ws_trips = trips_df[[\"tripid\", \"overallScore\"]]\n",
    "\n",
    "all_ws = all_ws.merge(all_ws_legs)\n",
    "all_ws = all_ws.merge(all_ws_trips)\n",
    "\n",
    "all_ws = all_ws[(all_ws.overallScore > 0) & (all_ws.overallScore < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_data = dict()\n",
    "for ws in weather_scenarios.keys():\n",
    "    print(\"ws:\", ws)\n",
    "\n",
    "    # Pandas select rows based on a function of a column\n",
    "    # See:\n",
    "    #   https://stackoverflow.com/a/56703848/2377454\n",
    "    ws_df = all_ws.loc[all_ws[\"weather_scenario\"].apply(lambda wslist: ws in wslist)]\n",
    "    ws_data[ws] = ws_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way to find the intersection of multiple sets?\n",
    "# See:\n",
    "#   https://stackoverflow.com/a/2541814/2377454\n",
    "def intersect_ws(weather_scenarios):\n",
    "    wslist = list(weather_scenarios)\n",
    "    wssets = [set(ws) for ws in wslist]\n",
    "\n",
    "    wsintersection = set.intersection(*wssets)\n",
    "\n",
    "    return list(wsintersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ws(weather_scenarios):\n",
    "    wslist = list(weather_scenarios)\n",
    "    wssets = [set(ws) for ws in wslist]\n",
    "\n",
    "    if len(wssets) > 0:\n",
    "        wsintersection = set.intersection(*wssets)\n",
    "        return all([aset == wsintersection for aset in wssets])\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# Pandas select rows based on a function of a column\n",
    "# See:\n",
    "#   https://stackoverflow.com/a/56703848/2377454\n",
    "selected = all_ws.groupby(\"tripid\")[\"weather_scenario\"].agg(select_ws)\n",
    "nonselected = selected.loc[selected == False]\n",
    "\n",
    "print(\"# of nonselected:\", len(nonselected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonselected.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#33:9960\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#33:9960\"].groupby(\"tripid\")[\"weather_scenario\"].agg(\n",
    "    intersect_ws\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#130:14450\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#130:14450\"].groupby(\"tripid\")[\"weather_scenario\"].agg(\n",
    "    intersect_ws\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#30:13084\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws.loc[all_ws[\"tripid\"] == \"#30:13084\"].groupby(\"tripid\")[\"weather_scenario\"].agg(\n",
    "    intersect_ws\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_wastedtime = (\n",
    "    all_ws.loc[(all_ws.wastedTime > 0) & (all_ws.wastedTime < 6)]\n",
    "    .groupby(\"tripid\")[\"wastedTime\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "tmp_wastedtime[\"wastedTime\"] = tmp_wastedtime[\"wastedTime\"].apply(\n",
    "    lambda x: int(round(x, 0))\n",
    ")\n",
    "tmp_wastedtime.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite = (\n",
    "    all_ws.groupby(\"tripid\")[[\"weather_scenario\", \"overallScore\"]]\n",
    "    .agg({\"weather_scenario\": [intersect_ws], \"overallScore\": [np.mean]})\n",
    "    .reset_index()\n",
    ")\n",
    "all_ws_composite.droplevel(0, axis=1)\n",
    "all_ws_composite.columns = [\"tripid\", \"weather_scenario\", \"overallScore\"]\n",
    "\n",
    "all_ws_composite = all_ws_composite.merge(tmp_wastedtime, on=\"tripid\")\n",
    "all_ws_composite[\"wscount\"] = all_ws_composite[\"weather_scenario\"].apply(\n",
    "    lambda x: len(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite.loc[all_ws_composite[\"tripid\"] == \"#30:13084\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite.loc[all_ws_composite[\"tripid\"] == \"#33:9960\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite.loc[all_ws_composite[\"tripid\"] == \"#130:14450\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ws_composite.loc[all_ws_composite[\"tripid\"] == \"#30:13084\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ws_composite.groupby(\"wscount\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = all_ws_composite.groupby(\"wscount\").count().reset_index()\n",
    "print(\"Total number of scenarios:\", sum(foo[\"wscount\"] * foo[\"weather_scenario\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_composite_data = dict()\n",
    "for ws in weather_scenarios.keys():\n",
    "    print(\"ws:\", ws)\n",
    "\n",
    "    # Pandas select rows based on a function of a column\n",
    "    # See:\n",
    "    #   https://stackoverflow.com/a/56703848/2377454\n",
    "    ws_composite_df = all_ws_composite.loc[\n",
    "        all_ws_composite[\"weather_scenario\"].apply(lambda wslist: ws in wslist)\n",
    "    ]\n",
    "    ws_composite_data[ws] = ws_composite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_sum = 0\n",
    "for ws in weather_scenarios.keys():\n",
    "    ws_count = len(ws_composite_data[ws])\n",
    "    ws_sum += ws_count\n",
    "    print(\"  * {}:{}\".format(ws, ws_count))\n",
    "\n",
    "print(\"Total number of scenarios:\", ws_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_composite_data[\"cold\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Plot each distribution for each weather scenario\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"Distributions (absolute counts) of mood ratings by weather scenario\",\n",
    "    size=16,\n",
    "    y=1.12,\n",
    ")\n",
    "axes = axes.ravel()\n",
    "\n",
    "\n",
    "axid = 0\n",
    "for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "    print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "    tmp = ws_composite_data[ws]\n",
    "    tmp = tmp.groupby([\"overallScore\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    sns.barplot(x=\"overallScore\", y=\"count\", data=tmp, color=cws[ws], ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(ws, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"mood ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q13.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot each distribution for each weather scenario\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"Distributions (relative counts) of mood ratings by weather scenario\",\n",
    "    size=16,\n",
    "    y=1.12,\n",
    ")\n",
    "axes = axes.ravel()\n",
    "\n",
    "\n",
    "axid = 0\n",
    "for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "    print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "    tmp = ws_composite_data[ws]\n",
    "    tmp = tmp.groupby([\"overallScore\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    tot = tmp[\"count\"].sum()\n",
    "    tmp[\"rel_count\"] = tmp.apply(lambda x: x[\"count\"] / tot, axis=1,)\n",
    "\n",
    "    sns.barplot(x=\"overallScore\", y=\"rel_count\", data=tmp, color=cws[ws], ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(ws, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"relative count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"mood ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q13_relcount.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q14' ></a>\n",
    "### Q14: What is the distribution of transport modes and worthwhileness ratings among different weather scenarios?\n",
    "\n",
    "Information to be extracted following a combination of weather statistics during trips and user profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Plot each distribution for each weather scenario\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"Distributions (absolute counts) of worhthwhileness ratings by weather scenario\",\n",
    "    size=16,\n",
    "    y=1.12,\n",
    ")\n",
    "axes = axes.ravel()\n",
    "\n",
    "\n",
    "axid = 0\n",
    "for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "    print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "    tmp = ws_composite_data[ws]\n",
    "    tmp = tmp.groupby([\"wastedTime\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    sns.barplot(x=\"wastedTime\", y=\"count\", data=tmp, color=cws[ws], ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(ws, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q14.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c  ### Plot each distribution for each weather scenario\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "fig.suptitle(\n",
    "    \"Distributions (relative counts) of worhthwhileness ratings by weather scenario\",\n",
    "    size=16,\n",
    "    y=1.12,\n",
    ")\n",
    "axes = axes.ravel()\n",
    "\n",
    "axid = 0\n",
    "for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "    print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "    tmp = ws_composite_data[ws]\n",
    "    tmp = tmp.groupby([\"wastedTime\"])[\"tripid\"].size().reset_index(name=\"count\")\n",
    "\n",
    "    tot = tmp[\"count\"].sum()\n",
    "    tmp[\"rel_count\"] = tmp.apply(lambda x: x[\"count\"] / tot, axis=1,)\n",
    "\n",
    "    sns.barplot(x=\"wastedTime\", y=\"rel_count\", data=tmp, color=cws[ws], ax=axes[idx])\n",
    "    axes[idx].legend(\"\")\n",
    "    axes[idx].set_title(ws, fontsize=14)\n",
    "    axes[idx].set_ylabel(\"relative count\", fontsize=12)\n",
    "    axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "    axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + \"h15_q14_relcount.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_composite_data_tc = {}\n",
    "for ws in weather_scenarios.keys():\n",
    "    print(\"ws:\", ws)\n",
    "\n",
    "    ws_composite_data_tc[ws] = ws_composite_data[ws].merge(\n",
    "        legs_df[[\"tripid\", \"transp_category\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ws_composite_data_tc[\"cold\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY TRANSPORT CATEGORY\n",
    "\n",
    "\n",
    "def q14_count_plot(tc):\n",
    "    nrows = 2\n",
    "    ncols = 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "    fig.suptitle(\n",
    "        \"Distributions (absolute counts) of worhthwhileness ratings by weather scenario \"\n",
    "        'per transport category \"{}\"'.format(tc),\n",
    "        size=16,\n",
    "        y=1.12,\n",
    "    )\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    axid = 0\n",
    "    for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "        print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "        tmp = ws_composite_data_tc[ws].loc[\n",
    "            ws_composite_data_tc[ws][\"transp_category\"] == tc\n",
    "        ]\n",
    "        tmp = tmp.groupby([\"wastedTime\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "        sns.barplot(x=\"wastedTime\", y=\"count\", data=tmp, color=cws[ws], ax=axes[idx])\n",
    "        axes[idx].legend(\"\")\n",
    "        axes[idx].set_title(ws, fontsize=14)\n",
    "        axes[idx].set_ylabel(\"count\", fontsize=12)\n",
    "        axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "        axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = \"h15_q14_{}.png\".format(tc)\n",
    "    plt.savefig(img_path + filename, bbox_to_anchor=True, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def q14_relcount_plot(tc):\n",
    "    nrows = 2\n",
    "    ncols = 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 8), sharey=True)\n",
    "    fig.suptitle(\n",
    "        \"Distributions (relative counts) of worhthwhileness ratings by weather scenario \"\n",
    "        'per transport category \"{}\"'.format(tc),\n",
    "        size=16,\n",
    "        y=1.12,\n",
    "    )\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    axid = 0\n",
    "    for idx, ws in list(enumerate(weather_scenarios.keys())):\n",
    "        print(\"(idx, ws): ({}, {})\".format(idx, ws))\n",
    "\n",
    "        tmp = ws_composite_data_tc[ws].loc[\n",
    "            ws_composite_data_tc[ws][\"transp_category\"] == tc\n",
    "        ]\n",
    "        tmp = tmp.groupby([\"wastedTime\"])[\"tripid\"].size().reset_index(name=\"count\")\n",
    "\n",
    "        tot = tmp[\"count\"].sum()\n",
    "        tmp[\"rel_count\"] = tmp.apply(lambda x: x[\"count\"] / tot, axis=1,)\n",
    "\n",
    "        sns.barplot(\n",
    "            x=\"wastedTime\", y=\"rel_count\", data=tmp, color=cws[ws], ax=axes[idx]\n",
    "        )\n",
    "        axes[idx].legend(\"\")\n",
    "        axes[idx].set_title(ws, fontsize=14)\n",
    "        axes[idx].set_ylabel(\"relative count\", fontsize=12)\n",
    "        axes[idx].set_xlabel(\"worthwhileness ratings\", fontsize=12)\n",
    "        axes[idx].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = \"h15_q14_relcount_{}.png\".format(tc)\n",
    "    plt.savefig(img_path + filename, bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_categories = [\n",
    "    tc for tc in set(legs_df.transp_category.values) if tc is not None\n",
    "]\n",
    "print(\"transport_categories:\", transport_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tc in transport_categories:\n",
    "    q14_count_plot(tc)\n",
    "\n",
    "for tc in transport_categories:\n",
    "    q14_relcount_plot(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "7"
          },
          {
           "key": 4,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "10"
          },
          {
           "key": 4,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H9\n",
    "\n",
    "\n",
    "**Obj:** Modal distances\n",
    "<br>\n",
    "To explore how many urban trips are short distances.\n",
    "\n",
    "## Questions\n",
    "\n",
    "- [Q1](#Q1): What is the cumulative distribution of leg distances?\n",
    "- [Q2](#Q2): How many car trips were short (e.g. less than 5km and less than 10km) and what are the traveller characteristics of those users?\n",
    "- [Q3](#Q3): What are the negative experience factors of cyclists and users of public transport for the same short trip legs performed by car?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Q3' ></a>\n",
    "### Q3: What are the negative experience factors of cyclists and users of public transport for the same short trip legs performed by car?\n",
    "\n",
    "What is the potential for shifting to other modes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "\n",
    "# numerical libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "cutting_date = \"2019-05-01\"  # remove trips and data published before this date\n",
    "meta_data_path = \"../../data-campaigns/meta-data/\"\n",
    "input_path = \"../../2019-12-16.out/\"\n",
    "out_path = \"../../2019-12-16.out/hypothesis/H9/\"\n",
    "img_path = \"../../2019-12-16.out/hypothesis/H9/\"\n",
    "\n",
    "# Graphical parameters\n",
    "rcParams[\"axes.titlepad\"] = 45\n",
    "rcParams[\"font.size\"] = 16\n",
    "rcParams[\"figure.figsize\"] = 12, 8\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.abspath(out_path))\n",
    "except FileExistsError:\n",
    "    print(\"Directory '{}' already exists\".format(out_path), file=sys.stderr)\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.abspath(img_path))\n",
    "except FileExistsError:\n",
    "    print(\"Directory '{}' already exists\".format(img_path), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "legs = \"all_legs_merged_no_outlier_0.01.pkl\"\n",
    "trips_users = \"trips_users_df.pkl\"\n",
    "trips = \"trips_df.pkl\"\n",
    "users_with_trips = \"users_df_with_trips.pkl\"\n",
    "\n",
    "# read datasets\n",
    "legs_df = pd.read_pickle(input_path + legs)\n",
    "trips_users_df = pd.read_pickle(input_path + trips_users)\n",
    "trips_df = pd.read_pickle(input_path + trips)\n",
    "users_df_with_trips = pd.read_pickle(input_path + users_with_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure:\n",
    "1. select trip legs performed by car;\n",
    "2. get users that have performed at least a trip as per point 1. above;\n",
    "3. among users from point 2., get the ones that have chosen at least one preferred transport mode within the transport categories: \"biking\". \"public transport (short)\", \"public transport (long)\"\n",
    "4. for the users from point 3., select all trips that were not perfomed by car and look at the top negative experience factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_df.transp_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. select trips with at least one leg that is private motorized\n",
    "pm_tripids = legs_df.loc[\n",
    "    legs_df[\"transp_category\"] == \"private_motorized\"\n",
    "].tripid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. select users that have performed at least a trip as per point 1. above;\n",
    "pm_userids = legs_df.loc[legs_df[\"tripid\"].isin(pm_tripids)].userid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. among users from point 2., get the ones that have chosen at least one preferred transport mode\n",
    "#    within the trasport categories: \"biking\". \"public transport (short)\", \"public transport (long)\"\n",
    "user_prefmots = users_df_with_trips.loc[users_df_with_trips[\"userid\"].isin(pm_userids)][\n",
    "    [\"userid\", \"preferedMots\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def list_prefmots(pm):\n",
    "    prefmots = []\n",
    "\n",
    "    for pmdict in pm:\n",
    "        prefmots.append(pmdict[\"Mot\"])\n",
    "\n",
    "    return prefmots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transport category according to spreadsheet\n",
    "category_transp_mode_dict = {\n",
    "    \"walking\": [2, 7, 8, 34, 37],\n",
    "    \"cycling_emerging_micromobility\": [1, 16, 17, 18, 19, 31, 35],\n",
    "    \"public_transp_short_dist\": [10, 11, 12, 15, 30],\n",
    "    \"public_transp_long_dist\": [14, 13, 28, 33, 27],\n",
    "    \"private_motorized\": [0, 9, 20, 21, 22, 23, 25, 26, 32, 36],\n",
    "}\n",
    "\n",
    "transp_mode_category_dict = {}\n",
    "for tc, motlist in category_transp_mode_dict.items():\n",
    "    for mot in motlist:\n",
    "        transp_mode_category_dict[mot] = tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prefmot_to_tranpcats(prefmot_list):\n",
    "    tranpcats = []\n",
    "\n",
    "    for pmot in prefmot_list:\n",
    "        tc = transp_mode_category_dict.get(pmot, \"Unknown\")\n",
    "        tranpcats.append(tc)\n",
    "\n",
    "    return set(tranpcats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefmots[\"prefmots_transp_categories\"] = user_prefmots.preferedMots.apply(\n",
    "    lambda pm: map_prefmot_to_tranpcats(list_prefmots(pm))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefmots.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTERNATIVE_TRANSPORT_CATEGORIES = [\n",
    "    \"cycling_emerging_micromobility\",\n",
    "    \"public_transp_short_dist\",\n",
    "    \"public_transp_long_dist\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b):\n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    if a_set & b_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_aternative_transp_categories(tc):\n",
    "    return common_member(tc, ALTERNATIVE_TRANSPORT_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefmots[\n",
    "    \"has_aternative_transp_categories\"\n",
    "] = user_prefmots.prefmots_transp_categories.apply(has_aternative_transp_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prefmots.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['column_name'] == some_value]\n",
    "alt_userids = user_prefmots.loc[\n",
    "    user_prefmots[\"has_aternative_transp_categories\"] == True\n",
    "].userid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users that have performed a trip by car but that have also preferred modes that are bike and public transport\n",
    "common_users = set(pm_userids).intersection(set(alt_userids))\n",
    "print(\n",
    "    \"Number of that have performed a trip by car but have also alternative preferred modes:\",\n",
    "    len(common_users),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users_legs_df = legs_df.loc[legs_df[\"userid\"].isin(common_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users_legs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users_noncar_legs_df = common_users_legs_df.loc[\n",
    "    common_users_legs_df[\"transp_category\"].isin(ALTERNATIVE_TRANSPORT_CATEGORIES)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users_noncar_legs_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data for reliability\n",
    "all_factors = pd.read_pickle(input_path + \"all_factors.pkl\")\n",
    "\n",
    "# delete legs with minus=F and plus=F\n",
    "all_factors = all_factors[\n",
    "    ~((all_factors[\"minus\"] == False) & (all_factors[\"plus\"] == False))\n",
    "]\n",
    "\n",
    "# delete legs with minus=T and plus=T (3% of obs)\n",
    "all_factors = all_factors[\n",
    "    ~((all_factors[\"minus\"] == True) & (all_factors[\"plus\"] == True))\n",
    "]\n",
    "\n",
    "print(\"all records:\", len(all_factors))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_users_noncar_legs = all_factors.loc[\n",
    "    all_factors[\"legid\"].isin(common_users_noncar_legs_df[\"legid\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_users_noncar_legs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all trips that were not perfomed by car and look at the top negative experience factor\n",
    "all_factors_minus_users_noncar_legs = all_factors_users_noncar_legs.loc[\n",
    "    all_factors_users_noncar_legs[\"minus\"] == True\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_factors_minus_users_noncar_legs = all_factors_minus_users_noncar_legs.merge(\n",
    "    legs_df[[\"legid\", \"transp_category\"]], on=\"legid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_minus_users_noncar_legs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = (\n",
    "    all_factors_minus_users_noncar_legs.groupby([\"transp_category\", \"factor\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index(name=\"nlegs\")\n",
    ")\n",
    "\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_categories = list(set(transp_mode_category_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = pd.pivot_table(\n",
    "    results, values=\"nlegs\", index=[\"factor\"], columns=[\"transp_category\"], fill_value=0\n",
    ")\n",
    "heatmap_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = heatmap_df.reindex(\n",
    "    heatmap_df.sort_values(by=\"cycling_emerging_micromobility\", ascending=False).index\n",
    ")\n",
    "heatmap_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 24))\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\"d\")\n",
    "\n",
    "# set title and style\n",
    "plt.title(\"Top negative factors for alternative trips\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save image\n",
    "plt.savefig(img_path + \"h9_q3.png\", bbox_to_anchor=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of Similar Legs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legs_coords_filename = \"all_legs_final_ds_user_info_urban_class.pkl\"\n",
    "all_legs_coords = pd.read_pickle(os.path.join(input_path, all_legs_coords_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_cities_filename = \"gps_cities.pkl\"\n",
    "gps_cities = pd.read_pickle(os.path.join(input_path, gps_cities_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gps_cities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "legs_coords_df = gps_cities[\n",
    "    [\n",
    "        \"legid\",\n",
    "        \"StartLat\",\n",
    "        \"StartLon\",\n",
    "        \"country_start\",\n",
    "        \"start_class\",\n",
    "        \"EndLat\",\n",
    "        \"EndLon\",\n",
    "        \"country_end\",\n",
    "        \"end_class\",\n",
    "    ]\n",
    "]\n",
    "legs_coords_df = legs_coords_df.rename(\n",
    "    columns={\n",
    "        \"StartLat\": \"lat_start\",\n",
    "        \"StartLon\": \"lon_start\",\n",
    "        \"start_class\": \"class_start\",\n",
    "        \"EndLat\": \"lat_end\",\n",
    "        \"EndLon\": \"lon_end\",\n",
    "        \"end_class\": \"class_end\",\n",
    "    }\n",
    ")\n",
    "legs_coords_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "legs_coords_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate rounding procedure\n",
    "\n",
    "Following the information on the Wikipedia page [Decimal degree](https://en.wikipedia.org/w/index.php?title=Decimal_degrees&oldid=937245621#Precision) and the question on StackOverflow [\"Measuring accuracy of latitude and longitude?\"](https://gis.stackexchange.com/q/8650/18292), we have that:\n",
    "> The third decimal place is worth up to 110 m: it can identify a large agricultural field or institutional campus.\n",
    "```\n",
    "3        0.001            111  m\n",
    "```\n",
    "\n",
    "We will proceed like this: we consider each point (lat, lon) to be represented by a square given with the following vertices:\n",
    "* `A (lat-0.002, lon+0.002)`\n",
    "* `B (lat+0.002, lon+0.002)`\n",
    "* `C (lat+0.002, lon-0.002)`\n",
    "* `D (lat-0.002, lon-0.002)`\n",
    "\n",
    "In this way each point is effectively transformed in a square - or, rather a curved square, each side is an arc - with sides of lenght o.004 degrees.\n",
    "\n",
    "If the the squares representing two points intersect we consider them equal. In this way two points are distant at most:\n",
    "```\n",
    "sqrt(2)·(0.004 deg)·(111.32 km/deg) = 629,72102 m ~ 630 m\n",
    "```\n",
    "\n",
    "Graphical example:\n",
    "![coordinate_intersection.png](https://i.imgur.com/fSh5ISh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if two rectangles overlap\n",
    "# https://www.geeksforgeeks.org/find-two-rectangles-overlap/\n",
    "\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "# Returns true if two rectangles(l1, r1) and (l2, r2) overlap\n",
    "def rect_overlap(l1, r1, l2, r2):\n",
    "    # If one rectangle is on left side of other\n",
    "    if l1.x > r2.x or l2.x > r1.x:\n",
    "        return False\n",
    "\n",
    "    # If one rectangle is above other\n",
    "    if l1.y < r2.y or l2.y < r1.y:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def equivalent_points(p1lat, p1lon, p2lat, p2lon):\n",
    "    # A (lat-0.002, lon+0.002)\n",
    "    # B (lat+0.002, lon+0.002)\n",
    "    # C (lat+0.002, lon-0.002)\n",
    "    # D (lat-0.002, lon-0.002)\n",
    "\n",
    "    a1 = Point(p1lat - 0.002, p1lon + 0.002)\n",
    "    b1 = Point(p1lat + 0.002, p1lon + 0.002)\n",
    "    c1 = Point(p1lat + 0.002, p1lon - 0.002)\n",
    "    d1 = Point(p1lat - 0.002, p1lon - 0.002)\n",
    "\n",
    "    a2 = Point(p2lat - 0.002, p2lon + 0.002)\n",
    "    b2 = Point(p2lat + 0.002, p2lon + 0.002)\n",
    "    c2 = Point(p2lat + 0.002, p2lon - 0.002)\n",
    "    d2 = Point(p2lat - 0.002, p2lon - 0.002)\n",
    "\n",
    "    return rect_overlap(a1, c1, a2, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalent_points(1.0, 1.0, 1.00405, 1.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    legs_coords_df[\n",
    "        [\"legid\", \"country_start\", \"country_end\", \"class_start\", \"class_end\"]\n",
    "    ]\n",
    "    .fillna(\"NONE\")\n",
    "    .groupby([\"country_start\", \"country_end\", \"class_start\", \"class_end\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.groupby([\"country_start\"]).size().sort_values(\n",
    "    ascending=False\n",
    ").reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.groupby([\"country_start\", \"class_start\"]).size().sort_values(\n",
    "    ascending=False\n",
    ").reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.groupby([\"country_end\", \"class_end\"]).size().sort_values(\n",
    "    ascending=False\n",
    ").reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = set(legs_coords_df.country_start.fillna(\"NONE\").unique()).union(\n",
    "    set(legs_coords_df.country_end.fillna(\"NONE\").unique())\n",
    ")\n",
    "countries.discard(\"NONE\")\n",
    "print(\"Number of different countries:\", len(countries))\n",
    "print(countries)\n",
    "\n",
    "point_classes = set(legs_coords_df.class_start.fillna(\"NONE\").unique()).union(\n",
    "    set(legs_coords_df.class_end.fillna(\"NONE\").unique())\n",
    ")\n",
    "point_classes.discard(\"NONE\")\n",
    "print(\"Number of classes:\", len(point_classes))\n",
    "print(point_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_NROWS = 1000000\n",
    "\n",
    "\n",
    "def select_legs(coords1_df, coords2_df, country, pc):\n",
    "    tmp1_df = coords1_df.loc[\n",
    "        ((coords1_df[\"country\"] == country) | (coords1_df[\"country\"] == \"NONE\"))\n",
    "        & ((coords1_df[\"class\"] == pc) | (coords1_df[\"class\"] == \"NONE\"))\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    tmp2_df = coords2_df.loc[\n",
    "        ((coords2_df[\"country\"] == country) | (coords2_df[\"country\"] == \"NONE\"))\n",
    "        & ((coords2_df[\"class\"] == pc) | (coords2_df[\"class\"] == \"NONE\"))\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    npoints1 = tmp1_df.legid.nunique()\n",
    "    npoints2 = tmp2_df.legid.nunique()\n",
    "    print(\n",
    "        \"- Points 1: {}, Points 2: {}, To Process: {} - \".format(\n",
    "            npoints1, npoints2, npoints1 * npoints2\n",
    "        ),\n",
    "        end=\"\",\n",
    "    )\n",
    "\n",
    "    if npoints1 > 0 and npoints2 > 0:\n",
    "        i = 0\n",
    "        # iterating over multiple columns\n",
    "        for row1 in tmp1_df.itertuples():\n",
    "            for row2 in tmp2_df.itertuples():\n",
    "                i = i + 1\n",
    "                if (i % PRINT_NROWS) == 0:\n",
    "                    print(\".\", end=\"\")\n",
    "                if (i % (10 * PRINT_NROWS)) == 0:\n",
    "                    print(\" \", end=\"\")\n",
    "\n",
    "                # equivalent_points(p1lat, p1lon, p2lat, p2lon):\n",
    "                if row1.legid > row2.legid and equivalent_points(\n",
    "                    row1.lat, row1.lon, row2.lat, row2.lon\n",
    "                ):\n",
    "                    yield (row1.legid, row2.legid)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "COMPUTE_MATCHING_LEGS = False\n",
    "BIG_MEMORY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import csv\n",
    "\n",
    "legs_start_coords_df = legs_coords_df[\n",
    "    [\"legid\", \"lat_start\", \"lon_start\", \"country_start\", \"class_start\"]\n",
    "].copy()\n",
    "legs_start_coords_df[\"country_start\"] = legs_start_coords_df[\"country_start\"].fillna(\n",
    "    \"NONE\"\n",
    ")\n",
    "legs_start_coords_df[\"class_start\"] = legs_start_coords_df[\"class_start\"].fillna(\"NONE\")\n",
    "legs_start_coords_df.columns = [\"legid\", \"lat\", \"lon\", \"country\", \"class\"]\n",
    "\n",
    "legs_end_coords_df = legs_coords_df[\n",
    "    [\"legid\", \"lat_end\", \"lon_end\", \"country_end\", \"class_end\"]\n",
    "].copy()\n",
    "legs_end_coords_df[\"country_end\"] = legs_end_coords_df[\"country_end\"].fillna(\"NONE\")\n",
    "legs_end_coords_df[\"class_end\"] = legs_end_coords_df[\"class_end\"].fillna(\"NONE\")\n",
    "legs_end_coords_df.columns = [\"legid\", \"lat\", \"lon\", \"country\", \"class\"]\n",
    "\n",
    "matching_points = []\n",
    "if COMPUTE_MATCHING_LEGS:\n",
    "    matching_points_filename = \"matching_points.csv\"\n",
    "    with open(os.path.join(input_path, \"matching_points.csv\"), \"w+\") as outfp:\n",
    "        for country in sorted(countries):\n",
    "            for pc in sorted(point_classes):\n",
    "\n",
    "                print(\"Processing: {} ({})\".format(country, pc))\n",
    "\n",
    "                writer = csv.writer(outfp)\n",
    "\n",
    "                writer.writerow([\"legid1\", \"type1\", \"legid2\", \"type2\"])\n",
    "                for match in select_legs(\n",
    "                    legs_start_coords_df, legs_start_coords_df, country, pc\n",
    "                ):\n",
    "                    legid1 = match[0]\n",
    "                    legid2 = match[1]\n",
    "                    if BIG_MEMORY:\n",
    "                        matching_points.append((legid1, \"start\", legid2, \"start\"))\n",
    "                    else:\n",
    "                        writer.writerow((legid1, \"start\", legid2, \"start\"))\n",
    "\n",
    "                for match in select_legs(\n",
    "                    legs_start_coords_df, legs_end_coords_df, country, pc\n",
    "                ):\n",
    "                    legid1 = match[0]\n",
    "                    legid2 = match[1]\n",
    "                    if BIG_MEMORY:\n",
    "                        matching_points.append((legid1, \"start\", legid2, \"end\"))\n",
    "                    else:\n",
    "                        writer.writerow((legid1, \"start\", legid2, \"end\"))\n",
    "\n",
    "                for match in select_legs(\n",
    "                    legs_end_coords_df, legs_end_coords_df, country, pc\n",
    "                ):\n",
    "                    legid1 = match[0]\n",
    "                    legid2 = match[1]\n",
    "                    if BIG_MEMORY:\n",
    "                        matching_points.append((legid1, \"end\", legid2, \"end\"))\n",
    "                    else:\n",
    "                        writer.writerow((legid1, \"end\", legid2, \"end\"))\n",
    "\n",
    "                if BIG_MEMORY:\n",
    "                    for match in matching_points:\n",
    "                        writer.writerow(match)\n",
    "\n",
    "else:\n",
    "    if BIG_MEMORY:\n",
    "        matching_points_filename = \"matching_points.csv\"\n",
    "    else:\n",
    "        matching_points_filename = \"matching_points_10M.csv\"\n",
    "\n",
    "    with open(os.path.join(input_path, matching_points_filename), \"r\") as infp:\n",
    "        reader = csv.reader(infp)\n",
    "\n",
    "        # skip header\n",
    "        next(reader)\n",
    "\n",
    "        matching_points = [line for line in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of matching points pairs:\", len(matching_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_points[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_legids = legs_df.loc[legs_df[\"tripid\"].isin(pm_tripids)].legid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "matching_points_legids = set(\n",
    "    itertools.chain.from_iterable([(el[0], el[2]) for el in matching_points])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_legids = set(matching_points_legids).intersection(pm_legids)\n",
    "print(\"Number of legids in common_legids:\", len(common_legids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ss_points = defaultdict(list)\n",
    "se_points = defaultdict(list)\n",
    "es_points = defaultdict(list)\n",
    "ee_points = defaultdict(list)\n",
    "\n",
    "for legid1, type1, legid2, type2 in matching_points:\n",
    "    if type1 == \"start\" and type2 == \"start\":\n",
    "        ss_points[legid1].append(legid2)\n",
    "    elif type1 == \"start\" and type2 == \"end\":\n",
    "        se_points[legid1].append(legid2)\n",
    "        es_points[legid2].append(legid1)\n",
    "    elif type1 == \"end\" and type2 == \"end\":\n",
    "        ee_points[legid1].append(legid2)\n",
    "    else:\n",
    "        print(\"Unepected types: ({}, {}, {}, {})\".format(legid1, type1, legid2, type2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "def take(iterable, n):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ss_points:\", end=\"\")\n",
    "print([(k, len(v)) for k, v in take(ss_points.items(), 5)])\n",
    "\n",
    "print(\"se_points:\", end=\"\")\n",
    "print([(k, len(v)) for k, v in take(se_points.items(), 5)])\n",
    "\n",
    "print(\"es_points:\", end=\"\")\n",
    "print([(k, len(v)) for k, v in take(es_points.items(), 5)])\n",
    "\n",
    "print(\"ee_points:\", end=\"\")\n",
    "print([(k, len(v)) for k, v in take(ee_points.items(), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_legs = defaultdict(list)\n",
    "\n",
    "for legid in ss_points.keys():\n",
    "    matching_start_ids = ss_points[legid]\n",
    "    matching_end_ids = ee_points[legid]\n",
    "\n",
    "    common_matches = set(matching_start_ids).intersection(matching_end_ids)\n",
    "    if len(common_matches) > 0:\n",
    "        matching_legs[legid].extend(common_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of matching legs (start-end):\", len(matching_legs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"matching_legs:\", end=\"\")\n",
    "pprint([(k, v) for k, v in take(matching_legs.items(), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_df.loc[legs_df[\"legid\"] == \"#24:23124\"].userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.loc[legs_coords_df[\"legid\"] == \"#24:23124\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_df.loc[legs_df[\"legid\"] == matching_legs[\"#24:23124\"][0]].userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_coords_df.loc[legs_coords_df[\"legid\"] == matching_legs[\"#24:23124\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_selected_legs = legs_df.loc[\n",
    "    (legs_df[\"transp_category\"] == \"private_motorized\")\n",
    "    & (legs_df[\"legid\"].isin(set(k for k in matching_legs.keys())))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of selected private motorized legs:\", pm_selected_legs.legid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_matching_legs = set()\n",
    "for pm_legid in set(pm_selected_legs.legid.unique()):\n",
    "    selected_matching_legs.update(matching_legs[pm_legid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take(selected_matching_legs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of matching legs: \", len(selected_matching_legs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_selected_legs = legs_df.loc[\n",
    "    (legs_df[\"transp_category\"].isin(ALTERNATIVE_TRANSPORT_CATEGORIES))\n",
    "    & (legs_df[\"legid\"].isin(selected_matching_legs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_selected_legs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_alternative_selected_legs = all_factors.loc[\n",
    "    all_factors[\"legid\"].isin(alternative_selected_legs[\"legid\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all negative experience factor\n",
    "all_factors_minus_alternative_selected_legs = all_factors_alternative_selected_legs.loc[\n",
    "    all_factors_alternative_selected_legs[\"minus\"] == True\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors_minus_alternative_selected_legs = all_factors_minus_alternative_selected_legs.merge(\n",
    "    legs_df[[\"legid\", \"transp_category\"]], on=\"legid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (\n",
    "    all_factors_minus_alternative_selected_legs.groupby([\"transp_category\", \"factor\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index(name=\"nlegs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
